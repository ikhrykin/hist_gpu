{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nimport matplotlib.pyplot as pl\n\nfrom cupyx import jit\nfrom astropy.table import Table\nfrom cupyx.profiler import benchmark","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:54:34.231425Z","iopub.execute_input":"2023-12-11T19:54:34.231668Z","iopub.status.idle":"2023-12-11T19:54:39.107301Z","shell.execute_reply.started":"2023-12-11T19:54:34.231645Z","shell.execute_reply":"2023-12-11T19:54:39.106445Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Option 1: jit translation of a pythonic code to CUDA/ะก, global atomic_add()\n@jit.rawkernel()\ndef histogram_jit(data, bins_data, n_bins, min_x, max_x, data_size):\n\n    gid    = jit.threadIdx.x + jit.blockIdx.x * jit.blockDim.x\n    stride = jit.blockDim.x * jit.gridDim.x\n    \n    dbin   = (max_x-min_x)/n_bins\n\n    while gid < data_size:\n        number = data[gid]\n        index  = cp.int32(number / dbin)\n        jit.atomic_add(bins_data, index, 1)\n        gid   += stride\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:54:43.057205Z","iopub.execute_input":"2023-12-11T19:54:43.058293Z","iopub.status.idle":"2023-12-11T19:54:43.067122Z","shell.execute_reply.started":"2023-12-11T19:54:43.058245Z","shell.execute_reply":"2023-12-11T19:54:43.066215Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/cupyx/jit/_interface.py:171: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n  cupy._util.experimental('cupyx.jit.rawkernel')\n","output_type":"stream"}]},{"cell_type":"code","source":"histogram_jit_cashed = cp.RawKernel(r'''\n                                    extern \"C\" __global__ \n                                    void histogram_jit(float* data, int* bins_data, int n_bins, float min_x, float max_x, int data_size) \n                                    {\n                                      float number;\n                                      int index;\n                                      unsigned int gid = (threadIdx.x + (blockIdx.x * blockDim.x));\n                                      unsigned int stride = (blockDim.x * gridDim.x);\n                                      float dbin = ((float)(max_x - min_x) / (float)(float)(n_bins));\n  \n                                      while ((gid < (unsigned int)(data_size))) \n                                          {\n                                            number = data[gid];\n                                            index = (int)(((float)number / (float)dbin));\n                                            atomicAdd(&bins_data[index], 1);\n                                            \n                                            { unsigned int &_tmp_1 = gid; \n                                                            _tmp_1 = (_tmp_1 + stride); }\n                                          }\n                                    }\n                                   ''', 'histogram_jit_cashed' )","metadata":{"execution":{"iopub.status.busy":"2023-12-11T17:42:22.241179Z","iopub.execute_input":"2023-12-11T17:42:22.241549Z","iopub.status.idle":"2023-12-11T17:42:22.247378Z","shell.execute_reply.started":"2023-12-11T17:42:22.241524Z","shell.execute_reply":"2023-12-11T17:42:22.246407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Option 2: Raw kernel, CUDA/C, global atomic_add\nhistogram_raw = cp.RawKernel(r'''\n\t                         extern \"C\" __global__\n                             void histogram_raw( float* data, int* bins_data, int n_bins, float min_x, float max_x, int data_size )\n                              {\n                                int gid    = threadIdx.x + blockIdx.x * blockDim.x;\n                                int stride = blockDim.x * gridDim.x;\n                                \n                                float bin_size = (max_x-min_x) / n_bins;\n\n                                while (gid < data_size)\n                                 {\n                                   int index = (int)( data[gid] / bin_size );\n                                  \n                                   atomicAdd(&bins_data[index], 1);\n\n                                   gid += stride;\n                                 }\n                              }\n                             ''', 'histogram_raw')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:54:47.181519Z","iopub.execute_input":"2023-12-11T19:54:47.182398Z","iopub.status.idle":"2023-12-11T19:54:47.188872Z","shell.execute_reply.started":"2023-12-11T19:54:47.182357Z","shell.execute_reply":"2023-12-11T19:54:47.187884Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Option 3. ElementWise Kernel, CUDA/C, global memory atomic_add\nhistogram_elw = cp.ElementwiseKernel(\n                                      'float32 data, int32 n_bins, float32 x_min, float32 x_max', # input\n                                      'raw T bins_data',                                          # output\n\n                                      '''\n                                      float bin_size = (x_max - x_min) / n_bins;\n\n                                      int index = (int)( data / bin_size);\n\n                                      atomicAdd(&bins_data[index], 1);\n\n                                      ''', 'histogram_elw'\n                                    )\n","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:54:50.845901Z","iopub.execute_input":"2023-12-11T19:54:50.846386Z","iopub.status.idle":"2023-12-11T19:54:50.851347Z","shell.execute_reply.started":"2023-12-11T19:54:50.846341Z","shell.execute_reply":"2023-12-11T19:54:50.850225Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"histogram_raw_shd = cp.RawKernel(r'''\n\t                         extern \"C\" __global__\n                             void histogram_raw_shd( float* data, int* bins_data, int n_bins, float min_x, float max_x, int data_size )\n                              {\n                                extern __shared__ unsigned int temp[];\n                                \n                                if (threadIdx.x < n_bins)\n                                    {\n                                      temp[threadIdx.x] = 0;\n                                    }\n                                __syncthreads();\n                                \n                                int gid    = threadIdx.x + blockIdx.x * blockDim.x;\n                                int stride = blockDim.x * gridDim.x;         \n                                \n                                float bin_size = (max_x-min_x) / n_bins;\n\n                                while (gid < data_size)\n                                 {\n                                   int index = (int)( data[gid] / bin_size );\n                                  \n                                   atomicAdd(&temp[index], 1);\n\n                                   gid += stride;\n                                 }\n                                \n                                __syncthreads();\n                                if (threadIdx.x < n_bins)\n                                {\n                                  atomicAdd( &(bins_data[threadIdx.x]), temp[threadIdx.x] );\n                                }\n                             \n                              }''','histogram_raw_shd'\n                             )","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:54:52.943457Z","iopub.execute_input":"2023-12-11T19:54:52.943828Z","iopub.status.idle":"2023-12-11T19:54:52.949703Z","shell.execute_reply.started":"2023-12-11T19:54:52.943799Z","shell.execute_reply":"2023-12-11T19:54:52.948711Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"histogram_raw_shd_new = cp.RawKernel(r'''\n    extern \"C\" global\n    void histogram_raw_shd_new(float* data, int* bins_data, int n_bins, float min_x, float max_x, int data_size)\n    {\n        extern shared unsigned int temp[];\n\n        int tid = threadIdx.x;\n        int gid = tid + blockIdx.x * blockDim.x;\n        int stride = blockDim.x * gridDim.x;\n\n        // Initialize shared memory to store bin counts\n        if (tid < n_bins)\n        {\n            temp[tid] = 0;\n        }\n        __syncthreads();\n\n        float bin_size = (max_x - min_x) / n_bins;\n\n        // Compute histogram in global memory with coarsening and warp optimization\n        while (gid < data_size)\n        {\n            #pragma unroll\n            for (int i = 0; i < 32; i += warpSize)\n            {\n                int index = static_cast<int>((data[gid + i] - min_x) / bin_size);\n                index = max(0, min(index, n_bins - 1) * (index >= 0 && index < n_bins));\n                atomicAdd(&temp[index], 1);\n            }\n\n            gid += stride;\n        }\n\n        // Synchronize threads before updating global memory\n        __syncthreads();\n\n        // Update global memory with shared memory counts\n        if (tid < n_bins)\n        {\n            atomicAdd(&(bins_data[tid]), temp[tid]);\n        }\n    }\n''', 'histogram_raw_shd_new')","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:54:59.463921Z","iopub.execute_input":"2023-12-11T19:54:59.464948Z","iopub.status.idle":"2023-12-11T19:54:59.470512Z","shell.execute_reply.started":"2023-12-11T19:54:59.464911Z","shell.execute_reply":"2023-12-11T19:54:59.469443Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"###### Histogram params #######\nn_bins = 10\nn_data = 2**20\nmax_x  = cp.float32(1.0)\nmin_x  = cp.float32(0.0)\n###############################\n\n##### DEVICE arrays #####\ncp.random.seed(42)\nnp.random.seed(42)\nd_data              = cp.random.rand(n_data).astype(cp.float32)\nh_data              = np.random.rand(n_data).astype(np.float32)\nd_bins_data_jit     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_raw     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_elw     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_shd     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_shd_new = cp.zeros(n_bins, dtype=cp.int32)\n#########################\n#print (d_data.size )\n###### GPU params #######\nn_threads = 1024\nsmem = n_bins * cp.dtype(cp.int32).itemsize\n\nhistogram_jit((1,1,1), (n_threads,1,1), (d_data, d_bins_data_jit, n_bins, min_x, max_x, d_data.size ))\nhistogram_raw((1,1,1), (n_threads,1,1), (d_data, d_bins_data_raw, n_bins, min_x, max_x, d_data.size ))\nhistogram_elw( d_data, n_bins, min_x, max_x, d_bins_data_elw, block_size=n_threads )\n\nhistogram_raw_shd(    (1,1,1),(n_threads,1,1), (d_data, d_bins_data_shd, n_bins, min_x, max_x, d_data.size), shared_mem=smem)\nhistogram_raw_shd_new((1,1,1),(n_threads,1,1), (d_data, d_bins_data_shd, n_bins, min_x, max_x, d_data.size), shared_mem=smem)\n\nhistogram_np,_ = np.histogram(h_data, n_bins, range=(0,1))\n\nprint (d_bins_data_jit.get())\nprint (d_bins_data_raw.get())\nprint (d_bins_data_elw.get())\n\nprint (d_bins_data_shd.get())\nprint (d_bins_data_shd_new.get())\n\nprint (histogram_np)\n\nd_bins_data_jit     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_raw     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_elw     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_shd     = cp.zeros(n_bins, dtype=cp.int32)\nd_bins_data_shd_new = cp.zeros(n_bins, dtype=cp.int32)\n\ncp.random.seed(42)\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T19:56:08.096075Z","iopub.execute_input":"2023-12-11T19:56:08.096984Z","iopub.status.idle":"2023-12-11T19:56:11.643100Z","shell.execute_reply.started":"2023-12-11T19:56:08.096948Z","shell.execute_reply":"2023-12-11T19:56:11.641549Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNVRTCError\u001b[0m                                Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cupy/cuda/compiler.py:689\u001b[0m, in \u001b[0;36m_NVRTCProgram.compile\u001b[0;34m(self, options, log_stream)\u001b[0m\n\u001b[1;32m    688\u001b[0m         nvrtc\u001b[38;5;241m.\u001b[39maddNameExpression(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptr, ker)\n\u001b[0;32m--> 689\u001b[0m \u001b[43mnvrtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompileProgram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32mcupy_backends/cuda/libs/nvrtc.pyx:159\u001b[0m, in \u001b[0;36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy_backends/cuda/libs/nvrtc.pyx:171\u001b[0m, in \u001b[0;36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy_backends/cuda/libs/nvrtc.pyx:89\u001b[0m, in \u001b[0;36mcupy_backends.cuda.libs.nvrtc.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mNVRTCError\u001b[0m: NVRTC_ERROR_COMPILATION (6)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mCompileException\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m histogram_elw( d_data, n_bins, min_x, max_x, d_bins_data_elw, block_size\u001b[38;5;241m=\u001b[39mn_threads )\n\u001b[1;32m     28\u001b[0m histogram_raw_shd(    (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),(n_threads,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), (d_data, d_bins_data_shd, n_bins, min_x, max_x, d_data\u001b[38;5;241m.\u001b[39msize), shared_mem\u001b[38;5;241m=\u001b[39msmem)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mhistogram_raw_shd_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43md_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_bins_data_shd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m histogram_np,_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(h_data, n_bins, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m (d_bins_data_jit\u001b[38;5;241m.\u001b[39mget())\n","File \u001b[0;32mcupy/_core/raw.pyx:89\u001b[0m, in \u001b[0;36mcupy._core.raw.RawKernel.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy/_core/raw.pyx:96\u001b[0m, in \u001b[0;36mcupy._core.raw.RawKernel.kernel.__get__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy/_core/raw.pyx:113\u001b[0m, in \u001b[0;36mcupy._core.raw.RawKernel._kernel\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy/_util.pyx:64\u001b[0m, in \u001b[0;36mcupy._util.memoize.decorator.ret\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy/_core/raw.pyx:536\u001b[0m, in \u001b[0;36mcupy._core.raw._get_raw_module\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy/_core/core.pyx:2188\u001b[0m, in \u001b[0;36mcupy._core.core.compile_with_cache\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mcupy/_core/core.pyx:2251\u001b[0m, in \u001b[0;36mcupy._core.core.compile_with_cache\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cupy/cuda/compiler.py:496\u001b[0m, in \u001b[0;36m_compile_module_with_cache\u001b[0;34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, jitify)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile_with_cache_hip(\n\u001b[1;32m    493\u001b[0m         source, options, arch, cache_dir, extra_source, backend,\n\u001b[1;32m    494\u001b[0m         name_expressions, log_stream, cache_in_memory)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_with_cache_cuda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_cooperative_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cupy/cuda/compiler.py:574\u001b[0m, in \u001b[0;36m_compile_with_cache_cuda\u001b[0;34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, cache_in_memory, jitify)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnvrtc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    573\u001b[0m     cu_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_in_memory \u001b[38;5;28;01melse\u001b[39;00m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.cu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 574\u001b[0m     ptx, mapping \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_using_nvrtc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_cudadevrt_needed(options):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;66;03m# for separate compilation\u001b[39;00m\n\u001b[1;32m    579\u001b[0m         ls \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mLinkState()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cupy/cuda/compiler.py:322\u001b[0m, in \u001b[0;36mcompile_using_nvrtc\u001b[0;34m(source, options, arch, filename, name_expressions, log_stream, cache_in_memory, jitify)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cu_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m cu_file:\n\u001b[1;32m    320\u001b[0m             cu_file\u001b[38;5;241m.\u001b[39mwrite(source)\n\u001b[0;32m--> 322\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     cu_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jitify \u001b[38;5;28;01melse\u001b[39;00m filename\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cupy/cuda/compiler.py:306\u001b[0m, in \u001b[0;36mcompile_using_nvrtc.<locals>._compile\u001b[0;34m(source, options, cu_path, name_expressions, log_stream, jitify)\u001b[0m\n\u001b[1;32m    303\u001b[0m prog \u001b[38;5;241m=\u001b[39m _NVRTCProgram(source, cu_path, headers, include_names,\n\u001b[1;32m    304\u001b[0m                      name_expressions\u001b[38;5;241m=\u001b[39mname_expressions, method\u001b[38;5;241m=\u001b[39mmethod)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     compiled_obj, mapping \u001b[38;5;241m=\u001b[39m \u001b[43mprog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CompileException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    308\u001b[0m     dump \u001b[38;5;241m=\u001b[39m _get_bool_env_variable(\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUPY_DUMP_CUDA_SOURCE_ON_ERROR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cupy/cuda/compiler.py:708\u001b[0m, in \u001b[0;36m_NVRTCProgram.compile\u001b[0;34m(self, options, log_stream)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m nvrtc\u001b[38;5;241m.\u001b[39mNVRTCError:\n\u001b[1;32m    707\u001b[0m     log \u001b[38;5;241m=\u001b[39m nvrtc\u001b[38;5;241m.\u001b[39mgetProgramLog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptr)\n\u001b[0;32m--> 708\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CompileException(log, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, options,\n\u001b[1;32m    709\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnvrtc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runtime\u001b[38;5;241m.\u001b[39mis_hip \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiprtc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mCompileException\u001b[0m: /tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(2): error: explicit type is missing (\"int\" assumed)\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(2): error: A namespace scope variable without memory space annotations (__device__/__constant__/__shared__/__managed__) is considered a host variable, and host variables are not allowed in JIT mode. Consider using -default-device flag to process unannotated namespace scope variables as __device__ variables in JIT mode\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(3): error: expected a \";\"\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(23): warning #607-D: this pragma must immediately precede a statement\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(26): warning #12-D: parsing restarts here after previous syntax error\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(27): error: this declaration has no storage class or type specifier\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(27): error: A namespace scope variable without memory space annotations (__device__/__constant__/__shared__/__managed__) is considered a host variable, and host variables are not allowed in JIT mode. Consider using -default-device flag to process unannotated namespace scope variables as __device__ variables in JIT mode\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(27): error: identifier \"n_bins\" is undefined\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: this declaration has no storage class or type specifier\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: declaration is incompatible with overloaded function \"atomicAdd\"\n__nv_nvrtc_builtin_header.h(23837): here\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: A namespace scope variable without memory space annotations (__device__/__constant__/__shared__/__managed__) is considered a host variable, and host variables are not allowed in JIT mode. Consider using -default-device flag to process unannotated namespace scope variables as __device__ variables in JIT mode\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: identifier \"temp\" is undefined\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: too many initializer values\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(29): error: expected a declaration\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(32): error: expected a declaration\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(35): warning #12-D: parsing restarts here after previous syntax error\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(38): error: expected a declaration\n\n14 errors detected in the compilation of \"/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu\".\n"],"ename":"CompileException","evalue":"/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(2): error: explicit type is missing (\"int\" assumed)\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(2): error: A namespace scope variable without memory space annotations (__device__/__constant__/__shared__/__managed__) is considered a host variable, and host variables are not allowed in JIT mode. Consider using -default-device flag to process unannotated namespace scope variables as __device__ variables in JIT mode\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(3): error: expected a \";\"\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(23): warning #607-D: this pragma must immediately precede a statement\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(26): warning #12-D: parsing restarts here after previous syntax error\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(27): error: this declaration has no storage class or type specifier\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(27): error: A namespace scope variable without memory space annotations (__device__/__constant__/__shared__/__managed__) is considered a host variable, and host variables are not allowed in JIT mode. Consider using -default-device flag to process unannotated namespace scope variables as __device__ variables in JIT mode\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(27): error: identifier \"n_bins\" is undefined\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: this declaration has no storage class or type specifier\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: declaration is incompatible with overloaded function \"atomicAdd\"\n__nv_nvrtc_builtin_header.h(23837): here\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: A namespace scope variable without memory space annotations (__device__/__constant__/__shared__/__managed__) is considered a host variable, and host variables are not allowed in JIT mode. Consider using -default-device flag to process unannotated namespace scope variables as __device__ variables in JIT mode\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: identifier \"temp\" is undefined\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(28): error: too many initializer values\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(29): error: expected a declaration\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(32): error: expected a declaration\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(35): warning #12-D: parsing restarts here after previous syntax error\n\n/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu(38): error: expected a declaration\n\n14 errors detected in the compilation of \"/tmp/tmpnpwvcjyg/dff524cf4882c6c04459d7c9b52c25b3428a38a8.cubin.cu\".\n","output_type":"error"}]},{"cell_type":"code","source":"print (histogram_jit.cached_code)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T17:42:36.273978Z","iopub.execute_input":"2023-12-11T17:42:36.274738Z","iopub.status.idle":"2023-12-11T17:42:36.279553Z","shell.execute_reply.started":"2023-12-11T17:42:36.274703Z","shell.execute_reply":"2023-12-11T17:42:36.278603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy histogram counts from device to the host\nh_bins_data_jit  = d_bins_data_jit.get()\nh_bins_data_raw  = d_bins_data_raw.get()\nh_bins_data_elw  = d_bins_data_elw.get()\nh_bins_data_shd  = d_bins_data_shd.get()\n\n# Print counts in each bin depending on the histogram realization\nprint ('JIT hist   counts per bin:', h_bins_data_jit)\nprint ('RAW hist   counts per bin:', h_bins_data_raw)\nprint ('ELW hist   counts per bin:', h_bins_data_elw)\nprint ('NPy hist   counts per bin:', histogram_np)\nprint ('EAW shared counts per bin:', h_bins_data_shd)\n\n# Compare the number of elements in the input data array and the sum across all bins. These numbers should be identical.\nprint ('Data.size={:d}, Sum(jit)={:d}'.format( d_data.size, np.sum(h_bins_data_jit) ))\nprint ('Data.size={:d}, Sum(raw)={:d}'.format( d_data.size, np.sum(h_bins_data_raw) ))\nprint ('Data.size={:d}, Sum(elw)={:d}'.format( d_data.size, np.sum(h_bins_data_elw) ))\nprint ('Data.size={:d}, Sum(npy)={:d}'.format( d_data.size, np.sum(histogram_np) ))\nprint ('Data.size={:d}, Sum(shd)={:d}'.format( d_data.size, np.sum(h_bins_data_shd) ))\n\npl.xlabel('Bin Number')\npl.ylabel('Number of counts')\npl.plot(h_bins_data_jit, lw=4, ls='-',  c='grey',  label='jit')\npl.plot(h_bins_data_raw, lw=2, ls='--', c='red',   label='raw')\npl.plot(h_bins_data_elw, lw=1, ls='-',  c='blue',  label='elw', marker='o', alpha=0.2)\npl.plot(h_bins_data_shd, lw=1, ls='-',  c='green',  label='shd', marker='s', alpha=0.2)\n#pl.plot(histogram_np,    lw=1, ls='-',  c='magenta',  label='npy', marker='t', alpha=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-12-11T17:42:45.831595Z","iopub.execute_input":"2023-12-11T17:42:45.832354Z","iopub.status.idle":"2023-12-11T17:42:46.136401Z","shell.execute_reply.started":"2023-12-11T17:42:45.832317Z","shell.execute_reply":"2023-12-11T17:42:46.135445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the execution times as a function of number of data\nto_microsec = 1000000\ntab_out = Table()\nfname   = 'tab_Ndata_vs_time.txt'\nfmts    = {'N_data' :  '%d',\n           't_jit_m':  '%.6f',\n           't_jit_s':  '%.6f',\n           't_raw_m':  '%.6f',\n           't_raw_s':  '%.6f',\n           't_shd_m':  '%.6f',\n           't_shd_s':  '%.6f',\n           't_elw_m':  '%.6f',\n           't_elw_s':  '%.6f',\n           't_npy_m':  '%.6f',\n           't_npy_s':  '%.6f',\n           't_cpy_m':  '%.6f',\n           't_cpy_s':  '%.6f'}\n\nn_bins = 10\n#n_data = 1024#2**20\nn_threads = 1024\nmax_x  = cp.float32(1.0)\nmin_x  = cp.float32(0.0)\n\nsmem  = n_bins * cp.dtype(cp.int32).itemsize\n\ndatas = [pow(10,1),pow(10,2),pow(10,3),pow(10,4),pow(10,5),pow(10,6),pow(10,7)]\nt_jit_m, t_raw_m, t_elw_m, t_npy_m, t_cpy_m, t_shd_m = [],[],[],[],[],[]\nt_jit_s, t_raw_s, t_elw_s, t_npy_s, t_cpy_s, t_shd_s = [],[],[],[],[],[]\n\nfor n_data in datas:\n  d_bins_data_jit = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_raw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_elw = cp.zeros(n_bins, dtype=cp.int32)\n\n  cp.random.seed(42)\n  d_data = cp.random.rand(n_data).astype(cp.float32)\n  np.random.seed(42)\n  h_data = np.random.rand(n_data).astype(np.float32)\n\n  exe_gpu_jit = benchmark( histogram_jit, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_jit, n_bins, min_x, max_x, d_data.size )), n_repeat=5000, n_warmup=100 )\n  exe_gpu_raw = benchmark( histogram_raw, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_raw, n_bins, min_x, max_x, d_data.size )), n_repeat=5000, n_warmup=100 )\n  exe_gpu_shd = benchmark( histogram_raw_shd, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_raw, n_bins, min_x, max_x, d_data.size )), kwargs={'shared_mem':smem}, n_repeat=5000, n_warmup=100 )\n  exe_gpu_elw = benchmark( histogram_elw, args=((d_data, n_bins, min_x, max_x, d_bins_data_elw)), kwargs={'block_size':n_threads},   n_repeat=5000, n_warmup=100 )\n  exe_gpu_npy = benchmark( np.histogram,  args=((h_data, n_bins, (min_x, max_x))),   n_repeat=5000, n_warmup=100 )\n  exe_gpu_cpy = benchmark( cp.histogram,  args=((d_data, n_bins, (min_x, max_x))),   n_repeat=5000, n_warmup=100 )\n  \n  m_jit, s_jit = np.average(exe_gpu_jit.gpu_times), np.std(exe_gpu_jit.gpu_times)\n  m_raw, s_raw = np.average(exe_gpu_raw.gpu_times), np.std(exe_gpu_raw.gpu_times)\n  m_shd, s_shd = np.average(exe_gpu_shd.gpu_times), np.std(exe_gpu_shd.gpu_times)\n  m_elw, s_elw = np.average(exe_gpu_elw.gpu_times), np.std(exe_gpu_elw.gpu_times)\n  m_npy, s_npy = np.average(exe_gpu_npy.cpu_times), np.std(exe_gpu_npy.cpu_times)\n  m_cpy, s_cpy = np.average(exe_gpu_cpy.gpu_times), np.std(exe_gpu_npy.gpu_times)\n    \n  #print ('GPU performance:')\n  print ('N_data = {:d}'.format(n_data))\n  print ('Jit version:        t={:.6f}+/-{:.6f} us'.format(m_jit*to_microsec, s_jit*to_microsec))\n  print ('Raw version:        t={:.6f}+/-{:.6f} us'.format(m_raw*to_microsec, s_raw*to_microsec))\n  print ('ELW version:        t={:.6f}+/-{:.6f} us'.format(m_elw*to_microsec, s_elw*to_microsec))\n  print ('RAW shared version: t={:.6f}+/-{:.6f} us'.format(m_shd*to_microsec, s_shd*to_microsec))\n  print ('NPY version:        t={:.6f}+/-{:.6f} us'.format(m_npy*to_microsec, s_npy*to_microsec))\n  print ('CPY version:        t={:.6f}+/-{:.6f} us'.format(m_cpy*to_microsec, s_cpy*to_microsec))\n\n  d_bins_data_jit = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_raw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_elw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_shd = cp.zeros(n_bins, dtype=cp.int32)\n\n  t_jit_m.append(m_jit*to_microsec)\n  t_jit_s.append(s_jit*to_microsec)\n\n  t_raw_m.append(m_raw*to_microsec)\n  t_raw_s.append(s_raw*to_microsec)\n\n  t_shd_m.append(m_shd*to_microsec)\n  t_shd_s.append(s_shd*to_microsec)\n    \n  t_elw_m.append(m_elw*to_microsec)\n  t_elw_s.append(s_elw*to_microsec)\n    \n  t_npy_m.append(m_npy*to_microsec)\n  t_npy_s.append(s_npy*to_microsec)\n\n  t_cpy_m.append(m_cpy*to_microsec)\n  t_cpy_s.append(s_cpy*to_microsec)\n    \ntab_out['N_data']  = datas\n\n# JIT kernel GPU(!) mean and st.dev. times in [ms]\ntab_out['t_jit_m'] = t_jit_m\ntab_out['t_jit_s'] = t_jit_s\n# RAW kernel GPU(!) mean and st.dev. times in [ms]\ntab_out['t_raw_m'] = t_raw_m\ntab_out['t_raw_s'] = t_raw_s\n# RAW kernel GPU(!), shared memory, mean and st.dev times in [ms]\ntab_out['t_shd_m'] = t_shd_m\ntab_out['t_shd_s'] = t_shd_s\n# ElementWise kernel GPU(!) mean and st.dev. times in [ms]\ntab_out['t_elw_m'] = t_elw_m\ntab_out['t_elw_s'] = t_elw_s\n# NumPy CPU(!) mean and st.dev. times in [ms]\ntab_out['t_npy_m'] = t_npy_m\ntab_out['t_npy_s'] = t_npy_s\n# CuPy GPU(!) mean and st.dev. times in [ms]\ntab_out['t_cpy_m'] = t_cpy_m\ntab_out['t_cpy_s'] = t_cpy_s\n\ntab_out.write( fname, format='ascii.fixed_width', formats=fmts, bookend=False, delimiter=None, overwrite=True )","metadata":{"execution":{"iopub.status.busy":"2023-12-11T17:50:25.998366Z","iopub.execute_input":"2023-12-11T17:50:25.998733Z","iopub.status.idle":"2023-12-11T18:06:19.080357Z","shell.execute_reply.started":"2023-12-11T17:50:25.998706Z","shell.execute_reply":"2023-12-11T18:06:19.079431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the execution times as a function of number of bins\nto_microsec = 1000000\ntab_out = Table()\nfname   = 'tab_Nbins_vs_time.txt'\nfmts    = {'N_bins':  '%d',\n           't_jit_m':    '%.6f',\n           't_jit_s':    '%.6f',\n           't_raw_m':    '%.6f',\n           't_raw_s':    '%.6f',\n           't_shd_m':    '%.6f',\n           't_shd_s':    '%.6f',\n           't_elw_m':    '%.6f',\n           't_elw_s':    '%.6f'}\n\nn_data    = pow(10,5)\nn_threads = 1024\nmax_x  = cp.float32(1.0)\nmin_x  = cp.float32(0.0)\ncp.random.seed(42)\nd_data = cp.random.rand(n_data).astype(cp.float32)\n\nn_bins_all = [2,4,8,10,16,32,64,128,256]\nt_jit_m, t_raw_m, t_elw_m, t_shd_m = [],[],[],[]\nt_jit_s, t_raw_s, t_elw_s, t_shd_s = [],[],[],[]\n\nprint ('Compare execution time of CuPy kernels for different number of histogram bins')\nprint ('N_data = {:d}'.format(n_data))\n\nfor n_bins in n_bins_all:\n  exe_gpu_jit = benchmark( histogram_jit,     ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_jit, n_bins, min_x, max_x, d_data.size )),  n_repeat=5000, n_warmup=100 )\n  exe_gpu_raw = benchmark( histogram_raw,     ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_raw, n_bins, min_x, max_x, d_data.size )), n_repeat=5000, n_warmup=100 )\n  exe_gpu_shd = benchmark( histogram_raw_shd, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_shd, n_bins, min_x, max_x, d_data.size )), kwargs={'shared_mem':n_bins * cp.dtype(cp.int32).itemsize}, n_repeat=5000, n_warmup=100 )\n  exe_gpu_elw = benchmark( histogram_elw, args=((d_data, n_bins, min_x, max_x, d_bins_data_elw)), kwargs={'block_size':n_threads},    n_repeat=5000, n_warmup=100 )\n  \n  m_jit, s_jit = np.average(exe_gpu_jit.gpu_times), np.std(exe_gpu_jit.gpu_times)\n  m_raw, s_raw = np.average(exe_gpu_raw.gpu_times), np.std(exe_gpu_raw.gpu_times)\n  m_elw, s_elw = np.average(exe_gpu_elw.gpu_times), np.std(exe_gpu_elw.gpu_times)\n  m_shd, s_shd = np.average(exe_gpu_shd.gpu_times), np.std(exe_gpu_shd.gpu_times)\n\n  print ('N_bins = {:d}'.format(n_bins))\n  print ('Jit version:        t={:.6f}+/-{:.6f} us'.format(m_jit*to_microsec, s_jit*to_microsec))\n  print ('Raw version:        t={:.6f}+/-{:.6f} us'.format(m_raw*to_microsec, s_raw*to_microsec))\n  print ('ELW version:        t={:.6f}+/-{:.6f} us'.format(m_elw*to_microsec, s_elw*to_microsec))\n  print ('RAW shared version: t={:.6f}+/-{:.6f} us'.format(m_shd*to_microsec, s_shd*to_microsec))\n\n  d_bins_data_jit = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_raw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_elw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_shd = cp.zeros(n_bins, dtype=cp.int32)\n \n  t_jit_m.append(m_jit*to_microsec)\n  t_jit_s.append(s_jit*to_microsec)\n\n  t_raw_m.append(m_raw*to_microsec)\n  t_raw_s.append(s_raw*to_microsec)\n\n  t_elw_m.append(m_elw*to_microsec)\n  t_elw_s.append(s_elw*to_microsec)\n\n  t_shd_m.append(m_shd*to_microsec)\n  t_shd_s.append(s_shd*to_microsec)\n\ntab_out['N_bins']  = n_bins_all\ntab_out['t_jit_m'] = t_jit_m\ntab_out['t_jit_s'] = t_jit_s\n\ntab_out['t_raw_m'] = t_raw_m\ntab_out['t_raw_s'] = t_raw_s\n\ntab_out['t_elw_m'] = t_elw_m\ntab_out['t_elw_s'] = t_elw_s\n\ntab_out['t_shd_m'] = t_shd_m\ntab_out['t_shd_s'] = t_shd_s\n\ntab_out.write( fname, format='ascii.fixed_width', formats=fmts, bookend=False, delimiter=None, overwrite=True )","metadata":{"execution":{"iopub.status.busy":"2023-12-11T18:08:06.429072Z","iopub.execute_input":"2023-12-11T18:08:06.429561Z","iopub.status.idle":"2023-12-11T18:08:22.635374Z","shell.execute_reply.started":"2023-12-11T18:08:06.429528Z","shell.execute_reply":"2023-12-11T18:08:22.634473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the execution times as a function of number of threads\nto_microsec = 1000000\ntab_out = Table()\nfname   = 'tab_Nthreads_vs_time.txt'\nfmts    = {'N_threads':  '%d',\n           't_jit_m':    '%.6f',\n           't_jit_s':    '%.6f',\n           't_raw_m':    '%.6f',\n           't_raw_s':    '%.6f',\n           't_shd_m':    '%.6f',\n           't_shd_s':    '%.6f',\n           't_elw_m':    '%.6f',\n           't_elw_s':    '%.6f'}\n\n\nn_bins = 10\nn_data = pow(10,4)\nmax_x  = cp.float32(1.0)\nmin_x  = cp.float32(0.0)\ncp.random.seed(42)\nd_data = cp.random.rand(n_data).astype(cp.float32)\n\nsmem = n_bins * cp.dtype(cp.int32).itemsize\n\nn_threads_all = [16,32,64,128,256,512,1024]\nt_jit_m, t_raw_m, t_elw_m, t_shd_m = [],[],[],[]\nt_jit_s, t_raw_s, t_elw_s, t_shd_s = [],[],[],[]\n\nprint ('Compare execution time of CuPy kernels for different number of threads')\nprint ('N_data = {:d}'.format(n_data))\n\nfor n_threads in n_threads_all:\n  exe_gpu_jit = benchmark( histogram_jit, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_jit, n_bins, min_x, max_x, d_data.size )),  n_repeat=5000, n_warmup=100 )\n  exe_gpu_raw = benchmark( histogram_raw, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_raw, n_bins, min_x, max_x, d_data.size  )), n_repeat=5000, n_warmup=100 )\n  exe_gpu_shd = benchmark( histogram_raw_shd, ((1,1,1), (n_threads,1,1), (d_data, d_bins_data_shd, n_bins, min_x, max_x, d_data.size )), kwargs={'shared_mem':smem}, n_repeat=5000, n_warmup=100 )\n  exe_gpu_elw = benchmark( histogram_elw, args=((d_data, n_bins, min_x, max_x, d_bins_data_elw)), kwargs={'block_size':n_threads},    n_repeat=5000, n_warmup=100 )\n  \n  m_jit, s_jit = np.average(exe_gpu_jit.gpu_times), np.std(exe_gpu_jit.gpu_times)\n  m_raw, s_raw = np.average(exe_gpu_raw.gpu_times), np.std(exe_gpu_raw.gpu_times)\n  m_elw, s_elw = np.average(exe_gpu_elw.gpu_times), np.std(exe_gpu_elw.gpu_times)\n  m_shd, s_shd = np.average(exe_gpu_shd.gpu_times), np.std(exe_gpu_shd.gpu_times)\n\n  print ('N_threads = {:d}'.format(n_threads))\n  print ('Jit version:        t={:.6f}+/-{:.6f} us'.format(m_jit*to_microsec, s_jit*to_microsec))\n  print ('Raw version:        t={:.6f}+/-{:.6f} us'.format(m_raw*to_microsec, s_raw*to_microsec))\n  print ('ELW version:        t={:.6f}+/-{:.6f} us'.format(m_elw*to_microsec, s_elw*to_microsec))\n  print ('RAW shared version: t={:.6f}+/-{:.6f} us'.format(m_shd*to_microsec, s_shd*to_microsec))\n\n  d_bins_data_jit = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_raw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_elw = cp.zeros(n_bins, dtype=cp.int32)\n  d_bins_data_shd = cp.zeros(n_bins, dtype=cp.int32)\n \n  t_jit_m.append(m_jit*to_microsec)\n  t_jit_s.append(s_jit*to_microsec)\n\n  t_raw_m.append(m_raw*to_microsec)\n  t_raw_s.append(s_raw*to_microsec)\n\n  t_elw_m.append(m_elw*to_microsec)\n  t_elw_s.append(s_elw*to_microsec)\n    \n  t_shd_m.append(m_shd*to_microsec)\n  t_shd_s.append(s_shd*to_microsec)\n    \ntab_out['N_threads']  = n_threads_all\ntab_out['t_jit_m'] = t_jit_m\ntab_out['t_jit_s'] = t_jit_s\n\ntab_out['t_raw_m'] = t_raw_m\ntab_out['t_raw_s'] = t_raw_s\n\ntab_out['t_elw_m'] = t_elw_m\ntab_out['t_elw_s'] = t_elw_s\n\ntab_out['t_shd_m'] = t_shd_m\ntab_out['t_shd_s'] = t_shd_s\n\ntab_out.write( fname, format='ascii.fixed_width', formats=fmts, bookend=False, delimiter=None, overwrite=True )","metadata":{"execution":{"iopub.status.busy":"2023-12-11T18:08:59.503974Z","iopub.execute_input":"2023-12-11T18:08:59.504903Z","iopub.status.idle":"2023-12-11T18:09:11.270035Z","shell.execute_reply.started":"2023-12-11T18:08:59.504865Z","shell.execute_reply":"2023-12-11T18:09:11.269046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}