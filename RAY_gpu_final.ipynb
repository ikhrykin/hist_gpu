{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "71aa80b5",
      "metadata": {
        "id": "71aa80b5"
      },
      "source": [
        "# Сложение двух векторов на ГПУ с помощью RAY.\n",
        "### Размер, кол-во гпу и тп задается в коде."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab6cd1a5",
      "metadata": {
        "id": "ab6cd1a5",
        "outputId": "07fd7302-ce1b-48dc-9632-3a3397a3743e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-13 17:28:38,113\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Import done, Hello\n"
          ]
        }
      ],
      "source": [
        "# Library and frameworks import\n",
        "\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "import ray\n",
        "import os\n",
        "from scipy.stats import trim_mean\n",
        "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
        "print(\"Import done, Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f2b51f",
      "metadata": {
        "id": "34f2b51f",
        "outputId": "55e4d65a-a1cd-42b1-f987-2b10d55835fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Dec 13 17:28:39 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:51:00.0 Off |                    0 |\n",
            "| N/A   30C    P0    69W / 400W |   3499MiB / 81920MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA A100-SXM...  Off  | 00000000:57:00.0 Off |                    0 |\n",
            "| N/A   32C    P0    59W / 400W |      2MiB / 81920MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A   3859085      C   ...ython/3.9.7/bin/python3.9     3493MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241b1191",
      "metadata": {
        "id": "241b1191"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Задача. Есть 2 случайных вектора размера N. Мы их разбиваем на подвектора 'subvectors'\n",
        "\n",
        "Пример:\n",
        "num_subvectors = 2\n",
        "v1 = [0,1,2,3], v2 = [5, 6, 7, 8] -->\n",
        "subv1 = [[0,1], [2, 3]], subv2 = [[5, 6], [7, 8]]\n",
        "\n",
        "Функция RAY принимает на вход 2 вектора и складывает их.\n",
        "\n",
        "Вызываем функцию RAY для сложения одновременно всех подвекторов.\n",
        "\"\"\"\n",
        "num_subvectors = 4 # nubmer of subvectors\n",
        "num_gpus = 1 # number of gpus in system physically\n",
        "num_cpus = 36 # number of cpus in system physically\n",
        "num_gpus_per_worker = num_gpus/num_subvectors # How much resources will one worker use from GPU in fraction\n",
        "                                              # without blocking the other part\n",
        "\n",
        "N = 1 * 10**8 #size of arrays\n",
        "large_vector1 = np.random.rand(N)\n",
        "large_vector2 = np.random.rand(N)\n",
        "\n",
        "sub_vectors = np.array_split(large_vector1, num_subvectors) # This is list of lists sizez of\n",
        "sub_vectors2 = np.array_split(large_vector2, num_subvectors) # (num_subvectors, N/subvectors)\n",
        "\n",
        "repeat = 100 # Code repeats 100 times to gain statistics\n",
        "cut_off = 0.1 # To calculate the mean value of time estimation 10% of array will be cut from both sides (trim_mean)\n",
        "\n",
        "@ray.remote(num_gpus=num_gpus_per_worker) # Here we say that one worker will use only 'num_gpus_per_worker' resours\n",
        "def add_vectors_on_gpu(vector_a, vector_b):\n",
        "    \"\"\"\n",
        "    This func get 2 vectors and add them with time estimation by repeating \"repeat\" times\n",
        "    Return the summation vector result, averages of timing\n",
        "    \"\"\"\n",
        "    # array to contain time estimation to gain statistics\n",
        "    copy_time = [] # time to copy from Host to Device (H2D)\n",
        "    calc_time = [] # H2D + add 2 vecs calc time (CALC)\n",
        "    back_time = [] # H2D + CALC + time to copy back from Device to Host (D2H)\n",
        "    #cpu_time = [] # time measure with time.time() CPU method - only for comparison\n",
        "\n",
        "    for i in range(repeat):\n",
        "\n",
        "        # Setting start time points\n",
        "\n",
        "        start_gpu_time = time.time()\n",
        "        start_event = cp.cuda.Event()\n",
        "        end_event_1 = cp.cuda.Event()\n",
        "        end_event_2 = cp.cuda.Event()\n",
        "        end_event_3 = cp.cuda.Event()\n",
        "\n",
        "        # H2D procedure and timing\n",
        "\n",
        "        start_event.record()\n",
        "        gpu_vector_a = cp.asarray(vector_a)\n",
        "        gpu_vector_b = cp.asarray(vector_b)\n",
        "        end_event_1.record()\n",
        "        end_event_1.synchronize()\n",
        "\n",
        "        # Calculation procedure and H2D + CALC timing\n",
        "\n",
        "        result = cp.add(gpu_vector_a, gpu_vector_b)\n",
        "        end_event_2.record()\n",
        "        end_event_2.synchronize()\n",
        "\n",
        "        # D2H procedure and H2D + CALC + D2H timing\n",
        "        res = cp.asnumpy(result)\n",
        "        end_event_3.record()\n",
        "        end_event_3.synchronize()\n",
        "\n",
        "\n",
        "        # Time data collection\n",
        "        copy_time.append(cp.cuda.get_elapsed_time(start_event, end_event_1))\n",
        "        calc_time.append(cp.cuda.get_elapsed_time(start_event, end_event_2))\n",
        "        back_time.append(cp.cuda.get_elapsed_time(start_event, end_event_3))# Время в миллисекундах\n",
        "\n",
        "        end_gpu_time = time.time()\n",
        "\n",
        "    # After all repeats, calculate trim mean of each timing\n",
        "    append_time = end_gpu_time - start_gpu_time\n",
        "    avg_copy = trim_mean(copy_time, cut_off)\n",
        "    avg_calc = trim_mean(calc_time, cut_off)\n",
        "    avg_back = trim_mean(back_time, cut_off)\n",
        "\n",
        "    return res, avg_copy, avg_calc, avg_back, append_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9519a1cb",
      "metadata": {
        "id": "9519a1cb",
        "outputId": "e38df62e-dd73-4ae7-880b-35a15b684a1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-13 17:35:10,585\tINFO worker.py:1621 -- Started a local Ray instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initiation done\n",
            "total time = 18415.777921676636 ms\n",
            "time elapsed from CPU for 1 loop: 184.15777921676636 ms\n"
          ]
        }
      ],
      "source": [
        "# Starting Ray instance\n",
        "ray.init(num_cpus=num_cpus, num_gpus=num_gpus, include_dashboard=False, ignore_reinit_error=True)\n",
        "print(\"Initiation done\")\n",
        "\n",
        "start = time.time() # CPU time estimation\n",
        "\n",
        "# This thing makes the same like :\n",
        "# results = []\n",
        "# for i in range(num_subvectors):\n",
        "#     buf = add_vectors_on_gpu.remote(sub_vectors[i][:], sub_vetors2[i][:])\n",
        "#     results.append(buf)\n",
        "\n",
        "results = [add_vectors_on_gpu.remote(sub_v1, sub_v2) for sub_v1, sub_v2 in zip(sub_vectors, sub_vectors2)]\n",
        "final_results = ray.get(results)\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "ray.shutdown()\n",
        "\n",
        "print(f\"total time = {(end - start)*1000} ms\")\n",
        "print(f\"time elapsed from CPU for 1 loop: {(end - start)*1000/repeat} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1cbd1a3",
      "metadata": {
        "id": "e1cbd1a3"
      },
      "outputs": [],
      "source": [
        "#post production\n",
        "final_result = np.concatenate([result[0] for result in final_results])\n",
        "copy_time = np.array([res[1] for res in final_results])\n",
        "calc_time = np.array([res[2] for res in final_results])\n",
        "back_time = np.array([res[3] for res in final_results])\n",
        "append_time = np.array([res[4] for res in final_results])\n",
        "# this thing make right time in rigth place\n",
        "back_time = back_time - calc_time\n",
        "calc_time = calc_time - copy_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe62373",
      "metadata": {
        "id": "3fe62373",
        "outputId": "8c1ffd0a-f54f-4c42-c552-c92136b20c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AVG TIMES are given per one device! If you want for each device remove np.mean()\n",
            "Copy straight avg time = 76.94807415008545 ms\n",
            "Calc avg time = 0.5758175849914551 ms\n",
            "Copy avg back time = 54.50511145591736 ms\n",
            "Total avg time = 132.02900319099427 ms\n",
            "append time = 128.00651788711548 ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "label = f\"\"\"AVG TIMES are given per one device! If you want for each device remove np.mean()\n",
        "Copy straight avg time = {np.mean(copy_time)} ms\n",
        "Calc avg time = {np.mean(calc_time) } ms\n",
        "Copy avg back time = {np.mean(back_time)} ms\n",
        "Total avg time = {np.mean(copy_time + calc_time + back_time)} ms\n",
        "append time = {np.mean(append_time*1000)} ms\n",
        "\"\"\"\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17cf470d",
      "metadata": {
        "id": "17cf470d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}