{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scalene"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZOPBB31h0-4",
        "outputId": "6da40f70-7cf3-4b6a-fd1d-0917fa11a5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scalene in /usr/local/lib/python3.10/dist-packages (1.5.33)\n",
            "Requirement already satisfied: wheel>=0.36.1 in /usr/local/lib/python3.10/dist-packages (from scalene) (0.42.0)\n",
            "Requirement already satisfied: rich>=10.7.0 in /usr/local/lib/python3.10/dist-packages (from scalene) (13.7.0)\n",
            "Requirement already satisfied: cloudpickle>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from scalene) (2.2.1)\n",
            "Requirement already satisfied: pynvml<11.5,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from scalene) (11.4.1)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from scalene) (3.1.3)\n",
            "Requirement already satisfied: psutil>=5.9.2 in /usr/local/lib/python3.10/dist-packages (from scalene) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0.3->scalene) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7.0->scalene) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7.0->scalene) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.7.0->scalene) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8S7YEuv7RSn",
        "outputId": "2c5e1350-aaac-4dc6-df23-4d26cf86cd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext scalene"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d6Tfdggh3Ad",
        "outputId": "8daf119a-ae7d-4333-e917-dec6acc8679a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scalene extension is already loaded. To reload it, use:\n",
            "  %reload_ext scalene\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S470JbdjhMap"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def torchtest():\n",
        "    dtype = torch.float\n",
        "    #device = torch.device(\"cpu\")\n",
        "    device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
        "    # device = torch.device(\"cuda\")  # Uncomment this to run on GPU\n",
        "\n",
        "    # Create Tensors to hold input and outputs.\n",
        "    # By default, requires_grad=False, which indicates that we do not need to\n",
        "    # compute gradients with respect to these Tensors during the backward pass.\n",
        "    # x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "    q = torch.linspace(-math.pi, math.pi, 5000000, device=device, dtype=dtype)\n",
        "    x = torch.linspace(-math.pi, math.pi, 5000000, device=device, dtype=dtype)\n",
        "    y = torch.sin(x)\n",
        "\n",
        "    # Create random Tensors for weights. For a third order polynomial, we need\n",
        "    # 4 weights: y = a + b x + c x^2 + d x^3\n",
        "    # Setting requires_grad=True indicates that we want to compute gradients with\n",
        "    # respect to these Tensors during the backward pass.\n",
        "    a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "    b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "    c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "    d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "    learning_rate = 1e-6\n",
        "    for t in range(2000):\n",
        "        # Forward pass: compute predicted y using operations on Tensors.\n",
        "        y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "        # Compute and print loss using operations on Tensors.\n",
        "        # Now loss is a Tensor of shape (1,)\n",
        "        # loss.item() gets the scalar value held in the loss.\n",
        "        #     loss = (y_pred - y).pow(2).sum()\n",
        "        loss = (y_pred - y).sum()\n",
        "        if t % 100 == 99:\n",
        "            print(t, loss.item())\n",
        "\n",
        "        # Use autograd to compute the backward pass. This call will compute the\n",
        "        # gradient of loss with respect to all Tensors with requires_grad=True.\n",
        "        # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
        "        # the gradient of the loss with respect to a, b, c, d respectively.\n",
        "        loss.backward()\n",
        "\n",
        "        # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
        "        # because weights have requires_grad=True, but we don't need to track this\n",
        "        # in autograd.\n",
        "        with torch.no_grad():\n",
        "            a -= learning_rate * a.grad\n",
        "            b -= learning_rate * b.grad\n",
        "            c -= learning_rate * c.grad\n",
        "            d -= learning_rate * d.grad\n",
        "\n",
        "            # Manually zero the gradients after updating weights\n",
        "            a.grad = None\n",
        "            b.grad = None\n",
        "            c.grad = None\n",
        "            d.grad = None\n",
        "\n",
        "    print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "id": "TzWN4CI7azT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%scrun --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "5PXz9KVcltop",
        "outputId": "1c850a76-61f4-49bf-e5f3-a945f3c2f884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCRUN MAGIC\n",
            "Scalene version 1.5.33 (2024.01.02)\n",
            "Scalene failed to initialize.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 1877, in run_profiler\n",
            "    Scalene.process_args(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 1797, in process_args\n",
            "    time.perf_counter() + Scalene.__args.profile_interval\n",
            "AttributeError: 'Namespace' object has no attribute 'profile_interval'\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "StopJupyterExecution",
          "evalue": "",
          "traceback": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%scrun torchtest()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKkpJPP_a4Qa",
        "outputId": "6ec5fc1c-70af-4a78-fe22-521a7ba59c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCRUN MAGIC\n",
            "99 -29278793728.0\n",
            "199 -58837041152.0\n",
            "299 -88395128832.0\n",
            "399 -117953019904.0\n",
            "499 -147510919168.0\n",
            "599 -177068802048.0\n",
            "699 -206626684928.0\n",
            "799 -236184584192.0\n",
            "899 -265742483456.0\n",
            "999 -295300399104.0\n",
            "1099 -324858281984.0\n",
            "1199 -354416164864.0\n",
            "1299 -383974080512.0\n",
            "1399 -413531963392.0\n",
            "1499 -443089879040.0\n",
            "1599 -472647761920.0\n",
            "1699 -502205644800.0\n",
            "1799 -531763560448.0\n",
            "1899 -561321476096.0\n",
            "1999 -590879326208.0\n",
            "Result: y = -9999.580078125 + 1.3090906143188477 x + -32899.6015625 x^2 + -0.2016664296388626 x^3\n",
            "\u001b[3m                          /content/_ipython-input-10-profile: % of time = 100.00% (5.278s) out of 5.278s.                          \u001b[0m\n",
            "       ╷       ╷       ╷       ╷       ╷                                                                                           \n",
            " \u001b[1m      \u001b[0m│\u001b[1;34mTime\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\u001b[1;34m––––––\u001b[0m\u001b[1m \u001b[0m│\u001b[1;34m––––––\u001b[0m\u001b[1m \u001b[0m│\u001b[1;33m––––––\u001b[0m\u001b[1m \u001b[0m│\u001b[1m                                                                                         \u001b[0m\u001b[1m \u001b[0m \n",
            " \u001b[1m \u001b[0m\u001b[1;2mLine\u001b[0m\u001b[1m \u001b[0m│\u001b[1;3;34mPython\u001b[0m\u001b[1m \u001b[0m│\u001b[1;3;34mnative\u001b[0m\u001b[1m \u001b[0m│\u001b[1;3;34msystem\u001b[0m\u001b[1m \u001b[0m│\u001b[1;3;33mGPU\u001b[0m\u001b[1m   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m/content/_ipython-input-10-profile                                                       \u001b[0m\u001b[1m \u001b[0m \n",
            "╺━━━━━━┿━━━━━━━┿━━━━━━━┿━━━━━━━┿━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸\n",
            " \u001b[2m \u001b[0m\u001b[2m   1\u001b[0m\u001b[2m \u001b[0m│\u001b[1;31m   40%\u001b[0m\u001b[34m \u001b[0m│\u001b[1;31m   24%\u001b[0m\u001b[34m \u001b[0m│\u001b[34m  36% \u001b[0m\u001b[34m \u001b[0m│\u001b[33m      \u001b[0m\u001b[33m \u001b[0m│\u001b[37;40mtorchtest\u001b[0m\u001b[37;40m(\u001b[0m\u001b[37;40m)\u001b[0m\u001b[40m                                                                              \u001b[0m  \n",
            "       ╵       ╵       ╵       ╵       ╵                                                                                           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "YgzZx8MkpeUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%scrun --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yy-NGPL33-9k",
        "outputId": "40385379-f735-463f-909c-2cf322de8532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "usage: scalene \u001b[1m[\u001b[0m-h\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--version\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--column-width COLUMN_WIDTH\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--outfile OUTFILE\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--html\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--json\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cli\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--web\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--viewer\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--reduced-profile\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--profile-interval PROFILE_INTERVAL\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cpu\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cpu-only\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--gpu\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--memory\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--profile-all\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--profile-only PROFILE_ONLY\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--profile-exclude PROFILE_EXCLUDE\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--use-virtual-time\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cpu-percent-threshold CPU_PERCENT_THRESHOLD\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--cpu-sampling-rate CPU_SAMPLING_RATE\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--allocation-sampling-window ALLOCATION_SAMPLING_WINDOW\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--malloc-threshold MALLOC_THRESHOLD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--program-path PROGRAM_PATH\u001b[1m]\u001b[0m\n",
              "               \u001b[1m[\u001b[0m--memory-leak-detector\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--on | --off\u001b[1m]\u001b[0m\n",
              "\n",
              "\u001b[1mScalene\u001b[0m: a high-precision CPU and memory profiler, version \u001b[1;36m1.5\u001b[0m.\u001b[1;36m19\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m2023.01\u001b[0m.\u001b[1;36m06\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b]8;id=235435;https://github.com/plasma-umass/scalene\u001b\\\u001b[4;94mhttps://github.com/plasma-umass/scalene\u001b[0m\u001b]8;;\u001b\\\n",
              "\n",
              "command-line:\n",
              "  % \u001b[1mscalene \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\u001b[1m your_program.py \u001b[0m\u001b[1m[\u001b[0m\u001b[1m--- --your_program_args\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\n",
              "or\n",
              "  % \u001b[1mpython3 -m scalene \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\u001b[1m your_program.py \u001b[0m\u001b[1m[\u001b[0m\u001b[1m--- --your_program_args\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              "in Jupyter, line mode:\n",
              "\u001b[1m  %scrun \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\u001b[1m statement\u001b[0m\n",
              "\n",
              "in Jupyter, cell mode:\n",
              "\u001b[1m  %%scalene \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[1m   your code here\u001b[0m\n",
              "\n",
              "\n",
              "options:\n",
              "  -h, --help            show this help message and exit\n",
              "  --version             prints the version number for this release of Scalene and exits\n",
              "  --column-width COLUMN_WIDTH\n",
              "                        Column width for profile output \u001b[1m(\u001b[0mdefault: \u001b[1;34m132\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --outfile OUTFILE     file to hold profiler output \u001b[1m(\u001b[0mdefault: \u001b[34mstdout\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --html                output as HTML \u001b[1m(\u001b[0mdefault: \u001b[34mweb\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --json                output as JSON \u001b[1m(\u001b[0mdefault: \u001b[34mweb\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --cli                 forces use of the command-line\n",
              "  --web                 opens a web tab to view the profile \u001b[1m(\u001b[0msaved as \u001b[32m'profile.html'\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --viewer              only opens the web UI \u001b[1m(\u001b[0m\u001b[4;94mhttps://plasma-umass.org/scalene-gui/\u001b[0m\u001b[4;94m)\u001b[0m\n",
              "  --reduced-profile     generate a reduced profile, with non-zero lines only \u001b[1m(\u001b[0mdefault: \u001b[3;34mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --profile-interval PROFILE_INTERVAL\n",
              "                        output profiles every so many seconds \u001b[1m(\u001b[0mdefault: \u001b[34minf\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --cpu                 profile CPU time \u001b[1m(\u001b[0mdefault: \u001b[34m \u001b[0m\u001b[3;34mTrue\u001b[0m\u001b[34m \u001b[0m\u001b[1m)\u001b[0m\n",
              "  --cpu-only            profile CPU time \u001b[1m(\u001b[0m\u001b[31mdeprecated: use --cpu \u001b[0m\u001b[1m)\u001b[0m\n",
              "  --gpu                 profile GPU time and memory \u001b[1m(\u001b[0mdefault: \u001b[3;34mTrue\u001b[0m\u001b[34m \u001b[0m\u001b[1m)\u001b[0m\n",
              "  --memory              profile memory \u001b[1m(\u001b[0mdefault: \u001b[3;34mTrue\u001b[0m\u001b[34m \u001b[0m\u001b[1m)\u001b[0m\n",
              "  --profile-all         profile all executed code, not just the target program \u001b[1m(\u001b[0mdefault: \u001b[34monly the target program\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --profile-only PROFILE_ONLY\n",
              "                        profile only code in filenames that contain the given strings, separated by commas \n",
              "\u001b[1m(\u001b[0mdefault: \u001b[34mno restrictions\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --profile-exclude PROFILE_EXCLUDE\n",
              "                        do not profile code in filenames that contain the given strings, separated by commas \n",
              "\u001b[1m(\u001b[0mdefault: \u001b[34mno restrictions\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --use-virtual-time    measure only CPU time, not time spent in I/O or blocking \u001b[1m(\u001b[0mdefault: \u001b[3;34mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --cpu-percent-threshold CPU_PERCENT_THRESHOLD\n",
              "                        only report profiles with at least this percent of CPU time \u001b[1m(\u001b[0mdefault: \u001b[1;34m1\u001b[0m\u001b[34m%\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --cpu-sampling-rate CPU_SAMPLING_RATE\n",
              "                        CPU sampling rate \u001b[1m(\u001b[0mdefault: every \u001b[1;34m0.\u001b[0m\u001b[34m01s\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --allocation-sampling-window ALLOCATION_SAMPLING_WINDOW\n",
              "                        Allocation sampling window size, in bytes \u001b[1m(\u001b[0mdefault: \u001b[1;34m10485767\u001b[0m\u001b[34m bytes\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --malloc-threshold MALLOC_THRESHOLD\n",
              "                        only report profiles with at least this many allocations \u001b[1m(\u001b[0mdefault: \u001b[1;34m100\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --program-path PROGRAM_PATH\n",
              "                        The directory containing the code to profile \u001b[1m(\u001b[0mdefault: \u001b[34mthe path to the profiled program\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --memory-leak-detector\n",
              "                        EXPERIMENTAL: report likely memory leaks \u001b[1m(\u001b[0mdefault: \u001b[3;34mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "  --on                  start with profiling on \u001b[1m(\u001b[0mdefault\u001b[1m)\u001b[0m\n",
              "  --off                 start with profiling off\n",
              "\n",
              "When running Scalene in the background, you can suspend/resume profiling\n",
              "for the process ID that Scalene reports. For example:\n",
              "\n",
              "   % python3 -m scalene  yourprogram.py &\n",
              " Scalene now profiling process \u001b[1;36m12345\u001b[0m\n",
              "   to suspend profiling: python3 -m scalene.profile --off --pid \u001b[1;36m12345\u001b[0m\n",
              "   to resume profiling:  python3 -m scalene.profile --on  --pid \u001b[1;36m12345\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">usage: scalene <span style=\"font-weight: bold\">[</span>-h<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--version<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--column-width COLUMN_WIDTH<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--outfile OUTFILE<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--html<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--json<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--cli<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--web<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--viewer<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--reduced-profile<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--profile-interval PROFILE_INTERVAL<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--cpu<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--cpu-only<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--gpu<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--memory<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--profile-all<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--profile-only PROFILE_ONLY<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--profile-exclude PROFILE_EXCLUDE<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--use-virtual-time<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--cpu-percent-threshold CPU_PERCENT_THRESHOLD<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--cpu-sampling-rate CPU_SAMPLING_RATE<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--allocation-sampling-window ALLOCATION_SAMPLING_WINDOW<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--malloc-threshold MALLOC_THRESHOLD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--program-path PROGRAM_PATH<span style=\"font-weight: bold\">]</span>\n",
              "               <span style=\"font-weight: bold\">[</span>--memory-leak-detector<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>--on | --off<span style=\"font-weight: bold\">]</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Scalene</span>: a high-precision CPU and memory profiler, version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023.01</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span><span style=\"font-weight: bold\">)</span>\n",
              "<a href=\"https://github.com/plasma-umass/scalene\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/plasma-umass/scalene</span></a>\n",
              "\n",
              "command-line:\n",
              "  % <span style=\"font-weight: bold\">scalene [options] your_program.py [--- --your_program_args] </span>\n",
              "or\n",
              "  % <span style=\"font-weight: bold\">python3 -m scalene [options] your_program.py [--- --your_program_args] </span>\n",
              "\n",
              "in Jupyter, line mode:\n",
              "<span style=\"font-weight: bold\">  %scrun [options] statement</span>\n",
              "\n",
              "in Jupyter, cell mode:\n",
              "<span style=\"font-weight: bold\">  %%scalene [options]</span>\n",
              "<span style=\"font-weight: bold\">   your code here</span>\n",
              "\n",
              "\n",
              "options:\n",
              "  -h, --help            show this help message and exit\n",
              "  --version             prints the version number for this release of Scalene and exits\n",
              "  --column-width COLUMN_WIDTH\n",
              "                        Column width for profile output <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">132</span><span style=\"font-weight: bold\">)</span>\n",
              "  --outfile OUTFILE     file to hold profiler output <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">stdout</span><span style=\"font-weight: bold\">)</span>\n",
              "  --html                output as HTML <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">web</span><span style=\"font-weight: bold\">)</span>\n",
              "  --json                output as JSON <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">web</span><span style=\"font-weight: bold\">)</span>\n",
              "  --cli                 forces use of the command-line\n",
              "  --web                 opens a web tab to view the profile <span style=\"font-weight: bold\">(</span>saved as <span style=\"color: #008000; text-decoration-color: #008000\">'profile.html'</span><span style=\"font-weight: bold\">)</span>\n",
              "  --viewer              only opens the web UI <span style=\"font-weight: bold\">(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://plasma-umass.org/scalene-gui/)</span>\n",
              "  --reduced-profile     generate a reduced profile, with non-zero lines only <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  --profile-interval PROFILE_INTERVAL\n",
              "                        output profiles every so many seconds <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">inf</span><span style=\"font-weight: bold\">)</span>\n",
              "  --cpu                 profile CPU time <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">True</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"font-weight: bold\">)</span>\n",
              "  --cpu-only            profile CPU time <span style=\"font-weight: bold\">(</span><span style=\"color: #800000; text-decoration-color: #800000\">deprecated: use --cpu </span><span style=\"font-weight: bold\">)</span>\n",
              "  --gpu                 profile GPU time and memory <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">True</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"font-weight: bold\">)</span>\n",
              "  --memory              profile memory <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">True</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"font-weight: bold\">)</span>\n",
              "  --profile-all         profile all executed code, not just the target program <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">only the target program</span><span style=\"font-weight: bold\">)</span>\n",
              "  --profile-only PROFILE_ONLY\n",
              "                        profile only code in filenames that contain the given strings, separated by commas \n",
              "<span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">no restrictions</span><span style=\"font-weight: bold\">)</span>\n",
              "  --profile-exclude PROFILE_EXCLUDE\n",
              "                        do not profile code in filenames that contain the given strings, separated by commas \n",
              "<span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">no restrictions</span><span style=\"font-weight: bold\">)</span>\n",
              "  --use-virtual-time    measure only CPU time, not time spent in I/O or blocking <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "  --cpu-percent-threshold CPU_PERCENT_THRESHOLD\n",
              "                        only report profiles with at least this percent of CPU time <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080\">%</span><span style=\"font-weight: bold\">)</span>\n",
              "  --cpu-sampling-rate CPU_SAMPLING_RATE\n",
              "                        CPU sampling rate <span style=\"font-weight: bold\">(</span>default: every <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0.</span><span style=\"color: #000080; text-decoration-color: #000080\">01s</span><span style=\"font-weight: bold\">)</span>\n",
              "  --allocation-sampling-window ALLOCATION_SAMPLING_WINDOW\n",
              "                        Allocation sampling window size, in bytes <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">10485767</span><span style=\"color: #000080; text-decoration-color: #000080\"> bytes</span><span style=\"font-weight: bold\">)</span>\n",
              "  --malloc-threshold MALLOC_THRESHOLD\n",
              "                        only report profiles with at least this many allocations <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">100</span><span style=\"font-weight: bold\">)</span>\n",
              "  --program-path PROGRAM_PATH\n",
              "                        The directory containing the code to profile <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080\">the path to the profiled program</span><span style=\"font-weight: bold\">)</span>\n",
              "  --memory-leak-detector\n",
              "                        EXPERIMENTAL: report likely memory leaks <span style=\"font-weight: bold\">(</span>default: <span style=\"color: #000080; text-decoration-color: #000080; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "  --on                  start with profiling on <span style=\"font-weight: bold\">(</span>default<span style=\"font-weight: bold\">)</span>\n",
              "  --off                 start with profiling off\n",
              "\n",
              "When running Scalene in the background, you can suspend/resume profiling\n",
              "for the process ID that Scalene reports. For example:\n",
              "\n",
              "   % python3 -m scalene  yourprogram.py &amp;\n",
              " Scalene now profiling process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12345</span>\n",
              "   to suspend profiling: python3 -m scalene.profile --off --pid <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12345</span>\n",
              "   to resume profiling:  python3 -m scalene.profile --on  --pid <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12345</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "StopJupyterExecution",
          "evalue": "",
          "traceback": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%scrun --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "MbJTMwKxxbSO",
        "outputId": "13d965ec-5d9f-42a3-a632-9b3b29c5eaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalene version 1.5.20 (2023.02.27)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "StopJupyterExecution",
          "evalue": "",
          "traceback": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "jQ3Ha2Nk_ToL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%scalene\n",
        "\n",
        "for i in range(1000):\n",
        "  b = np.array(range(1000))\n",
        "  a = np.array(np.random.uniform(0, 100, size=10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Snxk_J_GWE",
        "outputId": "0a3d7378-fa70-4326-9db1-edd3bec5b2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalene: An exception of type SyntaxError occurred. Arguments:\n",
            "('invalid syntax', ('<unknown>', 1, 1, '%%scalene\\n', 1, 2))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 2000, in run_profiler\n",
            "    exit_status = profiler.profile_code(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 1810, in profile_code\n",
            "    did_output = Scalene.output_profile()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 909, in output_profile\n",
            "    json_output = Scalene.__json.output_profiles(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_json.py\", line 380, in output_profiles\n",
            "    enclosing_regions = ScaleneAnalysis.find_regions(code_str)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_analysis.py\", line 45, in find_regions\n",
            "    tree = ast.parse(src)\n",
            "  File \"/usr/lib/python3.10/ast.py\", line 50, in parse\n",
            "    return compile(source, filename, mode, flags,\n",
            "  File \"<unknown>\", line 1\n",
            "    %%scalene\n",
            "    ^\n",
            "SyntaxError: invalid syntax\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%scalene --web --profile-all\n",
        "\n",
        "# Train an image classifier on CIFAR\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "print(device)\n",
        "\n",
        "# Load & normalize CIFAR\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print('Complete loading CIFAR')\n",
        "\n",
        "# Define a CNN\n",
        "\n",
        "net = Net().to(device)\n",
        "print(next(net.parameters()).device)\n",
        "\n",
        "# Define a loss fun & optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "print('Complete creating model, criterion & optimizer')\n",
        "\n",
        "# Train the net\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    print(f'epoch {epoch}')\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # print(f'i = {i}')\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            # print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the net\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "e42NXwrhhR_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98c1a18-d480-4e60-f77f-7e5b5dd371cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Complete loading CIFAR\n",
            "cuda:0\n",
            "Complete creating model, criterion & optimizer\n",
            "epoch 0\n",
            "epoch 1\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 54 %\n",
            "Scalene: An exception of type SyntaxError occurred. Arguments:\n",
            "('invalid syntax', ('<unknown>', 1, 1, '%%scalene --web --profile-all\\n', 1, 2))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 2000, in run_profiler\n",
            "    exit_status = profiler.profile_code(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 1810, in profile_code\n",
            "    did_output = Scalene.output_profile()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_profiler.py\", line 909, in output_profile\n",
            "    json_output = Scalene.__json.output_profiles(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_json.py\", line 380, in output_profiles\n",
            "    enclosing_regions = ScaleneAnalysis.find_regions(code_str)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scalene/scalene_analysis.py\", line 45, in find_regions\n",
            "    tree = ast.parse(src)\n",
            "  File \"/usr/lib/python3.10/ast.py\", line 50, in parse\n",
            "    return compile(source, filename, mode, flags,\n",
            "  File \"<unknown>\", line 1\n",
            "    %%scalene --web --profile-all\n",
            "    ^\n",
            "SyntaxError: invalid syntax\n",
            "\n"
          ]
        }
      ]
    }
  ]
}