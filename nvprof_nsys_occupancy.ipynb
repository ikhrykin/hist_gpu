{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hR4DTteiDXKg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJsm8qxkByZK"
      },
      "source": [
        "## CUDA Basic Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mFiaU4S9FJ2"
      },
      "source": [
        "##GPU Learn the basic steps of coding\n",
        "\n",
        "- CPU Memory Settings\n",
        "- CPU Memory data settings\n",
        "- GPU Memory Settings : cudaMalloc(...)\n",
        "- CPU --> GPU Data Transfer: cudaMemcpy(to, from, sizeofdata, cudaMemcpyHostToDevice)\n",
        "- GPU Functions (Kernel) Perform\n",
        "- GPU --> CPU Transfer operation result data: : cudaMemcpy(to, from, sizeofdata, cudaMemcpyDeviceToHost);\n",
        "- Use the result of the operation on the CPU\n",
        "\n",
        "*  *  *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_UOYChfF_jf"
      },
      "source": [
        "# Change the n value and look at the execution time and data delivery time through nvprof."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8oWrLbL9mut",
        "outputId": "f7a15667-d4e3-43e2-d78a-3534905f15f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile cudabasic.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "int *host_A, *host_C1, *host_C2;       // host data\n",
        "int *device_A, *device_C;              // results\n",
        "\n",
        "// execute on device\n",
        "__global__ void vecAddOne(int *A, int *C, int N)\n",
        "{\n",
        "   int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "   if( i < N )\n",
        "      C[i] = A[i] + 1;\n",
        "}\n",
        "\n",
        "// execute on host\n",
        "void vecAddOne_h(int *A1, int *C1, int N)\n",
        "{\n",
        "   for(int i = 0; i < N; i++)\n",
        "      C1[i] = A1[i] + 1;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "   int n = 1024 * 1024; // number of threads (elements)\n",
        "   int nBytes = n * sizeof(int);\n",
        "   int block_size = 32;\n",
        "   int block_number = n / block_size;\n",
        "\n",
        "   // ===============================================================\n",
        "   // CPU Memory settings\n",
        "\n",
        "  printf(\"Allocating memory on host.\\n\");\n",
        "\n",
        "   host_A = (int *) malloc(nBytes);\n",
        "   host_C1 = (int *) malloc(nBytes);\n",
        "   host_C2 = (int *) malloc(nBytes);\n",
        "\n",
        "   // ===============================================================\n",
        "\n",
        "   printf(\"Allocating memory on device.\\n\");\n",
        "\n",
        "   cudaMalloc((void **) &device_A, n * sizeof(int));\n",
        "   cudaMalloc((void **) &device_C, n * sizeof(int));\n",
        "\n",
        "   // ===============================================================\n",
        "\n",
        "   printf(\"Copying to device.\\n\");\n",
        "\n",
        "   cudaMemcpy(device_A, host_A, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "   // ===============================================================\n",
        "\n",
        "   printf(\"Doing GPU Vector + 1 \\n\");\n",
        "\n",
        "   vecAddOne<<<block_number, block_size>>>(device_A, device_C, n);\n",
        "   cudaDeviceSynchronize();\n",
        "\n",
        "   // ===============================================================\n",
        "\n",
        "   printf(\"Doing a CPU Vector add & Copy to host\\n\");\n",
        "\n",
        "   vecAddOne_h(host_A, host_C1, n);\n",
        "\n",
        "   cudaMemcpy(host_C2, device_C, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "   // Compare Results\n",
        "\n",
        "   printf(\"Compare Results\\n\");\n",
        "\n",
        "   for(int i = 0; i < n; i++)\n",
        "   {\n",
        "       if(host_C1[i] != host_C2[i])\n",
        "       {\n",
        "           printf(\"Something Wrong ! \\n\");\n",
        "           break;\n",
        "       }\n",
        "   }\n",
        "\n",
        "   printf(\"Free resources\");\n",
        "\n",
        "   cudaFree(device_A);\n",
        "   cudaFree(device_C);\n",
        "\n",
        "   free(host_A);\n",
        "   free(host_C1);\n",
        "   free(host_C2);\n",
        "\n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cudabasic.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulc4tfsuBHsO"
      },
      "source": [
        "!nvcc -o cudabasic cudabasic.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp12avb1BcWe",
        "outputId": "a2602f3a-f43d-4fd6-c1a8-d6a7d2dd8bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./cudabasic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocating memory on host.\n",
            "Allocating memory on device.\n",
            "Copying to device.\n",
            "Doing GPU Vector + 1 \n",
            "Doing a CPU Vector add & Copy to host\n",
            "Compare Results\n",
            "Free resources"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwC2L5UUGMtH"
      },
      "source": [
        "*  *  *\n",
        "## nvprof:\n",
        "\n",
        "It is a command-line profiler that can be used for\n",
        "- quick checks\n",
        "- profiling anything (no matter which language the CUDA kernel is written as long as it is launched using the CUDA runtime API or driver API)\n",
        "- remote profiling (connect to the remote machine, using `ssh`, for example, and run your application under `nvprof`)\n",
        "\n",
        "See also:\n",
        "\n",
        "- Official doc: https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof\n",
        "- https://devblogs.nvidia.com/cuda-pro-tip-nvprof-your-handy-universal-gpu-profiler/\n",
        "\n",
        "**NVIDIA Visual Profiler (NVVP) and NVIDIA nvprof are deprecated!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to run: `nvprof [options] [application]\n",
        "    [application-arguments]`\n",
        "\n",
        "Help page: `nvprof --help`\n"
      ],
      "metadata": {
        "id": "tyeOg5KTpSn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WDMmMDphf0",
        "outputId": "211d3047-76d4-47f4-b590-fff7d83d77b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: nvprof [options] [application] [application-arguments]\n",
            "Options:\n",
            "       --aggregate-mode <on|off>\n",
            "                        Turn on/off aggregate mode for events and metrics specified\n",
            "                        by subsequent \"--events\" and \"--metrics\" options. Those\n",
            "                        event/metric values will be collected for each domain instance,\n",
            "                        instead of the whole device. Allowed values:\n",
            "                        \ton - turn on aggregate mode (default)\n",
            "                        \toff - turn off aggregate mode\n",
            "\n",
            "       --analysis-metrics\n",
            "                        Collect profiling data that can be imported to Visual Profiler's\n",
            "                        \"analysis\" mode. Note: Use \"--export-profile\" to specify\n",
            "                        an export file.\n",
            "\n",
            "       --annotate-mpi <off|openmpi|mpich>\n",
            "                        Automatically annotate MPI calls with NVTX markers. Specify\n",
            "                        the MPI implementation installed on your machine. Currently,\n",
            "                        Open MPI and MPICH implementations are supported. By default,\n",
            "                        this option is off.\n",
            "\n",
            "       --concurrent-kernels <on|off>\n",
            "                        Turn on/off concurrent kernel execution. If concurrent kernel\n",
            "                        execution is off, all kernels running on one device will\n",
            "                        be serialized. Allowed values:\n",
            "                        \ton - turn on concurrent kernel execution (default)\n",
            "                        \toff - turn off concurrent kernel execution\n",
            "\n",
            "       --continuous-sampling-interval <interval>\n",
            "                        Set the continuous mode sampling interval in milliseconds.\n",
            "                        Minimum is 1 ms. Default is 2 ms.\n",
            "\n",
            "       --cpu-thread-tracing <on|off>\n",
            "                        Collect information about CPU thread API activity.\n",
            "                        Allowed values:\n",
            "                        \ton  - turn on CPU thread API tracing\n",
            "                        \toff - turn off CPU thread API tracing (default)\n",
            "\n",
            "       --dependency-analysis\n",
            "                        Generate event dependency graph for host and device activities\n",
            "                        and run dependency analysis.\n",
            "\n",
            "       --device-buffer-size <size in MBs>\n",
            "                        Set the device memory size (in MBs) reserved for storing\n",
            "                        profiling data for non-CDP operations, especially for concurrent\n",
            "                        kernel tracing, for each buffer on a context. The default\n",
            "                        value is 8MB. The size should be a positive integer.\n",
            "\n",
            "       --device-cdp-buffer-size <size in MBs>\n",
            "                        Set the device memory size (in MBs) reserved for storing\n",
            "                        profiling data for CDP operations for each buffer on a context.\n",
            "                        The default value is 8MB. The size should be a positive\n",
            "                        integer.\n",
            "\n",
            "       --devices <device ids>\n",
            "                        Change the scope of subsequent \"--events\", \"--metrics\", \"--query-events\"\n",
            "                        and \"--query-metrics\" options.\n",
            "                        Allowed values:\n",
            "                        \tall - change scope to all valid devices\n",
            "                        \tcomma-separated device IDs - change scope to specified\n",
            "                        devices\n",
            "\n",
            "       --event-collection-mode <mode>\n",
            "                        Choose event collection mode for all events/metrics Allowed\n",
            "                        values:\n",
            "                        \tkernel - events/metrics are collected only for durations\n",
            "                        of kernel executions (default)\n",
            "                        \tcontinuous - events/metrics are collected for duration\n",
            "                        of application. This is not applicable for non-tesla devices.\n",
            "                        This mode is compatible only with NVLink metrics. This mode\n",
            "                        is incompatible with \"--profile-all-processes\" or \"--profile-child-processes\"\n",
            "                        or \"--replay-mode kernel\" or \"--replay-mode application\".\n",
            "\n",
            "  -e,  --events <event names>\n",
            "                        Specify the events to be profiled on certain device(s). Multiple\n",
            "                        event names separated by comma can be specified. Which device(s)\n",
            "                        are profiled is controlled by the \"--devices\" option. Otherwise\n",
            "                        events will be collected on all devices.\n",
            "                        For a list of available events, use \"--query-events\".\n",
            "                        Use \"--events all\" to profile all events available for each\n",
            "                        device.\n",
            "                        Use \"--devices\" and \"--kernels\" to select a specific kernel\n",
            "                        invocation.\n",
            "\n",
            "       --kernel-latency-timestamps <on|off>\n",
            "                        Turn on/off collection of kernel latency timestamps, namely\n",
            "                        queued and submitted. The queued timestamp is captured when\n",
            "                        a kernel launch command was queued into the CPU command\n",
            "                        buffer. The submitted timestamp denotes when the CPU command\n",
            "                        buffer containing this kernel launch was submitted to the\n",
            "                        GPU. Turning this option on may incur an overhead during\n",
            "                        profiling. Allowed values:\n",
            "                        \ton - turn on collection of kernel latency timestamps\n",
            "                        \toff - turn off collection of kernel latency timestamps\n",
            "                        (default)\n",
            "\n",
            "       --kernels <kernel path syntax>\n",
            "                        Change the scope of subsequent \"--events\", \"--metrics\" options.\n",
            "                        The syntax is as follows:\n",
            "                        \t<kernel name>\n",
            "                        \tLimit scope to given kernel name.\n",
            "                        or\n",
            "                        \t<context id/name>:<stream id/name>:<kernel name>:<invocation>\n",
            "                        The context/stream IDs, names, kernel name and invocation\n",
            "                        can be regular expressions. Empty string matches any number\n",
            "                        or characters. If <context id/name> or <stream id/name>\n",
            "                        is a positive number, it's strictly matched against the\n",
            "                        CUDA context/stream ID. Otherwise it's treated as a regular\n",
            "                        expression and matched against the context/stream name specified\n",
            "                        by the NVTX library. If the invocation count is a positive\n",
            "                        number, it's strictly matched against the invocation of\n",
            "                        the kernel. Otherwise it's treated as a regular expression.\n",
            "                        Example: --kernels \"1:foo:bar:2\" will profile any kernel\n",
            "                        whose name contains \"bar\" and is the 2nd instance on context\n",
            "                        1 and on stream named \"foo\".\n",
            "\n",
            "  -m,  --metrics <metric names>\n",
            "                        Specify the metrics to be profiled on certain device(s).\n",
            "                        Multiple metric names separated by comma can be specified.\n",
            "                        Which device(s) are profiled is controlled by the \"--devices\"\n",
            "                        option. Otherwise metrics will be collected on all devices.\n",
            "                        For a list of available metrics, use \"--query-metrics\".\n",
            "                        Use \"--metrics all\" to profile all metrics available for\n",
            "                        each device.\n",
            "                        Use \"--devices\" and \"--kernels\" to select a specific kernel\n",
            "                        invocation. \n",
            "                        Note: \"--metrics all\" does not include some metrics which\n",
            "                        are needed for Visual Profiler's source level analysis.\n",
            "                        For that, use \"--analysis-metrics\".\n",
            "\n",
            "       --pc-sampling-period <period>\n",
            "                        Specify PC Sampling period in cycles,  at which the sampling\n",
            "                        records will be dumped. Allowed values for the period are\n",
            "                        integers between 5 to 31 both inclusive.\n",
            "                        This will set the sampling period to (2^period) cycles\n",
            "                        Default value is a number between 5 and 12 based on the setup.\n",
            "                        Note: Only available for GM20X+.\n",
            "                        \n",
            "\n",
            "       --profile-all-processes\n",
            "                        Profile all processes launched by the same user who launched\n",
            "                        this nvprof instance. Note: Only one instance of nvprof\n",
            "                        can run with this option at the same time. Under this mode,\n",
            "                        there's no need to specify an application to run.\n",
            "\n",
            "       --profile-api-trace <none|runtime|driver|all>\n",
            "                        Turn on/off CUDA runtime/driver API tracing. Allowed values:\n",
            "                        \tnone - turn off API tracing\n",
            "                        \truntime - only turn on CUDA runtime API tracing\n",
            "                        \tdriver - only turn on CUDA driver API tracing\n",
            "                        \tall - turn on all API tracing (default)\n",
            "\n",
            "       --profile-child-processes\n",
            "                        Profile the application and all child processes launched\n",
            "                        by it.\n",
            "\n",
            "       --profile-from-start <on|off>\n",
            "                        Enable/disable profiling from the start of the application.\n",
            "                        If it's disabled, the application can use {cu,cuda}Profiler{Start,Stop}\n",
            "                        to turn on/off profiling. Allowed values:\n",
            "                        \ton - enable profiling from start (default)\n",
            "                        \toff - disable profiling from start\n",
            "\n",
            "       --profiling-semaphore-pool-size <count>\n",
            "                        Set the profiling semaphore pool size reserved for storing\n",
            "                        profiling data for serialized kernels and memory operations\n",
            "                        for each context. The default value is 65536. The size should\n",
            "                        be a positive integer.\n",
            "\n",
            "       --query-events\n",
            "                        List all the events available on the device(s). Device(s)\n",
            "                        queried can be controlled by the \"--devices\" option.\n",
            "\n",
            "       --query-metrics\n",
            "                        List all the metrics available on the device(s). Device(s)\n",
            "                        queried can be controlled by the \"--devices\" option.\n",
            "\n",
            "       --replay-mode <mode>\n",
            "                        Choose replay mode used when not all events/metrics can be\n",
            "                        collected in a single run. Allowed values:\n",
            "                        \tdisabled - replay is disabled, events/metrics couldn't\n",
            "                        be profiled will be dropped\n",
            "                        \tkernel - each kernel invocation is replayed (default)\n",
            "                        \tapplication - the entire application is replayed.\n",
            "                        This mode is incompatible with \"--profile-all-processes\"\n",
            "                        or \"profile-child-processes\".\n",
            "\n",
            "       --skip-kernel-replay-save-restore <on|off>\n",
            "                        If enabled, this option can vastly improve kernel replay\n",
            "                        speed, as save and restore of the mutable state for each\n",
            "                        kernel pass will be skipped.\n",
            "                        Skipping of save/restore of input/output buffers allows you\n",
            "                        to specify that all profiled kernels on the context do not\n",
            "                        change the contents of their input buffers during execution,\n",
            "                        or call device malloc/free or new/delete, that leave the\n",
            "                        device heap in a different state. Specifically, a kernel\n",
            "                        can malloc and free a buffer in the same launch, but it\n",
            "                        cannot call an unmatched malloc or an unmatched free. Note:\n",
            "                        incorrectly using this mode while one of the kernels does\n",
            "                        modify the input buffer or uses unmatched malloc/free will\n",
            "                        result in undefined behavior, including kernel execution\n",
            "                        failure and/or corrupted device data. Allowed values:\n",
            "                        \ton - skip save/restore of the input/output buffers\n",
            "                        \toff - save/restore input/output buffers for each\n",
            "                        kernel replay pass (default)\n",
            "\n",
            "  -a,  --source-level-analysis <source level analysis names>\n",
            "                        Specify the source level metrics to be profiled on a certain\n",
            "                        kernel invocation. Use \"--devices\" and \"--kernels\" to select\n",
            "                        a specific kernel invocation. Allowed values: one or more\n",
            "                        of the following, separated by commas\n",
            "                        \tglobal_access: global access\n",
            "                        \tshared_access: shared access\n",
            "                        \tbranch: divergent branch\n",
            "                        \tinstruction_execution: instruction execution\n",
            "                        \tpc_sampling: pc sampling, available only for GM20X+\n",
            "                        Note: Use \"--export-profile\" to specify an export file.\n",
            "\n",
            "       --system-profiling <on|off>\n",
            "                        Turn on/off power, clock, and thermal profiling. Allowed\n",
            "                        values:\n",
            "                        \ton - turn on system profiling\n",
            "                        \toff - turn off system profiling (default)\n",
            "\n",
            "  -t,  --timeout <seconds>\n",
            "                        Set an execution timeout (in seconds) for the CUDA application.\n",
            "                        Note: Timeout starts counting from the moment the CUDA driver\n",
            "                        is initialized. If the application doesn't call any CUDA\n",
            "                        APIs, timeout won't be triggered.\n",
            "\n",
            "       --trace <gpu|api>\n",
            "                        Specify the option (or options seperated by commas) to be\n",
            "                        traced. Allowed values:\n",
            "                        \tapi - only turn on CUDA runtime and driver API tracing\n",
            "                        \tgpu - only turn on CUDA GPU tracing\n",
            "\n",
            "       --track-memory-allocations <on|off>\n",
            "                        Turn on/off tracking of memory operations, which involves\n",
            "                        recording timestamps, memory size, memory type and program\n",
            "                        counters of the memory allocations and frees. Turning this\n",
            "                        option on may incur an overhead during profiling. Allowed\n",
            "                        values:\n",
            "                        \ton - turn on tracking of memory allocations and\n",
            "                        free\n",
            "                        \toff - turn off tracking of memory allocations and\n",
            "                        free (default)\n",
            "\n",
            "       --unified-memory-profiling <per-process-device|off>\n",
            "                        Configure unified memory profiling. Allowed values:\n",
            "                        \tper-process-device - collect counts for each process\n",
            "                        and each device (default)\n",
            "                        \toff - turn off unified memory profiling\n",
            "\n",
            "       --cpu-profiling <on|off>\n",
            "                        Turn on CPU profiling. Note: CPU profiling is not supported\n",
            "                        in multi-process mode.\n",
            "\n",
            "       --cpu-profiling-explain-ccff <filename>\n",
            "                        Path to a PGI pgexplain.xml file that should be used to interpret\n",
            "                        Common Compiler Feedback Format (CCFF) messages.\n",
            "\n",
            "       --cpu-profiling-frequency <frequency>\n",
            "                        Set the CPU profiling frequency in samples per second. Default\n",
            "                        is 100Hz. Maximum is 500Hz.\n",
            "\n",
            "       --cpu-profiling-max-depth <depth>\n",
            "                        Set the maximum depth of each call stack. Zero means no limit.\n",
            "                        Default is zero.\n",
            "\n",
            "       --cpu-profiling-mode <flat|top-down|bottom-up>\n",
            "                        Set the output mode of CPU profiling. Allowed values:\n",
            "                        \tflat - Show flat profile\n",
            "                        \ttop-down - Show parent functions at the top\n",
            "                        \tbottom-up - Show parent functions at the bottom\n",
            "                        (default)\n",
            "\n",
            "       --cpu-profiling-percentage-threshold <threshold>\n",
            "                        Filter out the entries that are below the set percentage\n",
            "                        threshold. The limit should be an integer between 0 and\n",
            "                        100, inclusive. Zero means no limit. Default is zero.\n",
            "\n",
            "       --cpu-profiling-scope <function|instruction>\n",
            "                        Choose the profiling scope. Allowed values:\n",
            "                        \tfunction - Each level in the stack trace represents\n",
            "                        a distinct function (default)\n",
            "                        \tinstruction - Each level in the stack trace represents\n",
            "                        a distinct instruction address\n",
            "\n",
            "       --cpu-profiling-show-ccff <on|off>\n",
            "                        Choose whether to print Common Compiler Feedback Format (CCFF)\n",
            "                        messages embedded in the binary. Note: this option implies\n",
            "                        \"--cpu-profiling-scope instruction\". Default is off.\n",
            "\n",
            "       --cpu-profiling-show-library <on|off>\n",
            "                        Choose whether to print the library name for each sample.\n",
            "\n",
            "       --cpu-profiling-thread-mode <separated|aggregated>\n",
            "                        Set the thread mode of CPU profiling. Allowed values:\n",
            "                        \tseparated - Show separate profile for each thread\n",
            "                        \taggregated - Aggregate data from all threads (default)\n",
            "\n",
            "       --cpu-profiling-unwind-stack <on|off>\n",
            "                        Choose whether to unwind the CPU call-stack at each sample\n",
            "                        point. Default is on. \n",
            "\n",
            "       --openacc-profiling <on|off>\n",
            "                        Enable/disable recording information from the OpenACC profiling\n",
            "                        interface. Note: if the OpenACC profiling interface is available\n",
            "                        depends on the OpenACC runtime. Default is on.\n",
            "\n",
            "       --openmp-profiling <on|off>\n",
            "                        Enable/disable recording information from the OpenMP profiling\n",
            "                        interface. Note: if the OpenMP profiling interface is available\n",
            "                        depends on the OpenMP runtime. Default is off.\n",
            "\n",
            "       --context-name <name>\n",
            "                        Name of the CUDA context.\n",
            "                        \t\"%i\" in the context name string is replaced with\n",
            "                        the ID of the context.\n",
            "                        \t\"%p\" in the context name string is replaced with\n",
            "                        the process ID of the application being profiled.\n",
            "                        \t\"%q{<ENV>}\" in the context name string is replaced\n",
            "                        with the value of the environment variable \"<ENV>\". If the\n",
            "                        environment variable is not set it's an error.\n",
            "                        \t\"%h\" in the context name string is replaced with\n",
            "                        the hostname of the system.\n",
            "                        \t\"%%\" in the context name string is replaced with\n",
            "                        \"%\". Any other character following \"%\" is illegal.\n",
            "\n",
            "       --csv\n",
            "                        Use comma-separated values in the output.\n",
            "\n",
            "       --demangling <on|off>\n",
            "                        Turn on/off C++ name demangling of function names. Allowed\n",
            "                        values:\n",
            "                        \ton - turn on demangling (default)\n",
            "                        \toff - turn off demangling\n",
            "\n",
            "  -u,  --normalized-time-unit <s|ms|us|ns|col|auto>\n",
            "                        Specify the unit of time that will be used in the output.\n",
            "                        Allowed values:\n",
            "                        \ts - second, ms - millisecond, us - microsecond,\n",
            "                        ns - nanosecond\n",
            "                        \tcol - a fixed unit for each column\n",
            "                        \tauto (default) - the scale is chosen for each value\n",
            "                        based on its length.\n",
            "\n",
            "       --openacc-summary-mode <mode>\n",
            "                        Set how durations are computed in the OpenACC summary. Allowed\n",
            "                        values:\n",
            "                        \texclusive: show exclusive times (default)\n",
            "                        \tinclusive: show inclusive times\n",
            "\n",
            "       --print-api-summary\n",
            "                        Print a summary of CUDA runtime/driver API calls.\n",
            "\n",
            "       --print-api-trace\n",
            "                        Print CUDA runtime/driver API trace.\n",
            "\n",
            "       --print-dependency-analysis-trace\n",
            "                        Print dependency analysis trace.\n",
            "\n",
            "       --print-gpu-summary\n",
            "                        Print a summary of the activities on the GPU (including CUDA\n",
            "                        kernels and memcpy's/memset's).\n",
            "\n",
            "       --print-gpu-trace\n",
            "                        Print individual kernel invocations (including CUDA memcpy's/memset's)\n",
            "                        and sort them in chronological order. In event/metric profiling\n",
            "                        mode, show events/metrics for each kernel invocation.\n",
            "\n",
            "       --print-openacc-constructs\n",
            "                        Include parent construct names in OpenACC profile.\n",
            "\n",
            "       --print-openacc-summary\n",
            "                        Print a summary of the OpenACC profile.\n",
            "\n",
            "       --print-openacc-trace\n",
            "                        Print a trace of the OpenACC profile.\n",
            "\n",
            "       --print-openmp-summary\n",
            "                        Print a summary of the OpenMP profile.\n",
            "\n",
            "  -s,  --print-summary\n",
            "                        Print a summary of the profiling result on screen. Note:\n",
            "                        This is the default unless \"--export-profile\" or other print\n",
            "                        options are used.\n",
            "\n",
            "       --print-summary-per-gpu\n",
            "                        Print a summary of the profiling result for each GPU.\n",
            "\n",
            "       --process-name <name>\n",
            "                        Name of the process.\n",
            "                        \t\"%p\" in the process name string is replaced with\n",
            "                        the process ID of the application being profiled.\n",
            "                        \t\"%q{<ENV>}\" in the process name string is replaced\n",
            "                        with the value of the environment variable \"<ENV>\". If the\n",
            "                        environment variable is not set it's an error.\n",
            "                        \t\"%h\" in the process name string is replaced with\n",
            "                        the hostname of the system.\n",
            "                        \t\"%%\" in the process  name string is replaced with\n",
            "                        \"%\". Any other character following \"%\" is illegal.\n",
            "\n",
            "       --quiet\n",
            "                        Suppress all nvprof output.\n",
            "\n",
            "       --stream-name <name>\n",
            "                        Name of the CUDA stream.\n",
            "                        \t\"%i\" in the stream name string is replaced with the\n",
            "                        ID of the stream.\n",
            "                        \t\"%p\" in the stream name string is replaced with\n",
            "                        the process ID of the application being profiled.\n",
            "                        \t\"%q{<ENV>}\" in the stream name string is replaced\n",
            "                        with the value of the environment variable \"<ENV>\". If the\n",
            "                        environment variable is not set it's an error.\n",
            "                        \t\"%h\" in the stream name string is replaced with\n",
            "                        the hostname of the system.\n",
            "                        \t\"%%\" in the stream name string is replaced with\n",
            "                        \"%\". Any other character following \"%\" is illegal.\n",
            "\n",
            "  -o,  --export-profile <filename>\n",
            "                        Export the result file which can be imported later or opened\n",
            "                        by the NVIDIA Visual Profiler.\n",
            "                        \t\"%p\" in the file name string is replaced with the\n",
            "                        process ID of the application being profiled.\n",
            "                        \t\"%q{<ENV>}\" in the file name string is replaced\n",
            "                        with the value of the environment variable \"<ENV>\". If the\n",
            "                        environment variable is not set it's an error.\n",
            "                        \t\"%h\" in the file name string is replaced with the\n",
            "                        hostname of the system.\n",
            "                        \t\"%%\" in the file name string is replaced with \"%\".\n",
            "                        \tAny other character following \"%\" is illegal.\n",
            "                        By default, this option disables the summary output. Note:\n",
            "                        If the application being profiled creates child processes,\n",
            "                        or if '--profile-all-processes' is used, the \"%p\" format\n",
            "                        is needed to get correct export files for each process.\n",
            "\n",
            "  -f,  --force-overwrite\n",
            "                        Force overwriting all output files (any existing files will\n",
            "                        be overwritten).\n",
            "\n",
            "  -i,  --import-profile <filename>\n",
            "                        Import a result profile from a previous run.\n",
            "\n",
            "       --log-file <filename>\n",
            "                        Make nvprof send all its output to the specified file, or\n",
            "                        one of the standard channels. The file will be overwritten.\n",
            "                        If the file doesn't exist, a new one will be created.\n",
            "                        \t\"%1\" as the whole file name indicates standard output\n",
            "                        channel (stdout).\n",
            "                        \t\"%2\" as the whole file name indicates standard error\n",
            "                        channel (stderr). Note: This is the default.\n",
            "                        \t\"%p\" in the file name string is replaced with the\n",
            "                        process ID of the application being profiled.\n",
            "                        \t\"%q{<ENV>}\" in the file name string is replaced\n",
            "                        with the value of the environment variable \"<ENV>\". If the\n",
            "                        environment variable is not set it's an error.\n",
            "                        \t\"%h\" in the file name string is replaced with the\n",
            "                        hostname of the system.\n",
            "                        \t\"%%\" in the file name is replaced with \"%\".\n",
            "                        \tAny other character following \"%\" is illegal.\n",
            "\n",
            "       --print-nvlink-topology\n",
            "                        Print NVLink topology \n",
            "\n",
            "       --print-pci-topology\n",
            "                        Print PCI topology\n",
            "\n",
            "  -h,  --help\n",
            "                        Print this help information.\n",
            "\n",
            "  -V,  --version\n",
            "                        Print version information of this tool.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some modes of running `nvprof`.\n",
        "\n",
        "**Summary mode**:\n",
        "- default mode\n",
        "- overview of the GPU kernels and memory copies in your application\n",
        "- output a single result line for each kernel function and each type of CUDA memory copy/set performed by the application\n",
        "- for each kernel, output\n",
        "  - the total time of all instances of the kernel or type of memory copy\n",
        "  - the average time\n",
        "  - the minimum time\n",
        "  - the maximum time\n",
        "- support of CUDA dynamic parallelism:  if the app uses dynamic parallelism, the output will contain one column for the number of host-launched kernels and one for the number of device-launched kernels\n",
        "\n",
        "*The time for a kernel* is the kernel execution time on the device"
      ],
      "metadata": {
        "id": "NyV9dwUyeS_F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vMCjO8ZFMMv",
        "outputId": "de82cbfd-b98e-4011-b608-d03adec4084f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./cudabasic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocating memory on host.\n",
            "Allocating memory on device.\n",
            "==457== NVPROF is profiling process 457, command: ./cudabasic\n",
            "Copying to device.\n",
            "Doing GPU Vector + 1 \n",
            "Doing a CPU Vector add & Copy to host\n",
            "Compare Results\n",
            "Free resources==457== Profiling application: ./cudabasic\n",
            "==457== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   59.36%  1.9856ms         1  1.9856ms  1.9856ms  1.9856ms  [CUDA memcpy DtoH]\n",
            "                   37.24%  1.2456ms         1  1.2456ms  1.2456ms  1.2456ms  [CUDA memcpy HtoD]\n",
            "                    3.40%  113.73us         1  113.73us  113.73us  113.73us  vecAddOne(int*, int*, int)\n",
            "      API calls:   93.85%  91.940ms         2  45.970ms  74.953us  91.865ms  cudaMalloc\n",
            "                    5.25%  5.1401ms         2  2.5701ms  1.5640ms  3.5761ms  cudaMemcpy\n",
            "                    0.35%  344.30us         2  172.15us  134.38us  209.92us  cudaFree\n",
            "                    0.26%  252.83us         1  252.83us  252.83us  252.83us  cudaLaunchKernel\n",
            "                    0.14%  139.41us       114  1.2220us     139ns  54.991us  cuDeviceGetAttribute\n",
            "                    0.12%  115.88us         1  115.88us  115.88us  115.88us  cudaDeviceSynchronize\n",
            "                    0.01%  10.780us         1  10.780us  10.780us  10.780us  cuDeviceGetName\n",
            "                    0.01%  9.0700us         1  9.0700us  9.0700us  9.0700us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.1230us         1  4.1230us  4.1230us  4.1230us  cuDeviceTotalMem\n",
            "                    0.00%  1.5900us         3     530ns     183ns  1.1330us  cuDeviceGetCount\n",
            "                    0.00%  1.0670us         2     533ns     216ns     851ns  cuDeviceGet\n",
            "                    0.00%     505ns         1     505ns     505ns     505ns  cuModuleGetLoadingMode\n",
            "                    0.00%     227ns         1     227ns     227ns     227ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`--profile-api-trace none`: turn off API trace"
      ],
      "metadata": {
        "id": "iiMsnoDhrWNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --profile-api-trace none ./cudabasic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oXeFru1rbM_",
        "outputId": "96f27e6d-22fe-4bbe-e815-c8cfe60bf73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocating memory on host.\n",
            "Allocating memory on device.\n",
            "==482== NVPROF is profiling process 482, command: ./cudabasic\n",
            "Copying to device.\n",
            "Doing GPU Vector + 1 \n",
            "Doing a CPU Vector add & Copy to host\n",
            "Compare Results\n",
            "Free resources==482== Profiling application: ./cudabasic\n",
            "==482== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   60.85%  1.8886ms         1  1.8886ms  1.8886ms  1.8886ms  [CUDA memcpy DtoH]\n",
            "                   35.48%  1.1011ms         1  1.1011ms  1.1011ms  1.1011ms  [CUDA memcpy HtoD]\n",
            "                    3.67%  114.05us         1  114.05us  114.05us  114.05us  vecAddOne(int*, int*, int)\n",
            "No API activities were profiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPdlxjtknBLn"
      },
      "source": [
        "*  *  *\n",
        "*  *  *\n",
        "\n",
        "**Kernel**: function that executes on device (GPU) and can be called from host (CPU)\n",
        "\n",
        "- Functions must be declared with a qualifier\n",
        "   - \\_\\_global\\_\\_: GPU kernel function launched by CPU, must return void\n",
        "   - \\_\\_device\\_\\_: can be called from GPU functions\n",
        "   - \\_\\_host\\_\\_: can be called from CPU functions (default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U4KP73rm2WG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120e58ac-b768-4b16-f947-651043010284"
      },
      "source": [
        "%%writefile cudaQual.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__device__ __host__ void hello()\n",
        "{\n",
        "  printf(\"Hello!\\n\");\n",
        "}\n",
        "\n",
        "__device__ void hiDeviceFunction(void)\n",
        "{ printf(\"Hello! This is in hiDeviceFunction. \\n\");\n",
        "  hello();\n",
        "}\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d\\n\", threadIdx.x);\n",
        "  hiDeviceFunction();\n",
        "  hello();\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  helloCUDA<<<1, 1>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cudaQual.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1p15nY_m1cA"
      },
      "source": [
        "!nvcc -o cudaQual cudaQual.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMyDUdZzncd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4eadc76-729b-4fac-de13-2f540b5256e4"
      },
      "source": [
        "!./cudaQual"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello thread 0\n",
            "Hello! This is in hiDeviceFunction. \n",
            "Hello!\n",
            "Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5fTQlsenhGu"
      },
      "source": [
        "Is the result value of the above code the value we expect ?\n",
        "\n",
        "If the value we expected didn't come out, what would be the reason ?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./cudaQual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUJ8VlZwlM2E",
        "outputId": "320e5144-0b8a-461c-e434-45e339d90771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==740== NVPROF is profiling process 740, command: ./cudaQual\n",
            "Hello thread 0\n",
            "Hello! This is in hiDeviceFunction. \n",
            "==740== Profiling application: ./cudaQual\n",
            "==740== Warning: 1 records have invalid timestamps due to insufficient device buffer space. You can configure the buffer space using the option --device-buffer-size.\n",
            "==740== Profiling result:\n",
            "No kernels were profiled.\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            "      API calls:   99.82%  92.215ms         1  92.215ms  92.215ms  92.215ms  cudaLaunchKernel\n",
            "                    0.15%  142.78us       114  1.2520us     136ns  55.510us  cuDeviceGetAttribute\n",
            "                    0.01%  13.231us         1  13.231us  13.231us  13.231us  cuDeviceGetName\n",
            "                    0.01%  5.9930us         1  5.9930us  5.9930us  5.9930us  cuDeviceTotalMem\n",
            "                    0.01%  5.0670us         1  5.0670us  5.0670us  5.0670us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7110us         3     570ns     189ns  1.0740us  cuDeviceGetCount\n",
            "                    0.00%  1.0760us         2     538ns     286ns     790ns  cuDeviceGet\n",
            "                    0.00%     500ns         1     500ns     500ns     500ns  cuModuleGetLoadingMode\n",
            "                    0.00%     233ns         1     233ns     233ns     233ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR4DTteiDXKg"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## Understanding Thread and Block\n",
        "\n",
        "- blockIdx.x / blockIdx.y\n",
        "- blockDim.x / blockDim.y\n",
        "- threadIdx.x / threadIdx.y\n",
        "- threadDim.x / threadDim.y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6wkCid3W5Dn",
        "outputId": "cb295dae-cdde-470d-c4b2-e214271c475b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile helloCUDA1.cu\n",
        "\n",
        "// Create multiple blocks! --------------> 10 blocks\n",
        "// Each block contains only one thread -----> 1 thread per block\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d in block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  helloCUDA<<<10, 1>>>();\n",
        "\n",
        "  cudaDeviceSynchronize();  // printf Wait until the function completes\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helloCUDA1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuFZjuhtXAls"
      },
      "source": [
        "!nvcc -o helloCUDA1 helloCUDA1.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mi0z-KzXzP_",
        "outputId": "ef2940f9-c259-4e1f-b975-39f0993bb310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./helloCUDA1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello thread 0 in block 2\n",
            "Hello thread 0 in block 7\n",
            "Hello thread 0 in block 4\n",
            "Hello thread 0 in block 9\n",
            "Hello thread 0 in block 0\n",
            "Hello thread 0 in block 3\n",
            "Hello thread 0 in block 8\n",
            "Hello thread 0 in block 5\n",
            "Hello thread 0 in block 1\n",
            "Hello thread 0 in block 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./helloCUDA1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6vPCpFzlijx",
        "outputId": "b2fda28f-4aad-4eb0-8c5c-f6d0058a6406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==830== NVPROF is profiling process 830, command: ./helloCUDA1\n",
            "Hello thread 0 in block 2\n",
            "Hello thread 0 in block 7\n",
            "Hello thread 0 in block 3\n",
            "Hello thread 0 in block 8\n",
            "Hello thread 0 in block 0\n",
            "Hello thread 0 in block 5\n",
            "Hello thread 0 in block 4\n",
            "Hello thread 0 in block 1\n",
            "Hello thread 0 in block 6\n",
            "Hello thread 0 in block 9\n",
            "==830== Profiling application: ./helloCUDA1\n",
            "==830== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  100.93us         1  100.93us  100.93us  100.93us  helloCUDA(void)\n",
            "      API calls:   99.68%  97.665ms         1  97.665ms  97.665ms  97.665ms  cudaLaunchKernel\n",
            "                    0.15%  143.63us       114  1.2590us     145ns  56.938us  cuDeviceGetAttribute\n",
            "                    0.14%  139.92us         1  139.92us  139.92us  139.92us  cudaDeviceSynchronize\n",
            "                    0.02%  15.653us         1  15.653us  15.653us  15.653us  cuDeviceGetName\n",
            "                    0.01%  5.7280us         1  5.7280us  5.7280us  5.7280us  cuDeviceGetPCIBusId\n",
            "                    0.01%  5.0440us         1  5.0440us  5.0440us  5.0440us  cuDeviceTotalMem\n",
            "                    0.00%  2.1480us         3     716ns     201ns  1.6550us  cuDeviceGetCount\n",
            "                    0.00%  1.2600us         2     630ns     316ns     944ns  cuDeviceGet\n",
            "                    0.00%     521ns         1     521ns     521ns     521ns  cuModuleGetLoadingMode\n",
            "                    0.00%     227ns         1     227ns     227ns     227ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg6res3bX58t",
        "outputId": "89de591e-3f88-4147-e10a-fdcaf9f5b851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile helloCUDA2.cu\n",
        "\n",
        "// Create one block! --------------> 1 Block\n",
        "// Each block contains 10 threads -----> 10 threads per block\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d in block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "  helloCUDA<<<1, 10>>>();\n",
        "\n",
        "  cudaDeviceSynchronize();  // printf Wait until the function completes\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helloCUDA2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqbZh4Q8YLvf"
      },
      "source": [
        "!nvcc -o helloCUDA2 helloCUDA2.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBj7Q3DGYOKd",
        "outputId": "0fb2a619-a914-4404-9625-f44d19b8970d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./helloCUDA2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello thread 0 in block 0\n",
            "Hello thread 1 in block 0\n",
            "Hello thread 2 in block 0\n",
            "Hello thread 3 in block 0\n",
            "Hello thread 4 in block 0\n",
            "Hello thread 5 in block 0\n",
            "Hello thread 6 in block 0\n",
            "Hello thread 7 in block 0\n",
            "Hello thread 8 in block 0\n",
            "Hello thread 9 in block 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./helloCUDA2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5j3_rQjlvZP",
        "outputId": "2520783c-df7c-4a15-9bb4-e47ea455ae5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==974== NVPROF is profiling process 974, command: ./helloCUDA2\n",
            "Hello thread 0 in block 0\n",
            "Hello thread 1 in block 0\n",
            "Hello thread 2 in block 0\n",
            "Hello thread 3 in block 0\n",
            "Hello thread 4 in block 0\n",
            "Hello thread 5 in block 0\n",
            "Hello thread 6 in block 0\n",
            "Hello thread 7 in block 0\n",
            "Hello thread 8 in block 0\n",
            "Hello thread 9 in block 0\n",
            "==974== Profiling application: ./helloCUDA2\n",
            "==974== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  91.072us         1  91.072us  91.072us  91.072us  helloCUDA(void)\n",
            "      API calls:   99.67%  94.849ms         1  94.849ms  94.849ms  94.849ms  cudaLaunchKernel\n",
            "                    0.15%  146.46us         1  146.46us  146.46us  146.46us  cudaDeviceSynchronize\n",
            "                    0.15%  138.71us       114  1.2160us     137ns  55.900us  cuDeviceGetAttribute\n",
            "                    0.01%  11.242us         1  11.242us  11.242us  11.242us  cuDeviceGetName\n",
            "                    0.01%  5.5080us         1  5.5080us  5.5080us  5.5080us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.3200us         1  4.3200us  4.3200us  4.3200us  cuDeviceTotalMem\n",
            "                    0.00%  2.1900us         3     730ns     306ns  1.5680us  cuDeviceGetCount\n",
            "                    0.00%  1.0690us         2     534ns     222ns     847ns  cuDeviceGet\n",
            "                    0.00%     673ns         1     673ns     673ns     673ns  cuModuleGetLoadingMode\n",
            "                    0.00%     229ns         1     229ns     229ns     229ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGRYhJOWBs8p",
        "outputId": "283ba82e-4ae7-458f-cca1-c144a79c8e2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile helloCUDA3.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d in block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int n = 12;\n",
        "  int blockDim = 4;            // Number of Threads within a Block\n",
        "  int gridDim = n / blockDim;  // Number of Blocks in Grid\n",
        "\n",
        "  // Thus, the total number of generated threads is blockDim * threadDim\n",
        "\n",
        "  helloCUDA<<<gridDim, blockDim>>>();\n",
        "\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helloCUDA3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftSMqLF6B6gB"
      },
      "source": [
        "!nvcc -o helloCUDA3 helloCUDA3.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwaUXUeECDi5",
        "outputId": "36228403-3c6d-485c-98ce-2c99635f9a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./helloCUDA3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello thread 0 in block 2\n",
            "Hello thread 1 in block 2\n",
            "Hello thread 2 in block 2\n",
            "Hello thread 3 in block 2\n",
            "Hello thread 0 in block 0\n",
            "Hello thread 1 in block 0\n",
            "Hello thread 2 in block 0\n",
            "Hello thread 3 in block 0\n",
            "Hello thread 0 in block 1\n",
            "Hello thread 1 in block 1\n",
            "Hello thread 2 in block 1\n",
            "Hello thread 3 in block 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU-trace mode**:\n",
        "- timeline of all activities taking place on the GPU in chronological order\n",
        "- for each kernel or memory copy, detailed information such as kernel parameters, shared memory usage and memory transfer throughput are shown\n",
        "- the number shown in the square brackets after the kernel name correlates to the CUDA API that launched that kernel.\n",
        "- `nvprof --print-gpu-trace`\n",
        "- support of CUDA dynamic parallelism:\n",
        "  - for host kernel launch, the kernel ID will be shown\n",
        "  - for device kernel launch, the kernel ID, parent kernel ID and parent block will be shown"
      ],
      "metadata": {
        "id": "XwIGLfWPe6VD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP-QEuUxGeZv",
        "outputId": "f96a296a-8af7-41eb-e181-54b5ee54fc2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof --print-gpu-trace ./helloCUDA3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1077== NVPROF is profiling process 1077, command: ./helloCUDA3\n",
            "Hello thread 0 in block 2\n",
            "Hello thread 1 in block 2\n",
            "Hello thread 2 in block 2\n",
            "Hello thread 3 in block 2\n",
            "Hello thread 0 in block 0\n",
            "Hello thread 1 in block 0\n",
            "Hello thread 2 in block 0\n",
            "Hello thread 3 in block 0\n",
            "Hello thread 0 in block 1\n",
            "Hello thread 1 in block 1\n",
            "Hello thread 2 in block 1\n",
            "Hello thread 3 in block 1\n",
            "==1077== Profiling application: ./helloCUDA3\n",
            "==1077== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*           Device   Context    Stream  Name\n",
            "233.82ms  90.560us              (3 1 1)         (4 1 1)        32        0B        0B     Tesla T4 (0)         1         7  helloCUDA(void) [125]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**API-trace mode:**\n",
        "- timeline of all CUDA runtime and driver API calls invoked on the host in chronological order\n",
        "- `--print-api-trace`"
      ],
      "metadata": {
        "id": "P1OlN1o0s2Dp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtwajQGsGjTY",
        "outputId": "5283ab0d-8ad1-4b69-ce34-d532f2b1a4b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile simpleCUDA.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "__global__ void kernel1( int *a )\n",
        "{\n",
        "   int idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "   a[idx] = 7;          // output: 7 7 7 7   7 7 7 7   7 7 7 7   7 7 7 7\n",
        "}\n",
        "\n",
        "__global__ void kernel2( int *a )\n",
        "{\n",
        " int idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "   a[idx] = blockIdx.x; // output: 0 0 0 0   1 1 1 1   2 2 2 2   3 3 3 3\n",
        "}\n",
        "\n",
        "__global__ void kernel3( int *a )\n",
        "{\n",
        " int idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "   a[idx] = threadIdx.x;        // output: 0 1 2 3   1 2 3 4   0 1 2 3   0 1 2 3\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int *host_array;\n",
        "  int *dev_array;\n",
        "\n",
        "  host_array = (int *) malloc(sizeof(int)*16);\n",
        "  cudaMalloc(&dev_array, sizeof(int)*16);\n",
        "  cudaMemset(dev_array, 0, 16);\n",
        "\n",
        "  kernel1<<<4, 4>>>(dev_array);\n",
        "\n",
        "  cudaMemcpy(host_array, dev_array, sizeof(int)*16, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  for(int i = 0; i < 16; i++) printf(\" %d \", host_array[i]);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  cudaMemset(dev_array, 0, 16);\n",
        "\n",
        "  kernel2<<<4, 4>>>(dev_array);\n",
        "\n",
        "  cudaMemcpy(host_array, dev_array, sizeof(int)*16, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  for(int i = 0; i < 16; i++) printf(\" %d \", host_array[i]);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  cudaMemset(dev_array, 0, 16);\n",
        "\n",
        "  kernel3<<<4, 4>>>(dev_array);\n",
        "\n",
        "  cudaMemcpy(host_array, dev_array, sizeof(int)*16, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  for(int i = 0; i < 16; i++) printf(\" %d \", host_array[i]);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  free(host_array);\n",
        "  cudaFree(dev_array);\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing simpleCUDA.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5lnZlXamknt"
      },
      "source": [
        "!nvcc -o simpleCUDA simpleCUDA.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stfSsKdQmnq3",
        "outputId": "c10ae4fd-4d2c-475a-8db9-4720cd6d4660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./simpleCUDA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7 \n",
            " 0  0  0  0  1  1  1  1  2  2  2  2  3  3  3  3 \n",
            " 0  1  2  3  0  1  2  3  0  1  2  3  0  1  2  3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --print-api-trace ./simpleCUDA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY4a6dmDnsAF",
        "outputId": "6f8dcb53-cb94-4312-8430-248086b69cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==2441== NVPROF is profiling process 2441, command: ./simpleCUDA\n",
            " 7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7 \n",
            " 0  0  0  0  1  1  1  1  2  2  2  2  3  3  3  3 \n",
            " 0  1  2  3  0  1  2  3  0  1  2  3  0  1  2  3 \n",
            "==2441== Profiling application: ./simpleCUDA\n",
            "==2441== Profiling result:\n",
            "   Start  Duration  Name\n",
            "134.57ms  5.3540us  cuDeviceGetPCIBusId\n",
            "146.79ms     944ns  cuDeviceGetCount\n",
            "146.79ms     187ns  cuDeviceGetCount\n",
            "147.14ms     931ns  cuDeviceGet\n",
            "147.14ms  1.2480us  cuDeviceGetAttribute\n",
            "147.20ms     693ns  cuDeviceGetAttribute\n",
            "147.22ms     467ns  cuDeviceGetAttribute\n",
            "147.29ms     748ns  cuModuleGetLoadingMode\n",
            "147.34ms     345ns  cuDeviceGetCount\n",
            "147.34ms     192ns  cuDeviceGet\n",
            "147.34ms  10.991us  cuDeviceGetName\n",
            "147.35ms  4.3490us  cuDeviceTotalMem\n",
            "147.36ms     389ns  cuDeviceGetAttribute\n",
            "147.36ms     168ns  cuDeviceGetAttribute\n",
            "147.36ms     237ns  cuDeviceGetAttribute\n",
            "147.36ms     268ns  cuDeviceGetAttribute\n",
            "147.36ms     207ns  cuDeviceGetAttribute\n",
            "147.36ms  23.837us  cuDeviceGetAttribute\n",
            "147.38ms     223ns  cuDeviceGetAttribute\n",
            "147.38ms     163ns  cuDeviceGetAttribute\n",
            "147.39ms     194ns  cuDeviceGetAttribute\n",
            "147.39ms     176ns  cuDeviceGetAttribute\n",
            "147.39ms     405ns  cuDeviceGetAttribute\n",
            "147.39ms     174ns  cuDeviceGetAttribute\n",
            "147.39ms     174ns  cuDeviceGetAttribute\n",
            "147.39ms     170ns  cuDeviceGetAttribute\n",
            "147.39ms     174ns  cuDeviceGetAttribute\n",
            "147.39ms     175ns  cuDeviceGetAttribute\n",
            "147.39ms     175ns  cuDeviceGetAttribute\n",
            "147.39ms     176ns  cuDeviceGetAttribute\n",
            "147.39ms     179ns  cuDeviceGetAttribute\n",
            "147.39ms     176ns  cuDeviceGetAttribute\n",
            "147.39ms     180ns  cuDeviceGetAttribute\n",
            "147.39ms     190ns  cuDeviceGetAttribute\n",
            "147.39ms     178ns  cuDeviceGetAttribute\n",
            "147.39ms     175ns  cuDeviceGetAttribute\n",
            "147.39ms     177ns  cuDeviceGetAttribute\n",
            "147.39ms     178ns  cuDeviceGetAttribute\n",
            "147.39ms     178ns  cuDeviceGetAttribute\n",
            "147.39ms     173ns  cuDeviceGetAttribute\n",
            "147.39ms     167ns  cuDeviceGetAttribute\n",
            "147.39ms     167ns  cuDeviceGetAttribute\n",
            "147.39ms     174ns  cuDeviceGetAttribute\n",
            "147.39ms     175ns  cuDeviceGetAttribute\n",
            "147.39ms     171ns  cuDeviceGetAttribute\n",
            "147.39ms     182ns  cuDeviceGetAttribute\n",
            "147.40ms     174ns  cuDeviceGetAttribute\n",
            "147.40ms     177ns  cuDeviceGetAttribute\n",
            "147.40ms     176ns  cuDeviceGetAttribute\n",
            "147.40ms     183ns  cuDeviceGetAttribute\n",
            "147.40ms     180ns  cuDeviceGetAttribute\n",
            "147.40ms     174ns  cuDeviceGetAttribute\n",
            "147.40ms     178ns  cuDeviceGetAttribute\n",
            "147.40ms     174ns  cuDeviceGetAttribute\n",
            "147.40ms     164ns  cuDeviceGetAttribute\n",
            "147.40ms     167ns  cuDeviceGetAttribute\n",
            "147.40ms     164ns  cuDeviceGetAttribute\n",
            "147.40ms     171ns  cuDeviceGetAttribute\n",
            "147.40ms     166ns  cuDeviceGetAttribute\n",
            "147.40ms     175ns  cuDeviceGetAttribute\n",
            "147.40ms     158ns  cuDeviceGetAttribute\n",
            "147.40ms     178ns  cuDeviceGetAttribute\n",
            "147.40ms     172ns  cuDeviceGetAttribute\n",
            "147.40ms     178ns  cuDeviceGetAttribute\n",
            "147.40ms     165ns  cuDeviceGetAttribute\n",
            "147.40ms     176ns  cuDeviceGetAttribute\n",
            "147.40ms     174ns  cuDeviceGetAttribute\n",
            "147.40ms  53.143us  cuDeviceGetAttribute\n",
            "147.46ms     189ns  cuDeviceGetAttribute\n",
            "147.46ms     172ns  cuDeviceGetAttribute\n",
            "147.46ms     177ns  cuDeviceGetAttribute\n",
            "147.46ms     167ns  cuDeviceGetAttribute\n",
            "147.46ms     181ns  cuDeviceGetAttribute\n",
            "147.46ms     183ns  cuDeviceGetAttribute\n",
            "147.46ms     184ns  cuDeviceGetAttribute\n",
            "147.46ms     180ns  cuDeviceGetAttribute\n",
            "147.46ms     184ns  cuDeviceGetAttribute\n",
            "147.46ms     176ns  cuDeviceGetAttribute\n",
            "147.46ms     179ns  cuDeviceGetAttribute\n",
            "147.46ms     166ns  cuDeviceGetAttribute\n",
            "147.46ms     167ns  cuDeviceGetAttribute\n",
            "147.46ms     158ns  cuDeviceGetAttribute\n",
            "147.46ms     159ns  cuDeviceGetAttribute\n",
            "147.46ms     174ns  cuDeviceGetAttribute\n",
            "147.46ms     174ns  cuDeviceGetAttribute\n",
            "147.46ms     201ns  cuDeviceGetAttribute\n",
            "147.46ms     181ns  cuDeviceGetAttribute\n",
            "147.46ms     181ns  cuDeviceGetAttribute\n",
            "147.46ms     175ns  cuDeviceGetAttribute\n",
            "147.46ms  41.271us  cuDeviceGetAttribute\n",
            "147.50ms     193ns  cuDeviceGetAttribute\n",
            "147.51ms     183ns  cuDeviceGetAttribute\n",
            "147.51ms     175ns  cuDeviceGetAttribute\n",
            "147.51ms     243ns  cuDeviceGetAttribute\n",
            "147.51ms     169ns  cuDeviceGetAttribute\n",
            "147.51ms     183ns  cuDeviceGetAttribute\n",
            "147.51ms     178ns  cuDeviceGetAttribute\n",
            "147.51ms     536ns  cuDeviceGetAttribute\n",
            "147.51ms     209ns  cuDeviceGetAttribute\n",
            "147.51ms     174ns  cuDeviceGetAttribute\n",
            "147.51ms     166ns  cuDeviceGetAttribute\n",
            "147.51ms     667ns  cuDeviceGetAttribute\n",
            "147.51ms     176ns  cuDeviceGetAttribute\n",
            "147.51ms     354ns  cuDeviceGetAttribute\n",
            "147.51ms     164ns  cuDeviceGetAttribute\n",
            "147.51ms     179ns  cuDeviceGetAttribute\n",
            "147.51ms     181ns  cuDeviceGetAttribute\n",
            "147.51ms     256ns  cuDeviceGetUuid\n",
            "147.51ms     202ns  cuDeviceGetAttribute\n",
            "147.51ms     170ns  cuDeviceGetAttribute\n",
            "147.51ms     174ns  cuDeviceGetAttribute\n",
            "147.51ms     177ns  cuDeviceGetAttribute\n",
            "147.51ms     673ns  cuDeviceGetAttribute\n",
            "147.52ms     218ns  cuDeviceGetAttribute\n",
            "147.52ms     174ns  cuDeviceGetAttribute\n",
            "147.52ms     472ns  cuDeviceGetAttribute\n",
            "147.52ms     183ns  cuDeviceGetAttribute\n",
            "147.52ms     163ns  cuDeviceGetAttribute\n",
            "147.52ms     178ns  cuDeviceGetAttribute\n",
            "147.52ms     217ns  cuDeviceGetAttribute\n",
            "147.52ms     180ns  cuDeviceGetAttribute\n",
            "147.52ms     183ns  cuDeviceGetAttribute\n",
            "147.52ms     176ns  cuDeviceGetAttribute\n",
            "147.52ms     174ns  cuDeviceGetAttribute\n",
            "147.58ms  187.08ms  cudaMalloc\n",
            "334.66ms  13.475us  cudaMemset\n",
            "334.68ms  39.495ms  cudaLaunchKernel (kernel1(int*) [127])\n",
            "374.18ms  31.616us  cudaMemcpy\n",
            "374.24ms  9.9880us  cudaMemset\n",
            "374.25ms  17.762us  cudaLaunchKernel (kernel2(int*) [130])\n",
            "374.27ms  19.663us  cudaMemcpy\n",
            "374.30ms  5.3970us  cudaMemset\n",
            "374.31ms  12.527us  cudaLaunchKernel (kernel3(int*) [133])\n",
            "374.32ms  16.849us  cudaMemcpy\n",
            "374.35ms  153.60us  cudaFree\n",
            "376.44ms  30.329ms  cudaDeviceReset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some useful `nvprof` arguments:**\n",
        "\n",
        "- `--log-file file`: output into a file\n",
        "- `--csv`: output is csv file\n",
        "- `--analysis-metrics -o file.nvprof`: capture all of the GPU metrics that the Visual Profiler needs for its “guided analysis” mode\n",
        "- `--print-summary-per-gpu`: print one summary per GPU if multiple CUDA capable devices are profiled\n",
        "- `--query-events`: list of all available events on a particular NVIDIA GPU\n",
        "- `--query-metrics`: list of all available metrics on a particular NVIDIA GPU\n",
        "- `--events all`: collect all events available on each device\n",
        "- `--metrics all`: collect all metrics available on each device\n",
        "- `--timeout sec_num`: the CUDA application being profiled will be killed after the timeout\n",
        "- `--concurrent-kernels off`: forces concurrent kernel executions to be serialized when a CUDA application is run with `nvprof`\n",
        "- `--devices <device IDs>`: profile kernels run only on specific devices\n",
        "- `--kernels <kernel filter>` where kernel filter is `<kernel name>` or `<context id/name>:<stream id/name>:<kernel name>:<invocation>`\n",
        "- `--cpu-profiling on` (has restrictions)"
      ],
      "metadata": {
        "id": "JMvhepuRm4-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Event/metric Trace Mode:**\n",
        "\n",
        "- event and metric values are shown for each kernel execution\n",
        "- by default, event and metric values are aggregated across all units in the GPU (for example, multiprocessor specific events are aggregated across all multiprocessors on the GPU; turn off: `--aggregate-mode off`)"
      ],
      "metadata": {
        "id": "hoWgbyTquIPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --log-file out.nvprof ./simpleCUDA"
      ],
      "metadata": {
        "id": "lcmJ06sYtXL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042923dd-8da6-4f58-a52f-885389140675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7 \n",
            " 0  0  0  0  1  1  1  1  2  2  2  2  3  3  3  3 \n",
            " 0  1  2  3  0  1  2  3  0  1  2  3  0  1  2  3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nsight Systems\n",
        "\n",
        "- Statistical sampling profiler with tracing features\n",
        "- Some terms:\n",
        "  - *Target* - device on which profiling happens\n",
        "  - *Host* - computer on which the user works and controls the profiling session\n",
        "  - Profiling - process of collecting any performance data\n",
        "  - Profilee - app under investigation during the profiling session\n",
        "  - Backtraces - call stack of active threads\n",
        "  - Sampling - process of periodically stopping the profilee, typically to collect backtraces, which allows you to understand statistically how much time is spent in each function\n",
        "  - Tracing - process of collecting precise information about various activities happening in the profilee or in the system (for example, profilee API execution may be traced providing the exact time and duration of a function call)\n",
        "\n",
        "System requirements: https://docs.nvidia.com/nsight-systems/InstallationGuide/index.html#installation-guide"
      ],
      "metadata": {
        "id": "95FtEn3DEmI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation in Google Collab ([Инструкция на Stack Overflow](https://stackoverflow.com/questions/76784746/how-to-use-nsys-in-google-colab))"
      ],
      "metadata": {
        "id": "6AucdT_3JL2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt update\n",
        "!apt install ./nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt --fix-broken install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oxARcGkIn2i",
        "outputId": "3238eca1-d94d-44e6-f9bd-7dc4191b155a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-14 09:25:59--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.20.126\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.20.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 317705436 (303M) [application/x-deb]\n",
            "Saving to: ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’\n",
            "\n",
            "nsight-systems-2023 100%[===================>] 302.99M   155MB/s    in 1.9s    \n",
            "\n",
            "2024-02-14 09:26:01 (155 MB/s) - ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’ saved [317705436/317705436]\n",
            "\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,735 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,342 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,068 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,455 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,784 kB]\n",
            "Fetched 7,617 kB in 2s (3,113 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "33 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'nsight-systems-2023.2.3' instead of './nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 libxtst6\n",
            "The following NEW packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 libxtst6 nsight-systems-2023.2.3\n",
            "0 upgraded, 12 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 318 MB of archives.\n",
            "After this operation, 1,269 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2023.2.3 2023.2.3.1001-32894139v0 [318 MB]\n",
            "Fetched 318 MB in 13s (25.0 MB/s)\n",
            "Selecting previously unselected package libtinfo5:amd64.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../01-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../02-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../03-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../04-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../05-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../06-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../07-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../08-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../09-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../10-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package nsight-systems-2023.2.3.\n",
            "Preparing to unpack .../11-nsight-systems-2023.2.3_2023.2.3.1001-32894139v0_amd64.deb ...\n",
            "Unpacking nsight-systems-2023.2.3 (2023.2.3.1001-32894139v0) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up nsight-systems-2023.2.3 (2023.2.3.1001-32894139v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.2.3/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Command Line Options:**\n",
        "- `nsys [global_option]`\n",
        "- `nsys [command_switch][optional command_switch_options][application] [optional application_options]`\n",
        "\n",
        "*Short v.s. long options: *\n",
        "- `-s process-tree`\n",
        "- `--sample=process-tree`\n",
        "\n",
        "**Global options:**\n",
        "- `--help / -h`\n",
        "- `--version / -v`"
      ],
      "metadata": {
        "id": "LFEoUa48JrjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSZod3GmGwBz",
        "outputId": "b25d1cbb-4af1-4a5a-a06f-c74a34caa577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " usage: nsys [--version] [--help] <command> [<args>] [application] [<application args>]\n",
            "\n",
            " The most commonly used nsys commands are:\n",
            "\tprofile       Run an application and capture its profile into a QDSTRM file.\n",
            "\tlaunch        Launch an application ready to be profiled.\n",
            "\tstart         Start a profiling session.\n",
            "\tstop          Stop a profiling session and capture its profile into a QDSTRM file.\n",
            "\tcancel        Cancel a profiling session and discard any collected data.\n",
            "\tservice       Launch the Nsight Systems data service.\n",
            "\tstats         Generate statistics from an existing nsys-rep or SQLite file.\n",
            "\tstatus        Provide current status of CLI or the collection environment.\n",
            "\tshutdown      Disconnect launched processes from the profiler and shutdown the profiler.\n",
            "\tsessions list List active sessions.\n",
            "\texport        Export nsys-rep file into another format.\n",
            "\tanalyze       Identify optimization opportunities in a nsys-rep or SQLITE file.\n",
            "\trecipe        Run a recipe for multi-node analysis.\n",
            "\tnvprof        Translate nvprof switches to nsys switches and execute collection.\n",
            "\n",
            " Use 'nsys --help <command>' for more information about a specific command.\n",
            "\n",
            " To run a basic profiling session:   nsys profile ./my-application\n",
            " For more details see \"Profiling from the CLI\" at https://docs.nvidia.com/nsight-systems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Profile Command**\n",
        "\n",
        "`nsys [global-options] profile [options] <application> [application-arguments]`\n",
        "\n",
        "[Profile options](https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-profile-command-switch-options)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K0GgdR2sLMQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys export --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1n4Mitx74l4",
        "outputId": "99f43a14-5f9a-4d51-cf54-f06e7e569548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "usage: nsys export [<args>] [nsys-rep-file]\n",
            "\n",
            "\t-f, --force-overwrite=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   If true, overwrite all existing result files with same output filename\n",
            "\t   (QDSTRM, nsys-rep, SQLITE, HDF, TEXT, ARROW, JSON).\n",
            "\t   Default is 'false'.\n",
            "\n",
            "\t-h, --help=[<tag>]\n",
            "\n",
            "\t   Print the command's help menu. The switch can take one optional\n",
            "\t   argument that will be used as a tag. If a tag is provided, only options\n",
            "\t   relevant to the tag will be printed.\n",
            "\t   The available help menu tags for this command are:\n",
            "\n",
            "\t   export, output, and type.\n",
            "\n",
            "\t-l, --lazy=\n",
            "\n",
            "           Possible values are 'true' or 'false'.\n",
            "           Controls if table creation is lazy or not. Lazy table creation will\n",
            "           only create a table if it contains data. This affects SQLite, HDF5,\n",
            "           and Arrow exports only. Default is 'true', although this is\n",
            "           likely to change in a future release.\n",
            "\n",
            "\t-o, --output=\n",
            "\n",
            "           Path to results file.\n",
            "           Default is name of input file with modified extension.\n",
            "\n",
            "\t-q, --quiet=\n",
            "\n",
            "           Possible values are 'true' or 'false'.\n",
            "           If 'true', don't display progress bar.\n",
            "           Default is 'false'.\n",
            "\n",
            "\t--separate-strings=\n",
            "\n",
            "           Possible values are 'true' or 'false'.\n",
            "           Output stored strings and thread names separately, one\n",
            "           value per line. This affects JSON and text output only.\n",
            "           Default is 'false'.\n",
            "\n",
            "\t-t, --type=\n",
            "\n",
            "           Possible values are: sqlite, hdf, text, arrow, json, info.\n",
            "           Export format type.\n",
            "           HDF format is supported only on x86-64 Linux and Windows.\n",
            "\n",
            "\t--ts-normalize=\n",
            "\n",
            "           Possible values are 'true' or 'false'.\n",
            "           If true, all timestamp values in the report will be shifted to\n",
            "           UTC wall-clock time, as defined by the UNIX epoch. This option can\n",
            "           be used in conjunction with the --ts-shift option, in which case both\n",
            "           adjustments will be applied.\n",
            "           If this option is used to align a series of reports from a cluster\n",
            "           or distributed system, the accuracy of the alignment is limited by\n",
            "           the synchronization precision of the system clocks. For detailed\n",
            "           analysis, the use of PTP or another high-precision synchronization\n",
            "           methodology is recommended. NTP is unlikely to produce desirable\n",
            "           results.\n",
            "           This option only applies to Arrow, HDF5, and SQLite exports.\n",
            "           Default is 'false'.\n",
            "\n",
            "\t--ts-shift=\n",
            "\n",
            "           The value is a signed integer in nanoseconds.\n",
            "           If given, all timestamp values in the report will be shifted by\n",
            "           the given amount. This option can be used in conjunction with the\n",
            "           --ts-normalize option, in which case both adjustments will be applied.\n",
            "           This option can be used to \"hand-align\" report files captured at\n",
            "           different times, or reports captured on distributed systems with\n",
            "           poorly synchronized system clocks.\n",
            "           This option only applies to Arrow, HDF5, and SQLite exports.\n",
            "           Default is 0.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR5L6JdfMq8J",
        "outputId": "cff1f928-a4a7-49e8-988c-c64c6771153f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "usage: nsys profile [<args>] [application] [<application args>]\n",
            "\n",
            "\t-b, --backtrace=\n",
            "\n",
            "\t   Possible values are 'lbr', 'fp', 'dwarf', or 'none'.\n",
            "\t   Select the backtrace method to use while sampling.\n",
            "\t   Select 'none' to disable backtrace collection.\n",
            "\t   Default is 'lbr'.\n",
            "\n",
            "\t-c, --capture-range=\n",
            "\n",
            "\t   Possible values are none, cudaProfilerApi, nvtx, hotkey.\n",
            "\t   When '-c cudaProfilerApi' is used, profiling will start only when cudaProfilerStart API is\n",
            "\t   invoked in the application.\n",
            "\t   When '-c nvtx' is used, profiling will start only when the specified NVTX range is\n",
            "\t   started in the application.\n",
            "\t   When '-c hotkey' is used, profiling will start only when the hotkey\n",
            "\t   set by '--hotkey-capture' is pressed in the application. This works for graphic apps only.\n",
            "\t   Note that you must enable CUDA or NVTX tracing of the target application\n",
            "\t   for '-c cudaProfilerApi' or '-c nvtx' to work.\n",
            "\t   When '-capture-range none' is used, cudaProfilerStart/Stop APIs and hotkey will \n",
            "\t   be ignored and NVTX ranges will be ignored as collection start/stop triggers.\n",
            "\t   Default is none.\n",
            "\n",
            "\t--capture-range-end=\n",
            "\n",
            "\t   Possible values are 'none', 'stop', 'stop-shutdown', 'repeat[:N]' or 'repeat-shutdown:N'.\n",
            "\t   Specify the desired behavior when a capture range ends. Applicable only when used along\n",
            "\t   with --capture-range option.\n",
            "\t   If 'none', capture range end will be ignored.\n",
            "\t   If 'stop', collection will stop at capture range end. Any subsequent capture ranges will be\n",
            "\t   ignored. Target app will continue running.\n",
            "\t   If 'stop-shutdown', collection will stop at capture range end and session will be shutdown.\n",
            "\t   If 'repeat[:N]', collection will stop at capture range end and subsequent capture ranges\n",
            "\t   will trigger more collections. \n",
            "\t   Use the optional ':N' to specify max number of capture ranges to be honored. Any subsequent\n",
            "\t   capture ranges will be ignored once N capture ranges are collected.\n",
            "\t   If 'repeat-shutdown:N', same behavior as 'repeat:N' but session will be shutdown after N\n",
            "\t   ranges.\n",
            "\t   For 'stop-shutdown' and 'repeat-shutdown:N', use --kill option to specify the signal to be\n",
            "\t   sent to target app when shutting down session.\n",
            "\t   Default is 'stop-shutdown'.\n",
            "\n",
            "\t--command-file=\n",
            "\n",
            "\t   Open a file that contains nsys switches and parse the switches. Note that\n",
            "\t   command line switches will override switches found in the command-file.\n",
            "\n",
            "\t--cpu-core-events=\n",
            "\n",
            "\t   CPU Core events to sample.\n",
            "\t   Possible values are (for example) '2,3,...'.\n",
            "\t   Use the '--cpu-core-events=help' switch to see the full list of events.\n",
            "\t   Multiple values can be selected, separated by commas only (no spaces).\n",
            "\t   Use the --event-sample switch to enable.\n",
            "\n",
            "\t--cpuctxsw=\n",
            "\n",
            "\t   Possible values are 'process-tree', 'system-wide', or 'none'.\n",
            "\t   Trace OS thread scheduling activity. Select 'none' to disable tracing CPU context switches. \n",
            "\t   If CPU IP/backtrace sampling is enabled, --cpuctxsw equals the --sample setting.\n",
            "\t   For example, if --sample=process-tree, then --cpuctxsw=process-tree.\n",
            "\t   If --sample=none and a target application is launched, the default is 'process-tree',\n",
            "\t   otherwise the default is 'none'.\n",
            "\n",
            "\t--cuda-flush-interval=\n",
            "\n",
            "\t   Set the interval, in milliseconds, when buffered CUDA data is automatically saved to\n",
            "\t   storage. CUDA data buffer saves may cause profiler overhead. Buffer save behavior can be\n",
            "\t   controlled with this switch.\n",
            "\n",
            "\t   If the CUDA flush interval is set to 0 on systems running CUDA 11.0 or newer, buffers are\n",
            "\t   saved when they fill. If a flush interval is set to a non-zero value on such systems, \n",
            "\t   buffers are saved only when the flush interval expires. If a flush interval is set and the\n",
            "\t   profiler runs out of available buffers before the flush interval expires, additional buffers\n",
            "\t   will be allocated as needed. In this case, setting a flush interval can reduce buffer\n",
            "\t   save overhead but increase memory use by the profiler.\n",
            "\n",
            "\t   If the flush interval is set to 0 on systems running older versions of CUDA, \n",
            "\t   buffers are saved at the end of the collection. If the profiler runs out of available\n",
            "\t   buffers, additional buffers are allocated as needed. If a flush interval is set to a\n",
            "\t   non-zero value on such systems, buffers are saved when the flush interval expires.\n",
            "\t   A cuCtxSynchronize call may be inserted into the workflow before the buffers\n",
            "\t   are saved which will cause application overhead. In this case, setting a flush interval\n",
            "\t   can reduce memory use by the profiler but may increase save overhead.\n",
            "\t   Default is '0'. Application scope.\n",
            "\n",
            "\t--cuda-graph-trace=\n",
            "\n",
            "\t   Possible values are 'graph' or 'node'.\n",
            "\t   Set the granularity for CUDA graph trace. Applicable only when CUDA tracing is enabled.\n",
            "\t   If 'graph' is selected, CUDA graphs will be traced as a whole and node\n",
            "\t   activities will not be collected. This can reduce overhead to the minimal,\n",
            "\t   but requires CUDA driver version 11.7 or higher.\n",
            "\t   If 'node' is selected, node activities will be collected, but CUDA graphs\n",
            "\t   will not be traced as a whole. This may cause significant runtime overhead.\n",
            "\t   If CUDA driver version is 11.7 or higher, default is 'graph', otherwise default is 'node'.\n",
            "\t   Application scope.\n",
            "\n",
            "\t--cuda-memory-usage=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Track the GPU memory usage. Applicable only when CUDA tracing is enabled.\n",
            "\t   This feature may cause significant runtime overhead.\n",
            "\t   Default is 'false'. Application scope.\n",
            "\n",
            "\t--cuda-um-cpu-page-faults=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Track the CPU page faults that occur with Unified Memory.\n",
            "\t   Applicable only when CUDA tracing is enabled.\n",
            "\t   This feature may cause significant runtime overhead.\n",
            "\t   Default is 'false'. Application scope.\n",
            "\n",
            "\t--cuda-um-gpu-page-faults=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Track the GPU page faults that occur with Unified Memory.\n",
            "\t   Applicable only when CUDA tracing is enabled.\n",
            "\t   This feature may cause significant runtime overhead.\n",
            "\t   Default is 'false'. Application scope.\n",
            "\n",
            "\t--cudabacktrace=\n",
            "\n",
            "\t   Possible values are 'all','none','kernel','memory','sync','other'.\n",
            "\t   If tracing CUDA APIs, enable the collection of a backtrace when a CUDA API is invoked.\n",
            "\t   When selected, significant runtime overhead may occur.\n",
            "\t   Values may be combined using ','.\n",
            "\t   Each value except 'none' may be appended with a threshold after ':'.\n",
            "\t   Threshold is the duration, in nanoseconds, that CUDA APIs must execute before backtraces are\n",
            "\t   collected, e.g. 'kernel:500'.\n",
            "\t   Default value for each threshold is 80000ns (80us).\n",
            "\t   Note that CPU sampling must be enabled.\n",
            "\t   Default is 'none'. Application scope.\n",
            "\n",
            "\t-d, --duration=\n",
            "\n",
            "\t   Collection duration in seconds.\n",
            "\t   Default is 0 seconds.\n",
            "\n",
            "\t--duration-frames=\n",
            "\n",
            "\t   Stop the recording session after this many frames have been captured.\n",
            "\t   Minimum supported frame is '60'.\n",
            "\t   Note when it is selected cannot include any other stop options.\n",
            "\t   If not specified the default is disabled. Application scope.\n",
            "\n",
            "\t-e, --env-var=\n",
            "\n",
            "\t   Set environment variable(s) for application process to be launched.\n",
            "\t   Environment variable(s) should be defined as 'A=B'.\n",
            "\t   Multiple environment variables can be specified as 'A=B,C=D'\n",
            "\n",
            "\t--event-sample=\n",
            "\n",
            "\t   Enable event sampling.\n",
            "\t   Possible values are 'system-wide' or 'none'.\n",
            "\t   Select 'none' to disable event sampling.\n",
            "\t   The default is 'none'.\n",
            "\t   Use the '--cpu-core-events=help' and the '--os-events=help' switches to see the \n",
            "\t   full list of events.\n",
            "\t   If event sampling is enabled and no events are selected, \n",
            "\t   the CPU Core event 'Instructions Retired' is selected by default.\n",
            "\n",
            "\t--event-sampling-frequency=\n",
            "\n",
            "\t   The sampling frequency used to collect event counts.\n",
            "\t   Minimum event sampling frequency is '1' Hz.\n",
            "\t   Maximum event sampling frequency is '20' Hz.\n",
            "\t   The default is '3' Hz.\n",
            "\n",
            "\t--export=<format>[,<format>...]\n",
            "\n",
            "\t   Possible formats are: none arrow sqlite hdf text json\n",
            "\t   Create additional output file(s) based on the data collected.\n",
            "\t   If 'none' is selected, no additional files are created.\n",
            "\t   Default is 'none'. This option can be given more than once.\n",
            "\n",
            "\t-f, --force-overwrite=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   If true, overwrite all existing result files with same output filename\n",
            "\t   (QDSTRM, nsys-rep, SQLITE, HDF, TEXT, ARROW, JSON).\n",
            "\t   Default is 'false'.\n",
            "\n",
            "\t--flush-on-cudaprofilerstop=\n",
            "\n",
            "           If set to 'true', any call to cudaProfilerStop() will\n",
            "           cause the CUDA trace buffers to be flushed. Note that the CUDA trace\n",
            "           buffers will be flushed when the collection ends, irrespective of the\n",
            "           value of this switch. Default value is 'true'.\n",
            "\n",
            "\t--ftrace=\n",
            "\n",
            "\t   Collect ftrace events.\n",
            "\t   Argument should list events to collect as: subsystem1/event1,subsystem2/event2.\n",
            "\t   Requires root privileges.\n",
            "\t   Default is '' (no ftrace events are collected by default). System scope.\n",
            "\n",
            "\t--ftrace-keep-user-config=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Skip initial ftrace setup and collect already configured events.\n",
            "\t   Default is 'false' (nsys will reset the ftrace configuration).\n",
            "\n",
            "\t--gpu-metrics-device=\n",
            "\n",
            "\t   Collect GPU Metrics from specified devices.\n",
            "\t   The option argument must be 'none' or one of GPU IDs reported\n",
            "\t   by '--gpu-metrics-device=help' switch.\n",
            "\t   Default is 'none'. System scope.\n",
            "\n",
            "\t--gpu-metrics-frequency=\n",
            "\n",
            "\t   Specify GPU Metrics sampling frequency.\n",
            "\t   Minimum supported frequency is '10' (Hz).\n",
            "\t   Maximum supported frequency is '200000' (Hz).\n",
            "\t   Default is '10000'. System scope.\n",
            "\n",
            "\t--gpu-metrics-set=\n",
            "\n",
            "\t   Specify metric set for GPU Metrics sampling.\n",
            "\t   The option argument must be one of indices reported by '--gpu-metrics-set=help' switch.\n",
            "\t   Default is the first metric set that supports selected GPU. System scope.\n",
            "\n",
            "\t--gpuctxsw=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Trace GPU context switches. This switch requires CUDA driver r435.17 or higher.\n",
            "\t   Default is 'false'. System scope.\n",
            "\n",
            "\t-h, --help=[<tag>]\n",
            "\n",
            "\t   Print the command's help menu. The switch can take one optional\n",
            "\t   argument that will be used as a tag. If a tag is provided, only options\n",
            "\t   relevant to the tag will be printed.\n",
            "\t   The available help menu tags for this command are:\n",
            "\n",
            "\t   app, application, backtrace, capture, cli, command, cpu, cuda, env,\n",
            "\t   environment, export, file, filter, fork, frame, ftrace, gpu, hotkey,\n",
            "\t   interactive, log, logs, memory, metrics, mpi, network, nic, nvtx, opengl, os,\n",
            "\t   osrt, output, pmu, profile, profiling, range, run, sample, sampling, session,\n",
            "\t   stats, switch, symbol, symbols, trace, user, uvm, vulkan, and wait.\n",
            "\n",
            "\t--hotkey-capture=\n",
            "\n",
            "\t   Possible values are `F1` to `F12`.\n",
            "\t   Hotkey to trigger the profiling session.\n",
            "\t   Note that this switch is applicable only when --capture-range=hotkey is specified.\n",
            "\t   Default is `F12`.\n",
            "\n",
            "\t(Experimental) --ib-switch-metrics=<IB switch GUID>[,<IB switch GUID>...]\n",
            "\n",
            "\t   A comma-separated list of InfiniBand switch GUIDs.\n",
            "\t   Collect metrics from the specified InfiniBand switches.\n",
            "\t   This switch can be used multiple times.\n",
            "\t   Default is an empty list.\n",
            "\n",
            "\t--kill=\n",
            "\n",
            "\t   Possible values are 'none', 'sigkill', 'sigterm', or signal number.\n",
            "\t   Send signal to the target application's process group when ending/shutting down profiling session.\n",
            "\t   Default is 'sigterm', so the application is terminated when profiling session ends/is shutdown.\n",
            "\n",
            "\t--mpi-impl=\n",
            "\n",
            "\t   Possible values are 'openmpi' or 'mpich'.\n",
            "\t   Specify the MPI implementation used by the application.\n",
            "\t   Use 'mpich' for MPICH and its derivatives.\n",
            "\t   Note that this switch is applicable only when --trace=mpi is specified.\n",
            "\t   If no MPI implementation is specified, nsys tries to automatically detect it based on the\n",
            "\t   dynamic linker's search path. If this fails, 'openmpi' is used.\n",
            "\n",
            "\t-n, --inherit-environment=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Inherit environment variables.\n",
            "\t   Default is 'true'.\n",
            "\n",
            "\t--nic-metrics=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Collect metrics from NIC/HCA devices.\n",
            "\t   Default is 'false'.\n",
            "\n",
            "\t--nvtx-domain-[include|exclude]=\n",
            "\n",
            "\t   Possible values are a comma-separated list of NVTX domains.\n",
            "\t   Choose the include or exclude option to (only) include or exclude the specified domains. The\n",
            "\t   options are mutually exclusive. 'default' filters the NVTX default domain. A domain with\n",
            "\t   this name and commas in a domain name have to be escaped with '\\'.\n",
            "\t   Note that both switches are applicable only when --trace=nvtx is specified.\n",
            "\n",
            "\t-o, --output=\n",
            "\n",
            "\t   Output report filename.\n",
            "\t   Any %q{ENV_VAR} pattern in the filename will be substituted with the value of the \n",
            "\t   environment variable.\n",
            "\t   Any %h pattern in the filename will be substituted with the hostname of the system.\n",
            "\t   Any %p pattern in the filename will be substituted with the PID of the target process or\n",
            "\t   the PID of the root process if there is a process tree.\n",
            "\t   Any %% pattern in the filename will be substituted with %.\n",
            "\t   Default is report#.{nsys-rep,sqlite,h5,txt,arrows,json}.\n",
            "\n",
            "\t--opengl-gpu-workload=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   If true, trace the OpenGL workload's GPU activity.\n",
            "\t   Note that this switch is applicable only when --trace=opengl is specified.\n",
            "\t   Default is 'true'. Application scope.\n",
            "\n",
            "\t--os-events=\n",
            "\n",
            "\t   OS events to sample.\n",
            "\t   Possible values are (for example) '0,3,...'.\n",
            "\t   Use the '--os-events=help' switch to see the full list of events.\n",
            "\t   Multiple values can be selected, separated by commas only (no spaces).\n",
            "\t   Use the --event-sample switch to enable.\n",
            "\n",
            "\t--osrt-backtrace-stack-size=\n",
            "\n",
            "\t   Set the stack dump size, in bytes, to generate backtraces for OS runtime libraries calls.\n",
            "\t   Default is 6144 (6 KiB).\n",
            "\n",
            "\t--osrt-backtrace-threshold=\n",
            "\n",
            "\t   Set the duration, in nanoseconds, that all OS  runtime  libraries calls must execute before\n",
            "\t   backtraces are collected.\n",
            "\t   Default is 80000 (80 microseconds).\n",
            "\n",
            "\t--osrt-threshold=\n",
            "\n",
            "\t   Set the duration, in nanoseconds, that Operating System Runtime (osrt) APIs must execute\n",
            "\t   before they are traced. Values much less than 1000 may cause significant overhead and\n",
            "\t   result in extremely large result files.\n",
            "\t   Default is 1000 (1 microsecond).\n",
            "\n",
            "\t-p, --nvtx-capture=\n",
            "\n",
            "\t   Possible values are: `range@domain' to specify both range and\n",
            "\t   domain, `range' to specify range in default domain, `range@*' to specify range in any\n",
            "\t   domain.\n",
            "\t   NVTX range text and domain to trigger the profiling session.\n",
            "\t   Note that this switch is applicable only when --capture-range=nvtx is specified.\n",
            "\n",
            "\t--python-backtrace=\n",
            "\n",
            "\t   Possible values are 'cuda', 'none', 'false'.\n",
            "\t   Specify Python backtrace collection trigger.\n",
            "\t   Multiple APIs can be selected, separated by commas only (no spaces).\n",
            "\t   Note that you must enable tracing for the selected API.\n",
            "\t   Default is 'none'.\n",
            "\n",
            "\t--python-sampling=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Sample Python backtrace.\n",
            "\t   Default is 'false'.\n",
            "\t   Note: This feature provides meaningful backtraces for Python processes. \n",
            "\t   When profiling Python-only workflows, consider disabling the CPU sampling option to reduce overhead.\n",
            "\n",
            "\t--python-sampling-frequency=\n",
            "\n",
            "\t   Specify Python sampling frequency.\n",
            "\t   Minimum supported frequency is '1' (Hz).\n",
            "\t   Maximum supported frequency is '2000' (Hz).\n",
            "\t   Default is '1000' (Hz).\n",
            "\n",
            "\t--resolve-symbols=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Resolve symbols of captured samples and backtraces.\n",
            "\t   Default is 'false' on Windows, 'true' on other platforms.\n",
            "\n",
            "\t--run-as=\n",
            "\n",
            "\t   Run the target application as the specified username.\n",
            "\t   If not specified, the target application will be run by the same user\n",
            "\t   as Nsight Systems.\n",
            "\t   Requires root privileges.\n",
            "\n",
            "\t-s, --sample=\n",
            "\n",
            "\t   Possible values are 'process-tree', 'system-wide' or 'none'.\n",
            "\t   Collect CPU IP/backtrace samples. Select 'none' to disable sampling. \n",
            "\t   If a target application is launched, the default is 'process-tree', otherwise the default\n",
            "\t   is 'none'.\n",
            "\n",
            "\t--samples-per-backtrace=\n",
            "\n",
            "\t   Possible values are integers between 1 and 32.\n",
            "\t   The number of CPU IP samples collected for every CPU IP sample backtrace collected. For \n",
            "\t   example, if set to 4, on the fourth CPU IP sample collected, a backtrace will also be \n",
            "\t   collected. Lower values increase the amount of data collected. Higher values can reduce \n",
            "\t   overhead and help reduce the number of CPU IP samples dropped. \n",
            "\t   Default is 1. If DWARF backtraces are collected, the default is 4.\n",
            "\n",
            "\t--sampling-period=\n",
            "\n",
            "\t   Possible values are integers between 16000000 and 125000.\n",
            "\t   The number of CPU Clock (sw) events counted before a CPU instruction pointer (IP)\n",
            "\t   sample is collected. \n",
            "\t   If configured, backtraces may also be collected. The smaller the sampling period, the higher\n",
            "\t   the sampling rate. \n",
            "\t   Note that lower sampling periods will increase overhead and significantly increase the size\n",
            "\t   of the result file(s). \n",
            "\t   Default is 1000000. If DWARF backtraces are collected, the default is 2000000.\n",
            "\n",
            "\t--session-new=\n",
            "\n",
            "\t   Start the collection in a new named session. The option  argument represents the session\n",
            "\t   name.\n",
            "\t   The session name must start with an alphabetical character followed by printable or space\n",
            "\t   characters.\n",
            "\t   Any '%q{ENV_VAR}' pattern in the session name will be substituted with the value of the\n",
            "\t   environment variable.\n",
            "\t   Any '%h' pattern in the option argument will be substituted with the hostname of the system.\n",
            "\t   Any '%%' pattern in the option argument will be substituted with '%'.\n",
            "\n",
            "\t--start-frame-index=\n",
            "\n",
            "\t   Start the recording session when the frame index reaches the frame number preceding the\n",
            "\t   start frame index. Minimum supported frame is '1'.\n",
            "\t   Note when it is selected cannot include any other start options.\n",
            "\t   If not specified the default is disabled. Application scope.\n",
            "\n",
            "\t--stats=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Generate summary statistics after the collection.\n",
            "\t   When set to true, an SQLite database file will be created after the collection.\n",
            "\t   Default is 'false'.\n",
            "\n",
            "\t-t, --trace=\n",
            "\n",
            "\t   Possible values are 'cuda', 'nvtx', 'cublas', 'cublas-verbose', 'cusparse', \n",
            "\t   'cusparse-verbose', 'mpi', 'oshmem', 'ucx', 'osrt', 'cudnn', 'opengl', \n",
            "\t   'opengl-annotations', 'openacc', 'openmp', 'nvvideo', 'vulkan', \n",
            "\t   'vulkan-annotations' or 'none'.\n",
            "\t   Select the API(s) to trace. Multiple APIs can be selected, separated by commas only\n",
            "\t   (no spaces).\n",
            "\t   If '<api>-annotations' is selected, the corresponding API will also be traced.\n",
            "\t   If 'none' is selected, no APIs are traced.\n",
            "\t   Default is 'cuda,nvtx,osrt,opengl'. Application scope.\n",
            "\n",
            "\t--trace-fork-before-exec=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   If true, trace any child process after fork and before they call one of the exec functions.\n",
            "\t   Beware, tracing in this interval relies on undefined behavior and might cause your\n",
            "\t   application to crash or deadlock. This option is only available on Linux and Windows\n",
            "\t   target platforms.\n",
            "\t   Default is 'false'.\n",
            "\n",
            "\t--vulkan-gpu-workload=\n",
            "\n",
            "\t   Possible values are 'individual', 'batch', 'none', 'true' or 'false'.\n",
            "\t   If individual or true, trace each Vulkan workload's GPU activity individually.\n",
            "\t   If batch, trace Vulkan workloads' GPU activity in vkQueueSubmit call batches.\n",
            "\t   If none or false, do not trace Vulkan workloads' GPU activity.\n",
            "\t   Note that this switch is applicable only when --trace=vulkan is specified.\n",
            "\t   Default is 'individual'. Application scope.\n",
            "\n",
            "\t-w, --show-output=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   If true, send target process's stdout and stderr streams to both the console and\n",
            "\t   stdout/stderr files which are added to the QDSTRM file.\n",
            "\t   If false, only send target process stdout and stderr streams to the stdout/stderr files\n",
            "\t   which are added to the QDSTRM file.\n",
            "\t   Default is 'true'.\n",
            "\n",
            "\t--wait=\n",
            "\n",
            "\t   Possible values are 'primary' or 'all'.\n",
            "\t   If 'primary', the CLI will wait on the application process termination.\n",
            "\t   If 'all', the CLI will additionally wait on re-parented processes created by the\n",
            "\t   application.\n",
            "\t   Default is 'all'.\n",
            "\n",
            "\t-x, --stop-on-exit=\n",
            "\n",
            "\t   Possible values are 'true' or 'false'.\n",
            "\t   Stop profiling when the launched application exits.\n",
            "\t   If stop-on-exit=false, duration must be greater than 0.\n",
            "\t   Default is 'true'.\n",
            "\n",
            "\t-y, --delay=\n",
            "\n",
            "\t   Collection start delay in seconds.\n",
            "\t   Default is 0.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Useful options: **\n",
        "- `-t [cuda/nvtx/mpi/cudnn/opengl/openacc/none...]` - select APIs to trace (multiple APIs can be selected, separated by commas only)\n",
        "- `-d [number]` - collection duration in sec\n",
        "- `-o [file_name]` - generate output report file\n",
        "- `--gpu-metrics-device=[0/all...]` - collect GPUs metrics from specified device\n",
        "- `--gpu-metrics-set=[tu10x-gfxt/...]` - specify metric set for GPU Metrics sampling\n",
        "- `--sample=[process-tree/system-wide/none]` - collect CPU IP/backtrace samples\n",
        "- `--cpu-core-events=help` - get list of available CPU core events\n",
        "- `--stats=true` - generate summary statistics after the collection\n",
        "\n",
        "Profile Python script: `nsys profile python program.py`\n",
        "\n"
      ],
      "metadata": {
        "id": "kqbVM9HWM81L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Default analysis run*:\n",
        "\n",
        "`nsys profile <application> [application-arguments]`\n",
        "- start collecting immediately and end collection when the application stops\n",
        "- trace CUDA, OpenGL, NVTX, and OS runtime libraries APIs\n",
        "- collect CPU sampling information and thread scheduling information"
      ],
      "metadata": {
        "id": "0daLpZSIMwco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nvprof Command**:\n",
        "- `nsys nvprof [options]`\n",
        "- help former `nvprof` users transition to nsys\n",
        "- not all the commands from original `nvprof` are available in `nsys`!\n",
        "- [options](https://docs.nvidia.com/nsight-systems/UserGuide/index.html#cli-nvprof-command-switch-options)"
      ],
      "metadata": {
        "id": "mdqMgdrIQ_vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile example.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    for i in range(10):\n",
        "        x = np.array(range(10**7))\n",
        "        y = np.array(np.random.uniform(0, 100, size=(10**(8))))\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVu01lhZd8AX",
        "outputId": "5569ad05-c243-42f8-e3f7-5a76428d6ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile --stats=true --python-sampling=true python example.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vW7Ye1ReBVZ",
        "outputId": "a64367b6-0604-4c7f-c851-3e47d3a78f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating '/tmp/nsys-report-b102.qdstrm'\n",
            "[1/8] [========================100%] report1.nsys-rep\n",
            "[2/8] [========================100%] report1.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: No data available.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls  Avg (ns)   Med (ns)   Min (ns)  Max (ns)   StdDev (ns)           Name         \n",
            " --------  ---------------  ---------  ---------  ---------  --------  ---------  -----------  ----------------------\n",
            "     89.6      417,666,266      3,060  136,492.2  132,290.0    81,145  1,927,466     50,824.6  munmap                \n",
            "      4.5       21,131,650      3,071    6,881.0    6,363.0     4,577     94,738      3,093.2  mmap64                \n",
            "      3.2       14,891,475         62  240,185.1   16,495.5     8,312  1,831,022    415,088.4  pthread_cond_wait     \n",
            "      1.1        4,909,445         21  233,783.1    6,618.0     1,097  1,695,791    485,526.4  pthread_cond_timedwait\n",
            "      0.7        3,327,386        369    9,017.3    2,444.0       326    262,183     23,493.1  read                  \n",
            "      0.5        2,132,728        184   11,590.9    9,629.5     5,580    186,658     16,968.8  open64                \n",
            "      0.4        2,038,201     11,395      178.9       32.0        20     14,364      1,094.8  pthread_cond_signal   \n",
            "      0.0           55,227          5   11,045.4    5,603.0     2,541     33,892     12,905.2  fopen64               \n",
            "      0.0           39,610          4    9,902.5    4,023.0       971     30,593     13,870.0  fclose                \n",
            "      0.0           21,457         68      315.5      287.0        33      1,581        189.1  sigaction             \n",
            "      0.0            8,140          1    8,140.0    8,140.0     8,140      8,140          0.0  mmap                  \n",
            "      0.0            6,754          1    6,754.0    6,754.0     6,754      6,754          0.0  fputs_unlocked        \n",
            "      0.0            6,599          1    6,599.0    6,599.0     6,599      6,599          0.0  fread                 \n",
            "      0.0            2,903          3      967.7      842.0       612      1,449        432.4  dup                   \n",
            "      0.0            1,712          7      244.6      182.0       147        642        177.5  pthread_mutex_lock    \n",
            "      0.0            1,530          4      382.5      266.0        90        908        363.1  fflush                \n",
            "      0.0            1,299          1    1,299.0    1,299.0     1,299      1,299          0.0  getc                  \n",
            "      0.0              789          1      789.0      789.0       789        789          0.0  ioctl                 \n",
            "      0.0              702         11       63.8       47.0        26        255         65.0  flockfile             \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain GPU memory data.\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "SKIPPED: /content/report1.sqlite does not contain GPU memory data.\n",
            "Generated:\n",
            "    /content/report1.nsys-rep\n",
            "    /content/report1.sqlite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U py-boost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiuMfD1Oj1BE",
        "outputId": "5645c176-2791-463a-b339-5d3928d12655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py-boost\n",
            "  Downloading py_boost-0.4.3-py3-none-any.whl (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from py-boost) (1.3.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from py-boost) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from py-boost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from py-boost) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1 in /usr/local/lib/python3.10/dist-packages (from py-boost) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from py-boost) (4.66.1)\n",
            "Collecting treelite<4,>=3 (from py-boost)\n",
            "  Downloading treelite-3.9.1-py3-none-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treelite_runtime<4,>=3 (from py-boost)\n",
            "  Downloading treelite_runtime-3.9.1-py3-none-manylinux2014_x86_64.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->py-boost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->py-boost) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1->py-boost) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1->py-boost) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from treelite<4,>=3->py-boost) (23.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->py-boost) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1->py-boost) (1.16.0)\n",
            "Installing collected packages: treelite_runtime, treelite, py-boost\n",
            "Successfully installed py-boost-0.4.3 treelite-3.9.1 treelite_runtime-3.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile example2.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cupy as cp\n",
        "from py_boost.gpu.utils import *\n",
        "from astropy.table import Table\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "histogram_kernel_idx_elw = cp.ElementwiseKernel(\n",
        "    \"\"\"\n",
        "    uint64 i_, uint64 j_, uint64 k_,\n",
        "    uint64 kk,\n",
        "\n",
        "    raw uint64 jj,\n",
        "    raw bool padded_bool_indexer,\n",
        "\n",
        "    raw float32 target,\n",
        "    raw T arr,\n",
        "    raw int32 nodes,\n",
        "\n",
        "    uint64 hlen,\n",
        "    uint64 flen,\n",
        "    uint64 length,\n",
        "    uint64 feats,\n",
        "    uint64 nout\n",
        "    \"\"\",\n",
        "    'raw float32 hist',\n",
        "\n",
        "    \"\"\"\n",
        "    unsigned int feat_4t = arr[i_ * feats + j_];\n",
        "    int d;\n",
        "    int j;\n",
        "    int val;\n",
        "    int pos;\n",
        "    float *x_ptr;\n",
        "    float y = target[i_ * nout + k_];\n",
        "\n",
        "    for (d = 0; d < 4; d++) {\n",
        "\n",
        "        pos = (i_ + d) % 4;\n",
        "\n",
        "        if (padded_bool_indexer[j_ * 4 + pos]) {\n",
        "\n",
        "            val = (feat_4t >> (8 * pos)) % 256;\n",
        "            j = jj[j_ * 4 + pos];\n",
        "            x_ptr = &hist[0] +  kk * hlen + nodes[i_] * flen + j * length + val;\n",
        "            atomicAdd(x_ptr, y);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    \"\"\",\n",
        "\n",
        "    'histogram_kernel_idx')\n",
        "\n",
        "\n",
        "def fill_histogram_tmp(res, arr, target, nodes, col_indexer, row_indexer, out_indexer, func='elw'):\n",
        "    \"\"\"Fill the histogram res\n",
        "\n",
        "    Args:\n",
        "        res: cp.ndarray, histogram of zeros, shape (n_out, n_nodes, n_features, n_bins)\n",
        "        arr: cp.ndarray, features array, shape (n_data, n_features)\n",
        "        target: cp.ndarray, values to accumulate, shape (n_data, n_out)\n",
        "        nodes: cp.ndarray, tree node indices, shape (n_data, )\n",
        "        col_indexer: cp.ndarray, indices of features to accumulate\n",
        "        row_indexer: cp.ndarray, indices of rows to accumulate\n",
        "        out_indexer: cp.ndarray, indices of outputs to accumulate\n",
        "        func: numeric flag to choose the kernel that will be used in histogram calculations\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    # define data split for kernel launch\n",
        "    nout, nnodes, nfeats, nbins = res.shape\n",
        "\n",
        "    # padded array of 4 feature tuple\n",
        "    arr_4t = arr.base.view(dtype=cp.uint32)\n",
        "    pfeats = arr_4t.shape[1]\n",
        "\n",
        "    # create 4 feats tuple indexer\n",
        "    padded_bool_indexer = cp.zeros((arr.base.shape[1],), dtype=cp.bool_)\n",
        "    padded_col_indexer = cp.zeros((arr.base.shape[1],), dtype=cp.uint64)\n",
        "    tuple_indexer = cp.zeros((arr_4t.shape[1],), dtype=cp.bool_)\n",
        "\n",
        "    feature_grouper_kernel(col_indexer, padded_bool_indexer, tuple_indexer, padded_col_indexer)\n",
        "    tuple_indexer = cp.arange(arr_4t.shape[1], dtype=cp.uint64)[tuple_indexer]\n",
        "\n",
        "    fb = nfeats * nbins\n",
        "    nfb = nnodes * fb\n",
        "\n",
        "    magic_constant = 2 ** 19  # optimal value for my V100\n",
        "\n",
        "    # split features\n",
        "    nsplits = math.ceil(nfb / magic_constant)\n",
        "    # first split by feats\n",
        "    feats_batch = math.ceil(pfeats / nsplits)\n",
        "    # split by features\n",
        "    if feats_batch == nfeats:\n",
        "        out_batch = magic_constant // nfb\n",
        "    else:\n",
        "        out_batch = 1\n",
        "\n",
        "    ri = row_indexer[:, cp.newaxis, cp.newaxis]\n",
        "    ti = tuple_indexer[cp.newaxis, :, cp.newaxis]\n",
        "    oi = out_indexer[cp.newaxis, cp.newaxis, :]\n",
        "\n",
        "    nrows = ri.shape[0]\n",
        "\n",
        "    oii = cp.arange(oi.shape[2], dtype=cp.uint64)[cp.newaxis, cp.newaxis, :]\n",
        "\n",
        "    if func == 'ser2' or func == 'ser3':\n",
        "        with cp.cuda.Device(0):\n",
        "            res0 = cp.zeros(res.shape, dtype=cp.float32)\n",
        "        with cp.cuda.Device(1):\n",
        "            res1 = cp.zeros(res.shape, dtype=cp.float32)\n",
        "            ri_d1 = ri.copy()\n",
        "            padded_col_indexer_d1  = padded_col_indexer.copy()\n",
        "            padded_bool_indexer_d1 = padded_bool_indexer.copy()\n",
        "            target_d1 = target.copy()\n",
        "            arr_4t_d1 = arr_4t.copy()\n",
        "            nodes_d1  = nodes.copy()\n",
        "            nfb_d1    = nfb\n",
        "            fb_d1     = fb\n",
        "            nbins_d1  = nbins\n",
        "            nout_d1   = nout\n",
        "\n",
        "    for j in range(0, pfeats, feats_batch):\n",
        "        ti_ = ti[:, j: j + feats_batch]\n",
        "\n",
        "        for k in range(0, nout, out_batch):\n",
        "            oi_ = oi[..., k: k + out_batch]\n",
        "            oii_ = oii[..., k: k + out_batch]\n",
        "\n",
        "            if func == 'elw':\n",
        "                # Use original Anton's solution\n",
        "                histogram_kernel_idx_elw(ri, ti_, oi_,\n",
        "                                     oii_,\n",
        "                                     padded_col_indexer,\n",
        "                                     padded_bool_indexer,\n",
        "                                     target,\n",
        "                                     arr_4t,\n",
        "                                     nodes,\n",
        "                                     nfb, fb, nbins, arr_4t.shape[1], nout,\n",
        "                                     res, block_size=1024)\n",
        "            if func == 'ser':\n",
        "                histogram_kernel_idx_ser(ri, ti_, oi_,\n",
        "                                         oii_,\n",
        "                                         padded_col_indexer,\n",
        "                                         padded_bool_indexer,\n",
        "                                         target,\n",
        "                                         arr_4t,\n",
        "                                         nodes,\n",
        "                                         nfb, fb, nbins, arr_4t.shape[1], nout,\n",
        "                                         res, block_size=1024 )\n",
        "            if func == 'ser2':\n",
        "                with cp.cuda.Device(0):\n",
        "                    histogram_kernel_idx_ser(ri[0:nrows//2], ti_, oi_,\n",
        "                                             oii_,\n",
        "                                             padded_col_indexer,\n",
        "                                             padded_bool_indexer,\n",
        "                                             target,\n",
        "                                             arr_4t,\n",
        "                                             nodes,\n",
        "                                             nfb, fb, nbins, arr_4t.shape[1], nout,\n",
        "                                             res0, block_size=1024 )\n",
        "\n",
        "                with cp.cuda.Device(1):\n",
        "                    ti_d1  = ti_.copy()\n",
        "                    oi_d1  = oi_.copy()\n",
        "                    oii_d1 = oii_.copy()\n",
        "                    histogram_kernel_idx_ser(ri_d1[nrows//2:], ti_d1, oi_d1,\n",
        "                                             oii_d1,\n",
        "                                             padded_col_indexer_d1,\n",
        "                                             padded_bool_indexer_d1,\n",
        "                                             target_d1,\n",
        "                                             arr_4t_d1,\n",
        "                                             nodes_d1,\n",
        "                                             nfb_d1, fb_d1, nbins_d1, arr_4t_d1.shape[1], nout_d1,\n",
        "                                             res1, block_size=1024 )\n",
        "            if func == 'ser2_target':\n",
        "                with cp.cuda.Device(0):\n",
        "                    histogram_kernel_idx_ser(ri, ti_, oi_,\n",
        "                                             oii_,\n",
        "                                             padded_col_indexer,\n",
        "                                             padded_bool_indexer,\n",
        "                                             target[0:nrows//2],\n",
        "                                             arr_4t,\n",
        "                                             nodes,\n",
        "                                             nfb, fb, nbins, arr_4t.shape[1], nout,\n",
        "                                             res, block_size=1024 )\n",
        "                with cp.cuda.Device(1):\n",
        "                    ti_d1  = ti_.copy()\n",
        "                    oi_d1  = oi_.copy()\n",
        "                    oii_d1 = oii_.copy()\n",
        "                    histogram_kernel_idx_ser(ri_d1, ti_d1, oi_d1,\n",
        "                                             oii_d1,\n",
        "                                             padded_col_indexer_d1,\n",
        "                                             padded_bool_indexer_d1,\n",
        "                                             target_d1[nrows//2:],\n",
        "                                             arr_4t_d1,\n",
        "                                             nodes_d1,\n",
        "                                             nfb_d1, fb_d1, nbins_d1, arr_4t_d1.shape[1], nout_d1,\n",
        "                                             res1, block_size=1024)\n",
        "\n",
        "    if func == 'ser2' or func == 'ser2_target':\n",
        "        with cp.cuda.Device(0):\n",
        "            res[:] = res0 + res1\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def sample_idx(n, sample):\n",
        "    # THIST FUNCTION GENERATES IDS USED\n",
        "    # IN THE HISTOGRAM CALCULATIONS\n",
        "\n",
        "    idx = cp.arange(n, dtype=cp.uint64)\n",
        "    sl = cp.random.rand(n) < sample\n",
        "\n",
        "    return cp.ascontiguousarray(idx[sl])\n",
        "\n",
        "\n",
        "def generate_input( n_rows, n_cols, n_out, max_bin, nnodes,\n",
        "                    colsample=0.8, subsample=0.8, outsample=1.0, verbose=False, seed=42):\n",
        "    # THIS FUNCTION GENERATES ALL INPUT\n",
        "    # ARRAYS, REQUIRED BY THE HISTOGRAM\n",
        "    # FUNCTION IN PY-BOOST\n",
        "    # Input:\n",
        "    # n_rows   - number of rows in the input array\n",
        "    # n_cols   - number of cols in the input array\n",
        "    # n_out    - number of ???? in the output array\n",
        "    # max_bins - number of histogram bins (can't be >256 really)\n",
        "    # nnodes   - ????\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    features_cpu = np.random.randint(0, max_bin, size=(n_rows, n_cols)).astype(np.uint8)\n",
        "    features_gpu = pad_and_move(features_cpu)\n",
        "    cp.random.seed(seed)\n",
        "    targets_gpu  = cp.random.rand(n_rows, n_out).astype(np.float32)\n",
        "    cp.random.seed(seed)\n",
        "    nodes_gpu    = cp.random.randint(0, nnodes, size=(n_rows, )).astype(np.int32)\n",
        "    cp.random.seed(seed)\n",
        "\n",
        "    if verbose == True:\n",
        "        print('Initial CPU features shape: {}'.format(features_cpu.shape))\n",
        "        print('Padded  GPU features shape: {}'.format(features_gpu.shape))\n",
        "        print('Nodes   GPU vector   shape: {}'.format(nodes_gpu.shape   ))\n",
        "        print('Targets GPU array    shape: {}'.format(targets_gpu.shape ))\n",
        "\n",
        "    row_indexer = sample_idx(n_rows, subsample)\n",
        "    col_indexer = sample_idx(n_cols, colsample)\n",
        "    out_indexer = sample_idx(n_out, outsample)\n",
        "\n",
        "    if verbose == True:\n",
        "        print('Sampled rows shape:    {}'.format(row_indexer.shape))\n",
        "        print('Sampled columns shape: {}'.format(col_indexer.shape))\n",
        "        print('Sampled output shape:  {}'.format(out_indexer.shape))\n",
        "\n",
        "    nout   = out_indexer.shape[0]\n",
        "    nfeats = col_indexer.shape[0]\n",
        "\n",
        "    # Anton's function takes the following input arguments + the empty array to\n",
        "    # store the resulting histogram bins (comes in the first position)\n",
        "    # input: res, X, Y, nodes, col_indexer, row_indexer, out_indexer\n",
        "\n",
        "    res    = cp.zeros((nout, nnodes, nfeats, max_bin), dtype=cp.float32)\n",
        "    params = (res, features_gpu, targets_gpu, nodes_gpu, col_indexer, row_indexer, out_indexer)\n",
        "\n",
        "    if verbose == True:\n",
        "        true_res = nfeats * targets_gpu[row_indexer].sum()\n",
        "        print ('Sum of the resulting histogram must be {} ({}/2={})'.format( true_res, true_res, true_res/2 ))\n",
        "    return params\n",
        "\n",
        "\n",
        "# Original Anton's code on 1 GPU\n",
        "input_params = generate_input(n_rows=pow(10,6),n_cols=99,n_out=10,max_bin=256,nnodes=32,verbose=False)\n",
        "tau0 = benchmark( fill_histogram_tmp, (*input_params, 'elw'), n_repeat=1000, n_warmup=10 )\n",
        "\n",
        "print (tau0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Phy9IxAinD_",
        "outputId": "41a6dcde-daae-465f-81e7-da6377fcaacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing example2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile --stats=true --python-sampling=true python example2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnQDGzXzkSVO",
        "outputId": "a15f278f-98bc-435a-cad3-35a191656f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fill_histogram_tmp  :    CPU:  1799.232 us   +/- 582.253 (min:  1295.151 / max:  6667.247) us     GPU-0: 38804.605 us   +/- 918.958 (min: 35661.247 / max: 41830.463) us\n",
            "Generating '/tmp/nsys-report-7b6a.qdstrm'\n",
            "[1/8] [========================100%] report3.nsys-rep\n",
            "[2/8] [========================100%] report3.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: No data available.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)    Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  -------------  ---------  -----------  ------------  ----------------------\n",
            "     97.2   51,119,439,942        521  98,117,927.0  100,127,600.0      3,512  105,803,255  13,997,137.8  poll                  \n",
            "      0.9      473,738,222      3,788     125,062.9        1,807.5        303   45,309,071     976,399.1  read                  \n",
            "      0.8      418,550,047  6,239,131          67.1           45.0         33    7,824,121       8,002.4  getc                  \n",
            "      0.4      205,713,363        691     297,703.9       14,722.0        652   87,748,765   3,682,596.5  ioctl                 \n",
            "      0.3      139,507,807      3,824      36,482.2       14,516.5        749    4,254,269     212,467.5  pthread_cond_wait     \n",
            "      0.2       83,783,423    245,451         341.3           34.0         20    2,509,202       5,340.8  pthread_cond_signal   \n",
            "      0.2       82,618,646      4,129      20,009.4       15,272.0        760    2,221,016      70,512.1  pthread_cond_timedwait\n",
            "      0.1       42,771,426      2,786      15,352.3        8,439.5      1,382      803,490      40,372.5  open64                \n",
            "      0.0        5,069,936          1   5,069,936.0    5,069,936.0  5,069,936    5,069,936           0.0  nanosleep             \n",
            "      0.0        4,664,115        206      22,641.3       11,843.0      6,257    1,376,880      96,376.0  mmap64                \n",
            "      0.0        4,544,916        476       9,548.1        9,434.0      1,891       29,650       3,909.1  fopen                 \n",
            "      0.0        3,778,140         58      65,140.3       16,062.0      1,129    1,685,572     257,016.8  write                 \n",
            "      0.0        2,664,132        459       5,804.2        5,089.0      1,047      375,012      17,774.6  fclose                \n",
            "      0.0        1,995,381        151      13,214.4       13,371.0      3,424      171,571      14,412.8  mmap                  \n",
            "      0.0        1,053,624        172       6,125.7        3,709.0        461       25,322       5,459.9  mprotect              \n",
            "      0.0          709,093          2     354,546.5      354,546.5      2,283      706,810     498,175.8  pthread_rwlock_wrlock \n",
            "      0.0          672,147          5     134,429.4       51,443.0     45,070      468,458     186,778.2  sem_timedwait         \n",
            "      0.0          558,855      1,093         511.3          192.0         27       32,325       1,936.7  pthread_mutex_lock    \n",
            "      0.0          244,219        114       2,142.3           48.0         44       48,856       9,004.7  fgets                 \n",
            "      0.0          232,704          4      58,176.0       57,165.0     47,187       71,187       9,867.4  pthread_create        \n",
            "      0.0          156,129         12      13,010.8       12,163.5      8,022       27,963       5,504.4  munmap                \n",
            "      0.0           57,615          6       9,602.5        8,065.5      2,976       18,693       5,687.7  fopen64               \n",
            "      0.0           46,777          9       5,197.4        5,203.0      2,594       10,395       2,314.8  open                  \n",
            "      0.0           40,150        133         301.9          274.0         19        1,704         193.0  sigaction             \n",
            "      0.0           38,463         64         601.0          597.5        221        1,405         194.6  fcntl                 \n",
            "      0.0           34,168          1      34,168.0       34,168.0     34,168       34,168           0.0  waitpid               \n",
            "      0.0           27,425          2      13,712.5       13,712.5     10,137       17,288       5,056.5  socket                \n",
            "      0.0           26,303          3       8,767.7        9,310.0      6,847       10,146       1,715.1  pipe2                 \n",
            "      0.0           15,039        278          54.1           50.0         26          267          23.0  flockfile             \n",
            "      0.0           12,731        131          97.2           38.0         27        2,780         253.1  pthread_mutex_trylock \n",
            "      0.0           11,963         50         239.3           52.5         41        1,362         360.7  fflush                \n",
            "      0.0            9,871          1       9,871.0        9,871.0      9,871        9,871           0.0  connect               \n",
            "      0.0            7,544          7       1,077.7          525.0        405        2,818         900.5  signal                \n",
            "      0.0            7,414          1       7,414.0        7,414.0      7,414        7,414           0.0  fread                 \n",
            "      0.0            7,320          1       7,320.0        7,320.0      7,320        7,320           0.0  fputs_unlocked        \n",
            "      0.0            5,729         11         520.8          424.0        324        1,284         280.6  dup                   \n",
            "      0.0            2,242          1       2,242.0        2,242.0      2,242        2,242           0.0  bind                  \n",
            "      0.0            1,194          1       1,194.0        1,194.0      1,194        1,194           0.0  listen                \n",
            "      0.0              820          1         820.0          820.0        820          820           0.0  dup2                  \n",
            "      0.0              502          1         502.0          502.0        502          502           0.0  pthread_cond_broadcast\n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)     Min (ns)    Max (ns)    StdDev (ns)                 Name               \n",
            " --------  ---------------  ---------  ------------  ------------  ----------  -----------  ------------  ---------------------------------\n",
            "     97.3   37,034,156,409      1,001  36,997,159.2  37,064,852.0  31,284,329   40,390,778   1,116,443.8  cudaEventSynchronize             \n",
            "      1.1      433,506,065      1,013     427,942.8      25,469.0      21,843   66,275,788   4,427,709.8  cudaMemcpy                       \n",
            "      0.6      228,973,590     25,275       9,059.3       7,715.0       4,514    2,074,609      17,227.3  cuLaunchKernel                   \n",
            "      0.3      120,497,635         16   7,531,102.2     278,687.0      20,204  117,107,317  29,220,652.9  cudaMalloc                       \n",
            "      0.2       90,372,754          1  90,372,754.0  90,372,754.0  90,372,754   90,372,754           0.0  cudaHostAlloc                    \n",
            "      0.2       89,820,087          8  11,227,510.9      33,609.0      11,557   33,127,123  15,533,854.6  cudaLaunchKernel                 \n",
            "      0.1       20,052,593      3,031       6,615.8       4,551.0       2,593      819,463      17,648.0  cudaMemsetAsync                  \n",
            "      0.0       13,921,445      2,002       6,953.8       6,330.0       3,968       62,505       3,231.1  cudaEventRecord                  \n",
            "      0.0        8,902,283         15     593,485.5     554,033.0     365,941    1,525,984     282,335.5  cuModuleLoadData                 \n",
            "      0.0        1,630,332      1,019       1,599.9       1,302.0       1,056       17,898       1,054.0  cudaStreamIsCapturing_v10000     \n",
            "      0.0          780,385          3     260,128.3     259,804.0     258,783      261,798       1,533.4  cudaDeviceSynchronize            \n",
            "      0.0          427,057          1     427,057.0     427,057.0     427,057      427,057           0.0  cudaFree                         \n",
            "      0.0          253,089          1     253,089.0     253,089.0     253,089      253,089           0.0  cudaGetDeviceProperties_v2_v12000\n",
            "      0.0          162,637        390         417.0         374.5         182        7,013         363.7  cuGetProcAddress_v2              \n",
            "      0.0           73,709          1      73,709.0      73,709.0      73,709       73,709           0.0  cudaMemGetInfo                   \n",
            "      0.0           50,910          1      50,910.0      50,910.0      50,910       50,910           0.0  cudaMemcpyAsync                  \n",
            "      0.0           30,346          3      10,115.3       6,829.0       1,824       21,693      10,334.1  cudaEventCreateWithFlags         \n",
            "      0.0            6,550          1       6,550.0       6,550.0       6,550        6,550           0.0  cudaEventQuery                   \n",
            "      0.0            3,123          1       3,123.0       3,123.0       3,123        3,123           0.0  cuInit                           \n",
            "      0.0            2,983          2       1,491.5       1,491.5         533        2,450       1,355.5  cuModuleGetLoadingMode           \n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)                                                  Name                                                \n",
            " --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------------------------------------------------------------------------------------------------\n",
            "    100.0   38,586,540,026     20,200  1,910,224.8  1,899,123.0  1,562,774  3,673,287    171,472.5  histogram_kernel_idx                                                                                \n",
            "      0.0        3,808,578      2,023      1,882.6      1,888.0      1,536     35,072        765.1  cupy_arange__uint_uint_uint64                                                                       \n",
            "      0.0        2,812,687      1,015      2,771.1      2,688.0      2,368     90,271      2,756.4  cupy_scan_naive                                                                                     \n",
            "      0.0        2,296,852      1,013      2,267.4      2,176.0      1,952     84,256      2,580.9  cupy_getitem_mask                                                                                   \n",
            "      0.0        2,238,350      1,010      2,216.2      2,208.0      2,016      3,424         87.7  feature_grouper_kernel                                                                              \n",
            "      0.0          819,258          4    204,814.5     40,719.5      3,200    734,619    354,912.0  void gen_sequenced<curandStateXORWOW, double, int, &curand_uniform_double_noargs<curandStateXORWOW>…\n",
            "      0.0          766,202          3    255,400.7    254,718.0    254,366    257,118      1,497.6  void generate_seed_pseudo<rng_config<curandStateXORWOW, (curandOrdering)101>>(unsigned long long, u…\n",
            "      0.0          702,108          4    175,527.0     34,592.0      3,008    629,916    304,383.8  cupy_random_x_mod_1                                                                                 \n",
            "      0.0          507,036          1    507,036.0    507,036.0    507,036    507,036          0.0  cupy_copy__float64_float32                                                                          \n",
            "      0.0           65,408          1     65,408.0     65,408.0     65,408     65,408          0.0  cupy_add__int64_int_int64                                                                           \n",
            "      0.0           53,855          3     17,951.7      3,072.0      3,072     47,711     25,772.3  cupy_less__float64_float_bool                                                                       \n",
            "      0.0           52,320          1     52,320.0     52,320.0     52,320     52,320          0.0  cupy_copy__uint32_int64                                                                             \n",
            "      0.0           51,456          1     51,456.0     51,456.0     51,456     51,456          0.0  cupy_copy__int64_int32                                                                              \n",
            "      0.0           37,727          1     37,727.0     37,727.0     37,727     37,727          0.0  cupy_bitwise_and__uint32_uint_uint32                                                                \n",
            "      0.0           34,720          2     17,360.0     17,360.0      4,000     30,720     18,893.9  cupy_bsum_shfl                                                                                      \n",
            "      0.0           22,720          1     22,720.0     22,720.0     22,720     22,720          0.0  void gen_sequenced<curandStateXORWOW, unsigned int, int, &curand_noargs<curandStateXORWOW>, rng_con…\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)      Operation     \n",
            " --------  ---------------  -----  -----------  -----------  ---------  ---------  -----------  ------------------\n",
            "     71.0        8,088,905      1  8,088,905.0  8,088,905.0  8,088,905  8,088,905          0.0  [CUDA memcpy HtoD]\n",
            "     15.9        1,816,050  3,031        599.2        576.0        480    107,615      1,944.7  [CUDA memset]     \n",
            "     13.1        1,488,912  1,013      1,469.8      1,472.0      1,376      2,176         57.5  [CUDA memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
            "    100.000      1   100.000   100.000   100.000   100.000        0.000  [CUDA memcpy HtoD]\n",
            "     25.183  3,031     0.008     0.000     0.000    24.248        0.440  [CUDA memset]     \n",
            "      0.004  1,013     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /content/report3.nsys-rep\n",
            "    /content/report3.sqlite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze command**:\n",
        "- `nsys analyze file.nsys-rep`\n",
        "- post process existing Nsight Systems result, either in .nsys-rep or SQLite format, to generate expert systems report"
      ],
      "metadata": {
        "id": "Ccbuwfdqlcbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys analyze report3.nsys-rep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B1XRzhxk9Ao",
        "outputId": "e3567459-5404-4dde-b866-88be8299cbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NOTICE: Existing SQLite export found: report3.sqlite\n",
            "        It is assumed file was previously exported from: report3.nsys-rep\n",
            "        Consider using --force-export=true if needed.\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/cuda_memcpy_async.py]... \n",
            "\n",
            " ** CUDA Async Memcpy with Pageable Memory (cuda_memcpy_async):\n",
            "\n",
            "There were no problems detected related to memcpy operations using pageable\n",
            "memory.\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/cuda_memcpy_sync.py]... \n",
            "\n",
            " ** CUDA Synchronous Memcpy (cuda_memcpy_sync):\n",
            "\n",
            "The following are synchronous memory transfers that block the host. This does\n",
            "not include host to device transfers of a memory block of 64 KB or less.\n",
            "\n",
            "Suggestion: Use cudaMemcpy*Async() APIs instead.\n",
            "\n",
            " Duration (ns)    Start (ns)    Src Kind  Dst Kind  Bytes (MB)   PID    Device ID  Context ID  Stream ID      API Name    \n",
            " -------------  --------------  --------  --------  ----------  ------  ---------  ----------  ---------  ----------------\n",
            "         2,176  27,818,495,220  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         2,112  28,279,397,578  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,888  50,519,377,739  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,792  30,793,139,955  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,792  60,796,947,551  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,760  46,439,721,417  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,760  48,691,339,793  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,760  62,745,293,942  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,760  66,893,170,152  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,760  68,059,527,564  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,728  38,525,264,413  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,728  41,315,332,226  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,728  51,847,960,789  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,728  63,658,790,979  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,696  55,414,619,983  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,664  39,402,772,293  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,664  48,574,885,846  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,664  49,973,714,451  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,664  55,023,122,442  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,632  28,279,965,191  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,632  28,898,874,492  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,632  29,308,533,801  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,632  29,376,704,097  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  30,146,676,101  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  33,400,040,571  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  35,599,567,505  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  36,626,058,116  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  40,051,966,373  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  46,829,770,932  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  52,591,841,932  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  54,825,171,238  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  55,335,666,694  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  57,544,769,454  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  60,123,562,854  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,600  62,983,337,157  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  30,453,205,094  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  33,096,793,387  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  38,220,507,375  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  40,818,273,538  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  43,274,224,379  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  45,590,496,665  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,568  51,927,378,916  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  31,321,814,331  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  36,396,200,076  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  41,738,302,984  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  44,391,277,993  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  45,938,228,463  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  46,284,971,434  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  47,643,784,333  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "         1,536  49,546,968,803  Device    Pageable       0.000  10,494          0           1          7  cudaMemcpy_v3020\n",
            "\n",
            "Only the top 50 results are displayed. More data may be available.\n",
            "\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/cuda_memset_sync.py]... \n",
            "\n",
            " ** CUDA Synchronous Memset (cuda_memset_sync):\n",
            "\n",
            "There were no problems detected related to synchronization APIs.\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/cuda_api_sync.py]... \n",
            "\n",
            " ** CUDA Synchronization APIs (cuda_api_sync):\n",
            "\n",
            "The following are synchronization APIs that block the host until all issued\n",
            "CUDA calls are complete.\n",
            "\n",
            "Suggestions:\n",
            "   1. Avoid excessive use of synchronization.\n",
            "   2. Use asynchronous CUDA event calls, such as cudaStreamWaitEvent() and\n",
            "cudaEventSynchronize(), to prevent host synchronization.\n",
            "\n",
            " Duration (ns)    Start (ns)     PID     TID             API Name          \n",
            " -------------  --------------  ------  ------  ---------------------------\n",
            "       261,798  21,800,636,991  10,494  10,494  cudaDeviceSynchronize_v3020\n",
            "       259,804  25,324,716,616  10,494  10,494  cudaDeviceSynchronize_v3020\n",
            "       258,783  19,697,746,305  10,494  10,494  cudaDeviceSynchronize_v3020\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/gpu_gaps.py]... \n",
            "\n",
            " ** GPU Gaps (gpu_gaps):\n",
            "\n",
            "The following are ranges where a GPU is idle for more than 500ms. Addressing\n",
            "these gaps might improve application performance.\n",
            "\n",
            "Suggestions:\n",
            "   1. Use CPU sampling data, OS Runtime blocked state backtraces, and/or OS\n",
            "Runtime APIs related to thread synchronization to understand if a sluggish or\n",
            "blocked CPU is causing the gaps.\n",
            "   2. Add NVTX annotations to CPU code to understand the reason behind the gaps.\n",
            "\n",
            " Row#  Duration (ns)    Start (ns)     PID    Device ID  Context ID\n",
            " ----  -------------  --------------  ------  ---------  ----------\n",
            "    1  1,596,447,278  23,727,729,888  10,494          0           1\n",
            "    2  1,220,829,086  19,726,731,665  10,494          0           1\n",
            "    3    851,859,168  20,948,190,667  10,494          0           1\n",
            "    4    700,748,443  21,829,489,605  10,494          0           1\n",
            "    5    617,797,822  28,280,745,697  10,494          0           1\n",
            "    6    526,953,555  25,835,488,010  10,494          0           1\n",
            "    7    514,689,454  26,810,070,988  10,494          0           1\n",
            "    8    510,278,147  25,325,162,152  10,494          0           1\n",
            "    9    506,058,750  22,530,275,775  10,494          0           1\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/gpu_time_util.py]... \n",
            "\n",
            " ** GPU Time Utilization (gpu_time_util):\n",
            "\n",
            "The following are time regions with an average GPU utilization below 50%%.\n",
            "Addressing the gaps might improve application performance.\n",
            "\n",
            "Suggestions:\n",
            "   1. Use CPU sampling data, OS Runtime blocked state backtraces, and/or OS\n",
            "Runtime APIs related to thread synchronization to understand if a sluggish or\n",
            "blocked CPU is causing the gaps.\n",
            "   2. Add NVTX annotations to CPU code to understand the reason behind the gaps.\n",
            "\n",
            " Row#  In-Use (%)  Duration (ns)    Start (ns)     PID    Device ID  Context ID\n",
            " ----  ----------  -------------  --------------  ------  ---------  ----------\n",
            "    1         2.2  9,784,803,882  19,659,506,455  10,494          0           1\n",
            "\n",
            "Processing [report3.sqlite] with [/opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/rules/dx12_mem_ops.py]... \n",
            "SKIPPED: report3.sqlite could not be analyzed because it does not contain the required DX12 data. Does the application use DX12 APIs?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export CLI output to visual profiler"
      ],
      "metadata": {
        "id": "1AZ88eOG_U6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Export**\n",
        "\n",
        "`!nvprof --export-profile filename app`\n",
        "\n",
        "`!nsys nvprof --output=filename app`\n",
        "\n",
        "`!nvprof --import-profile filename`\n",
        "\n",
        "[Option desription](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#io-options)\n",
        "\n",
        "[How to import into nvprof visual profiler (nvvp)](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#import-session):\n",
        "\n",
        "- Click *Import* option in the *File* menu\n",
        "- Can import single or multiple `nvprof` output files\n",
        "\n",
        "**How to import into the Nsight Systems GUI:**\n",
        "\n",
        "- The CLI and host GUI versions must match to import a `.qdstrm` file successfully; the host GUI is backward compatible only with `.nsys-rep` files.\n",
        "\n",
        "- `File -> Import -> .qdstrm file`\n",
        "\n",
        "- *The import of really large, multi-gigabyte, `.qdstrm` files may take up all of the memory on the host computer and lock up the system*"
      ],
      "metadata": {
        "id": "q8C26hYrDQXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o cudabasic cudabasic.cu"
      ],
      "metadata": {
        "id": "_arO7YhaIRd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --export-profile result ./cudabasic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAuulxPmITWW",
        "outputId": "202a029c-ddf1-4ac1-eee3-10385e4c8537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocating memory on host.\n",
            "Allocating memory on device.\n",
            "==15698== NVPROF is profiling process 15698, command: ./cudabasic\n",
            "Copying to device.\n",
            "Doing GPU Vector + 1 \n",
            "Doing a CPU Vector add & Copy to host\n",
            "Compare Results\n",
            "Free resources==15698== Generated result file: /content/result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --import-profile result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufXoGc6fJ0aU",
        "outputId": "f7974bba-b1ff-4c08-fe22-c379caa3011c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   60.60%  1.9154ms         1  1.9154ms  1.9154ms  1.9154ms  [CUDA memcpy DtoH]\n",
            "                   35.80%  1.1317ms         1  1.1317ms  1.1317ms  1.1317ms  [CUDA memcpy HtoD]\n",
            "                    3.60%  113.70us         1  113.70us  113.70us  113.70us  vecAddOne(int*, int*, int)\n",
            "      API calls:   94.38%  93.486ms         2  46.743ms  70.340us  93.415ms  cudaMalloc\n",
            "                    4.82%  4.7730ms         2  2.3865ms  1.4441ms  3.3289ms  cudaMemcpy\n",
            "                    0.33%  326.93us         2  163.47us  124.69us  202.25us  cudaFree\n",
            "                    0.19%  191.70us         1  191.70us  191.70us  191.70us  cudaLaunchKernel\n",
            "                    0.13%  131.85us       114  1.1560us     135ns  52.442us  cuDeviceGetAttribute\n",
            "                    0.11%  113.61us         1  113.61us  113.61us  113.61us  cudaDeviceSynchronize\n",
            "                    0.01%  11.774us         1  11.774us  11.774us  11.774us  cuDeviceGetName\n",
            "                    0.01%  5.7820us         1  5.7820us  5.7820us  5.7820us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.5500us         1  4.5500us  4.5500us  4.5500us  cuDeviceTotalMem\n",
            "                    0.00%  1.8640us         3     621ns     194ns  1.4560us  cuDeviceGetCount\n",
            "                    0.00%     896ns         2     448ns     164ns     732ns  cuDeviceGet\n",
            "                    0.00%     653ns         1     653ns     653ns     653ns  cuModuleGetLoadingMode\n",
            "                    0.00%     238ns         1     238ns     238ns     238ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Occupancy\n",
        "\n",
        "[Reference](https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm)"
      ],
      "metadata": {
        "id": "FhXsDdWodiAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CUDA groups adjacent threads within a block into **warps**\n",
        "\n",
        "- A **warp** is considered **active** from the time its threads begin executing to the time when all threads in the warp have exited from the kernel\n",
        "\n",
        "- There is a **maximum number of warps** which can be concurrently active on a Streaming Multiprocessor (SM) (depends on he launch configuration, compile options for the kernel, and device capabilities)\n",
        "\n",
        "- **Occupancy** is the ratio of active warps on an SM to the maximum number of active warps supported by the SM\n",
        "\n",
        "- **Low occupancy** results in poor instruction issue efficiency, because there are not enough eligible warps to hide latency between dependent instructions\n",
        "\n",
        "- When occupancy is at a sufficient level to hide latency, increasing it further **may degrade performance** due to the reduction in resources per thread\n",
        "\n",
        "- An **early step of kernel performance analysis** should be to check occupancy and observe the effects on kernel execution time when running at different occupancy levels"
      ],
      "metadata": {
        "id": "DpdDs9pSfUSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theoretical Occupancy\n",
        "\n",
        "- Each block of a kernel launch gets distributed to one of the SMs for execution\n",
        "\n",
        "- A **block** is considered **active** from the time its warps begin executing to the time when all warps in the block have exited from the kernel\n",
        "\n",
        "- **(upper limit for active warps) = (upper limit for active blocks) \\* (number of warps per block)**\n",
        "\n",
        "- The number of blocks which can execute concurrently on an SM is limited by the factors listed below\n",
        "\n",
        "- Then how  we can increase the upper limit for active warps:\n",
        "\n",
        "  - increase the number of warps per block (defined by block dimension)\n",
        "\n",
        "  - or change the factors (see below) limiting how many blocks can fit on an SM to allow more active blocks\n",
        "\n",
        "- **The factors limiting the number of concurrently active warps**:\n",
        "\n",
        "  - *warps per SM*:\n",
        "\n",
        "    -  The SM has a maximum number of warps that can be active at once\n",
        "\n",
        "    - from the definition: occupancy is 100% if the number of active warps equals the maximum\n",
        "\n",
        "    - If this factor is limiting active blocks, occupancy cannot be increased\n",
        "\n",
        "    - [Example](https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm)\n",
        "\n",
        "  - *blocks per SM*:\n",
        "\n",
        "    - The SM has a maximum number of blocks that can be active at once\n",
        "\n",
        "    - If occupancy is below 100% and this factor is limiting active blocks, it means each block does not contain enough warps to reach 100% occupancy when the device's active block limit is reached\n",
        "    \n",
        "    - Occupancy can be increased by increasing block size\n",
        "\n",
        "    - [Example](https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm)\n",
        "\n",
        "  - *registers per SM*:\n",
        "\n",
        "    - The SM has a set of registers shared by all active threads\n",
        "\n",
        "    -  If this factor is limiting active blocks, it means the number of registers per thread allocated by the compiler can be reduced to increase\n",
        "\n",
        "    - The performance gain from improved latency hiding due to increased occupancy may be outweighed by the performance loss of having fewer registers per thread, and spilling to local memory more often\n",
        "\n",
        "    - The best-performing balance of occupancy and registers per thread can be found experimentally by tracing the kernel compiled with different numbers of registers per thread\n",
        "\n",
        "  - *shared Memory per SM*:\n",
        "\n",
        "    - The SM has a fixed amount of shared memory shared by all active threads\n",
        "\n",
        "    - If this factor is limiting active blocks, it means the shared memory needed per thread can be reduced to increase occupancy\n",
        "\n",
        "    - (Shared memory per thread) = (\"static shared memory\") + (\"dynamic shared memory\"), where\n",
        "\n",
        "      - \"static shared memory\" is the total size needed for all \\_\\_shared\\_\\_ variables\n",
        "\n",
        "      - \"dynamic shared memory\" is the amount of shared memory specified as a parameter to the kernel launch\n",
        "\n",
        "    - For some CUDA devices, the amount of shared memory per SM is configurable, trading between shared memory size and L1 cache size:\n",
        "\n",
        "      - If such a GPU is configured to use more L1 cache and shared memory is the limiting factor for occupancy, then occupancy can also be increased by choosing to use less L1 cache and more shared memory"
      ],
      "metadata": {
        "id": "HYcskCvafQ4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Achieved Occupancy\n"
      ],
      "metadata": {
        "id": "07zN1sD-kEux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Theoretical occupancy shows the upper bound active warps on an SM, but the true number of active warps varies over the duration of the kernel, as warps begin and end\n",
        "\n",
        "- A SM contain one or more warp schedulers\n",
        "\n",
        "- Each warp scheduler attempts to issue instructions from a warp on each clock cycle\n",
        "\n",
        "- To sufficiently hide latencies between dependent instructions, each scheduler must have at least one warp eligible to issue an instruction every clock cycle\n",
        "\n",
        "- Maintaining as many active warps as possible (a high occupancy) throughout the execution of the kernel helps to avoid situations where all warps are stalled and no instructions are issued\n",
        "\n",
        "- **Achieved occupancy** is measured on each warp scheduler using hardware performance counters to count the number of active warps on that scheduler every clock cycle\n",
        "\n",
        "- These counts are then summed across all warp schedulers on each SM and divided by the clock cycles the SM is active to find the average active warps per SM\n",
        "\n",
        "- Dividing by the SM's maximum supported number of active warps gives the **achieved occupancy per SM averaged over the duration of the kernel**\n",
        "\n",
        "- Averaging across all SMs gives the **overall achieved occupancy**"
      ],
      "metadata": {
        "id": "g738m2wln3eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Causes of Low Achieved Occupancy\n",
        "\n",
        "- *Achieved occupancy <= theoretical occupancy*\n",
        "\n",
        "- **Steps to increase achieved occupancy**:\n",
        "\n",
        "  1) increase theoretical occupancy by adjusting the limiting factors;\n",
        "\n",
        "  2) check if the achieved value is close to the theoretical value:\n",
        "  \n",
        "    - (achieved occupancy <= theoretical occupancy)  when the theoretical number of active warps is not maintained for the full time the SM is active; it occurs in the situations:\n",
        "\n",
        "      - **unbalanced workload within blocks**:\n",
        "\n",
        "        - If warps within a block do not all execute for the same amount of time, the **workload** is said to be **unbalanced** <=> fewer active warps at the end of the kernel, which is a problem known as **\"tail effect\"**\n",
        "\n",
        "        - **Best solution** is to try having a more balanced workload among the warps in each block\n",
        "\n",
        "      - **unbalanced workload across blocks:**\n",
        "\n",
        "        - Blocks within a grid do not all execute for the same amount of time\n",
        "\n",
        "        - The efficiency of the device can be improved without having to change to a more balanced workload\n",
        "\n",
        "        - Launching more blocks will allow new blocks to begin as others finish, meaning the tail effect does not occur inside every block, but only at the end of the kernel\n",
        "\n",
        "        - If there are not more blocks to launch, running concurrent kernels with similar block properties can achieve the same effect\n",
        "\n",
        "      - **too few blocks launched:**\n",
        "\n",
        "        - (\"Full wave\") = (number of SMs on the device) \\* (maximum active blocks per SM)\n",
        "\n",
        "        - Launching less than a full wave results in low achieved occupancy\n",
        "\n",
        "        - [Example](https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm)\n",
        "\n"
      ],
      "metadata": {
        "id": "KzarcbeXlH-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Charts & Analysis"
      ],
      "metadata": {
        "id": "ZljmuKSDn6bG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- varying block size\n",
        "- varying register count\n",
        "- varying share memory usage\n",
        "- achieved occupancy per SM\n",
        "\n",
        "[Charts](https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm#Charts)\n",
        "\n",
        "[What to do](https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedoccupancy.htm#Analysis)"
      ],
      "metadata": {
        "id": "5Io-1V4Mn9Om"
      }
    }
  ]
}